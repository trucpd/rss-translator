{
  "last_updated": "2025-03-09T09:22:52.246841",
  "entries": [
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Spotlight on SIG etcd",
      "link": "https://kubernetes.io/blog/2025/03/04/sig-etcd-spotlight/",
      "published": "Tue, 04 Mar 2025 00:00:00 +0000",
      "summary": "<p>In this SIG etcd spotlight we talked with <a href=\"https://github.com/jmhbnz\">James Blair</a>, <a href=\"https://github.com/serathius\">Marek\nSiarkowicz</a>, <a href=\"https://github.com/wenjiaswe\">Wenjia Zhang</a>, and\n<a href=\"https://github.com/ahrtr\">Benjamin Wang</a> to learn a bit more about this Kubernetes Special Interest\nGroup.</p>\n<h2 id=\"introducing-sig-etcd\">Introducing SIG etcd</h2>\n<p><strong>Frederico: Hello, thank you for the time! Let‚Äôs start with some introductions, could you tell us a\nbit about yourself, your role and how you got involved in Kubernetes.</strong></p>\n<p><strong>Benjamin:</strong> Hello, I am Benjamin. I am a SIG etcd Tech Lead and one of the etcd maintainers. I\nwork for VMware, which is part of the Broadcom group. I got involved in Kubernetes &amp; etcd &amp; CSI\n(<a href=\"https://github.com/container-storage-interface/spec/blob/master/spec.md\">Container Storage Interface</a>)\nbecause of work and also a big passion for open source. I have been working on Kubernetes &amp; etcd\n(and also CSI) since 2020.</p>\n<p><strong>James:</strong> Hey team, I‚Äôm James, a co-chair for SIG etcd and etcd maintainer. I work at Red Hat as a\nSpecialist Architect helping people adopt cloud native technology. I got involved with the\nKubernetes ecosystem in 2019. Around the end of 2022 I noticed how the etcd community and project\nneeded help so started contributing as often as I could. There is a saying in our community that\n&quot;you come for the technology, and stay for the people&quot;: for me this is absolutely real, it‚Äôs been a\nwonderful journey so far and I‚Äôm excited to support our community moving forward.</p>\n<p><strong>Marek:</strong> Hey everyone, I'm Marek, the SIG etcd lead. At Google, I lead the GKE etcd team, ensuring\na stable and reliable experience for all GKE users. My Kubernetes journey began with <a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation\">SIG\nInstrumentation</a>, where I\ncreated and led the <a href=\"https://kubernetes.io/blog/2020/09/04/kubernetes-1-19-introducing-structured-logs/\">Kubernetes Structured Logging effort</a>.<br />\nI'm still the main project lead for <a href=\"https://kubernetes-sigs.github.io/metrics-server/\">Kubernetes Metrics Server</a>,\nproviding crucial signals for autoscaling in Kubernetes. I started working on etcd 3 years ago,\nright around the 3.5 release. We faced some challenges, but I'm thrilled to see etcd now the most\nscalable and reliable it's ever been, with the highest contribution numbers in the project's\nhistory. I'm passionate about distributed systems, extreme programming, and testing.</p>\n<p><strong>Wenjia:</strong> Hi there, my name is Wenjia, I am the co-chair of SIG etcd and one of the etcd\nmaintainers. I work at Google as an Engineering Manager, working on GKE (Google Kubernetes Engine)\nand GDC (Google Distributed Cloud). I have been working in the area of open source Kubernetes and\netcd since the Kubernetes v1.10 and etcd v3.1 releases. I got involved in Kubernetes because of my\njob, but what keeps me in the space is the charm of the container orchestration technology, and more\nimportantly, the awesome open source community.</p>\n<h2 id=\"becoming-a-kubernetes-special-interest-group-sig\">Becoming a Kubernetes Special Interest Group (SIG)</h2>\n<p><strong>Frederico: Excellent, thank you. I'd like to start with the origin of the SIG itself: SIG etcd is\na very recent SIG, could you quickly go through the history and reasons behind its creation?</strong></p>\n<p><strong>Marek</strong>: Absolutely! SIG etcd was formed because etcd is a critical component of Kubernetes,\nserving as its data store. However, etcd was facing challenges like maintainer turnover and\nreliability issues. <a href=\"https://etcd.io/blog/2023/introducing-sig-etcd/\">Creating a dedicated SIG</a>\nallowed us to focus on addressing these problems, improving development and maintenance processes,\nand ensuring etcd evolves in sync with the cloud-native landscape.</p>\n<p><strong>Frederico: And has becoming a SIG worked out as expected? Better yet, are the motivations you just\ndescribed being addressed, and to what extent?</strong></p>\n<p><strong>Marek</strong>: It's been a positive change overall. Becoming a SIG has brought more structure and\ntransparency to etcd's development. We've adopted Kubernetes processes like KEPs\n(<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/README.md\">Kubernetes Enhancement Proposals</a>\nand PRRs (<a href=\"https://github.com/kubernetes/community/blob/master/sig-architecture/production-readiness.md\">Production Readiness Reviews</a>,\nwhich has improved our feature development and release cycle.</p>\n<p><strong>Frederico: On top of those, what would you single out as the major benefit that has resulted from\nbecoming a SIG?</strong></p>\n<p><strong>Marek</strong>: The biggest benefits for me was adopting Kubernetes testing infrastructure, tools like\n<a href=\"https://docs.prow.k8s.io/\">Prow</a> and <a href=\"https://testgrid.k8s.io/\">TestGrid</a>. For large projects like\netcd there is just no comparison to the default GitHub tooling. Having known, easy to use, clear\ntools is a major boost to the etcd as it makes it much easier for Kubernetes contributors to also\nhelp etcd.</p>\n<p><strong>Wenjia</strong>: Totally agree, while challenges remain, the SIG structure provides a solid foundation\nfor addressing them and ensuring etcd's continued success as a critical component of the Kubernetes\necosystem.</p>\n<p>The positive impact on the community is another crucial aspect of SIG etcd's success that I‚Äôd like\nto highlight. The Kubernetes SIG structure has created a welcoming environment for etcd\ncontributors, leading to increased participation from the broader Kubernetes community. We have had\ngreater collaboration with other SIGs like <a href=\"https://github.com/kubernetes/community/blob/master/sig-api-machinery/README.md\">SIG API\nMachinery</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scalability\">SIG Scalability</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scalability\">SIG Testing</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle\">SIG Cluster Lifecycle</a>, etc.</p>\n<p>This collaboration helps ensure etcd's development aligns with the needs of the wider Kubernetes\necosystem. The formation of the <a href=\"https://github.com/kubernetes/community/blob/master/wg-etcd-operator/README.md\">etcd Operator Working Group</a>\nunder the joint effort between SIG etcd and SIG Cluster Lifecycle exemplifies this successful\ncollaboration, demonstrating a shared commitment to improving etcd's operational aspects within\nKubernetes.</p>\n<p><strong>Frederico: Since you mentioned collaboration, have you seen changes in terms of contributors and\ncommunity involvement in recent months?</strong></p>\n<p><strong>James</strong>: Yes -- as showing in our\n<a href=\"https://etcd.devstats.cncf.io/d/23/prs-authors-repository-groups?orgId=1&amp;var-period=m&amp;var-repogroup_name=All&amp;from=1422748800000&amp;to=1738454399000\">unique PR author data</a>\nwe recently hit an all time high in March and are trending in a positive direction:</p>\n<figure>\n<img alt=\"Unique PR author data stats\" src=\"https://kubernetes.io/blog/2025/03/04/sig-etcd-spotlight/stats.png\" />\n</figure>\n<p>Additionally, looking at our\n<a href=\"https://etcd.devstats.cncf.io/d/74/contributions-chart?orgId=1&amp;from=1422748800000&amp;to=1738454399000&amp;var-period=m&amp;var-metric=contributions&amp;var-repogroup_name=All&amp;var-country_name=All&amp;var-company_name=All&amp;var-company=all\">overall contributions across all etcd project repositories</a>\nwe are also observing a positive trend showing a resurgence in etcd project activity:</p>\n<figure>\n<img alt=\"Overall contributions stats\" src=\"https://kubernetes.io/blog/2025/03/04/sig-etcd-spotlight/stats2.png\" />\n</figure>\n<h2 id=\"the-road-ahead\">The road ahead</h2>\n<p><strong>Frederico: That's quite telling, thank you. In terms of the near future, what are the current\npriorities for SIG etcd?</strong></p>\n<p><strong>Marek</strong>: Reliability is always top of mind -‚Äì we need to make sure etcd is rock-solid. We're also\nworking on making etcd easier to use and manage for operators. And we have our sights set on making\netcd a viable standalone solution for infrastructure management, not just for Kubernetes. Oh, and of\ncourse, scaling -‚Äì we need to ensure etcd can handle the growing demands of the cloud-native world.</p>\n<p><strong>Benjamin</strong>: I agree that reliability should always be our top guiding principle. We need to ensure\nnot only correctness but also compatibility. Additionally, we should continuously strive to improve\nthe understandability and maintainability of etcd. Our focus should be on addressing the pain points\nthat the community cares about the most.</p>\n<p><strong>Frederico: Are there any specific SIGs that you work closely with?</strong></p>\n<p><strong>Marek</strong>: SIG API Machinery, for sure ‚Äì they own the structure of the data etcd stores, so we're\nconstantly working together. And SIG Cluster Lifecycle ‚Äì etcd is a key part of Kubernetes clusters,\nso we collaborate on the newly created etcd operator Working group.</p>\n<p><strong>Wenjia</strong>: Other than SIG API Machinery and SIG Cluster Lifecycle that Marek mentioned above, SIG\nScalability and SIG Testing is another group that we work closely with.</p>\n<p><strong>Frederico: In a more general sense, how would you list the key challenges for SIG etcd in the\nevolving cloud native landscape?</strong></p>\n<p><strong>Marek</strong>: Well, reliability is always a challenge when you're dealing with critical data. The\ncloud-native world is evolving so fast that scaling to meet those demands is a constant effort.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p><strong>Frederico: We're almost at the end of our conversation, but for those interested in in etcd, how\ncan they get involved?</strong></p>\n<p><strong>Marek</strong>: We'd love to have them! The best way to start is to join our\n<a href=\"https://github.com/kubernetes/community/blob/master/sig-etcd/README.md#meetings\">SIG etcd meetings</a>,\nfollow discussions on the <a href=\"https://groups.google.com/g/etcd-dev\">etcd-dev mailing list</a>, and check\nout our <a href=\"https://github.com/etcd-io/etcd/issues\">GitHub issues</a>. We're always looking for people to\nreview proposals, test code, and contribute to documentation.</p>\n<p><strong>Wenjia</strong>: I love this question üòÄ . There are numerous ways for people interested in contributing\nto SIG etcd to get involved and make a difference. Here are some key areas where you can help:</p>\n<p><strong>Code Contributions</strong>:</p>\n<ul>\n<li><em>Bug Fixes</em>: Tackle existing issues in the etcd codebase. Start with issues labeled &quot;good first\nissue&quot; or &quot;help wanted&quot; to find tasks that are suitable for newcomers.</li>\n<li><em>Feature Development</em>: Contribute to the development of new features and enhancements. Check the\netcd roadmap and discussions to see what's being planned and where your skills might fit in.</li>\n<li><em>Testing and Code Reviews</em>: Help ensure the quality of etcd by writing tests, reviewing code\nchanges, and providing feedback.</li>\n<li><em>Documentation</em>: Improve <a href=\"https://etcd.io/docs/\">etcd's documentation</a> by adding new content,\nclarifying existing information, or fixing errors. Clear and comprehensive documentation is\nessential for users and contributors.</li>\n<li><em>Community Support</em>: Answer questions on forums, mailing lists, or <a href=\"https://kubernetes.slack.com/archives/C3HD8ARJ5\">Slack channels</a>.\nHelping others understand and use etcd is a valuable contribution.</li>\n</ul>\n<p><strong>Getting Started</strong>:</p>\n<ul>\n<li><em>Join the community</em>: Start by joining the etcd community on Slack,\nattending SIG meetings, and following the mailing lists. This will\nhelp you get familiar with the project, its processes, and the\npeople involved.</li>\n<li><em>Find a mentor</em>: If you're new to open source or etcd, consider\nfinding a mentor who can guide you and provide support. Stay tuned!\nOur first cohort of mentorship program was very successful. We will\nhave a new round of mentorship program coming up.</li>\n<li><em>Start small</em>: Don't be afraid to start with small contributions. Even\nfixing a typo in the documentation or submitting a simple bug fix\ncan be a great way to get involved.</li>\n</ul>\n<p>By contributing to etcd, you'll not only be helping to improve a\ncritical piece of the cloud-native ecosystem but also gaining valuable\nexperience and skills. So, jump in and start contributing!</p>\n<p><strong>Frederico: Excellent, thank you. Lastly, one piece of advice that\nyou'd like to give to other newly formed SIGs?</strong></p>\n<p><strong>Marek</strong>: Absolutely! My advice would be to embrace the established\nprocesses of the larger community, prioritize collaboration with other\nSIGs, and focus on building a strong community.</p>\n<p><strong>Wenjia</strong>: Here are some tips I myself found very helpful in my OSS\njourney:</p>\n<ul>\n<li><em>Be patient</em>: Open source development can take time. Don't get\ndiscouraged if your contributions aren't accepted immediately or if\nyou encounter challenges.</li>\n<li><em>Be respectful</em>: The etcd community values collaboration and\nrespect. Be mindful of others' opinions and work together to achieve\ncommon goals.</li>\n<li><em>Have fun</em>: Contributing to open source should be\nenjoyable. Find areas that interest you and contribute in ways that\nyou find fulfilling.</li>\n</ul>\n<p><strong>Frederico: A great way to end this spotlight, thank you all!</strong></p>\n<hr />\n<p>For more information and resources, please take a look at :</p>\n<ol>\n<li>etcd website: <a href=\"https://etcd.io/\">https://etcd.io/</a></li>\n<li>etcd GitHub repository: <a href=\"https://github.com/etcd-io/etcd\">https://github.com/etcd-io/etcd</a></li>\n<li>etcd community: <a href=\"https://etcd.io/community/\">https://etcd.io/community/</a></li>\n</ol>",
      "timestamp": 1741512160.5328608,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "NFTables mode for kube-proxy",
      "link": "https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/",
      "published": "Fri, 28 Feb 2025 00:00:00 +0000",
      "summary": "<p>A new nftables mode for kube-proxy was introduced as an alpha feature\nin Kubernetes 1.29. Currently in beta, it is expected to be GA as of\n1.33. The new mode fixes long-standing performance problems with the\niptables mode and all users running on systems with reasonably-recent\nkernels are encouraged to try it out. (For compatibility reasons, even\nonce nftables becomes GA, iptables will still be the <em>default</em>.)</p>\n<h2 id=\"why-nftables-part-1-data-plane-latency\">Why nftables? Part 1: data plane latency</h2>\n<p>The iptables API was designed for implementing simple firewalls, and\nhas problems scaling up to support Service proxying in a large\nKubernetes cluster with tens of thousands of Services.</p>\n<p>In general, the ruleset generated by kube-proxy in iptables mode has a\nnumber of iptables rules proportional to the sum of the number of\nServices and the total number of endpoints. In particular, at the top\nlevel of the ruleset, there is one rule to test each possible Service\nIP (and port) that a packet might be addressed to:</p>\n<pre tabindex=\"0\"><code># If the packet is addressed to 172.30.0.41:80, then jump to the chain\n# KUBE-SVC-XPGD46QRK7WJZT7O for further processing\n-A KUBE-SERVICES -m comment --comment \"namespace1/service1:p80 cluster IP\" -m tcp -p tcp -d 172.30.0.41 --dport 80 -j KUBE-SVC-XPGD46QRK7WJZT7O\n# If the packet is addressed to 172.30.0.42:443, then...\n-A KUBE-SERVICES -m comment --comment \"namespace2/service2:p443 cluster IP\" -m tcp -p tcp -d 172.30.0.42 --dport 443 -j KUBE-SVC-GNZBNJ2PO5MGZ6GT\n# etc...\n-A KUBE-SERVICES -m comment --comment \"namespace3/service3:p80 cluster IP\" -m tcp -p tcp -d 172.30.0.43 --dport 80 -j KUBE-SVC-X27LE4BHSL4DOUIK\n</code></pre><p>This means that when a packet comes in, the time it takes the kernel\nto check it against all of the Service rules is <strong>O(n)</strong> in the number\nof Services. As the number of Services increases, both the average and\nthe worst-case latency for the first packet of a new connection\nincreases (with the difference between best-case, average, and\nworst-case being mostly determined by whether a given Service IP\naddress appears earlier or later in the <code>KUBE-SERVICES</code> chain).</p>\n<figure>\n<img alt=\"kube-proxy iptables first packet latency, at various percentiles, in clusters of various sizes\" src=\"https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/iptables-only.svg\" />\n</figure>\n<p>By contrast, with nftables, the normal way to write a ruleset like\nthis is to have a <em>single</em> rule, using a &quot;verdict map&quot; to do the\ndispatch:</p>\n<pre tabindex=\"0\"><code>table ip kube-proxy {\n# The service-ips verdict map indicates the action to take for each matching packet.\nmap service-ips {\ntype ipv4_addr . inet_proto . inet_service : verdict\ncomment \"ClusterIP, ExternalIP and LoadBalancer IP traffic\"\nelements = { 172.30.0.41 . tcp . 80 : goto service-ULMVA6XW-namespace1/service1/tcp/p80,\n172.30.0.42 . tcp . 443 : goto service-42NFTM6N-namespace2/service2/tcp/p443,\n172.30.0.43 . tcp . 80 : goto service-4AT6LBPK-namespace3/service3/tcp/p80,\n... }\n}\n# Now we just need a single rule to process all packets matching an\n# element in the map. (This rule says, \"construct a tuple from the\n# destination IP address, layer 4 protocol, and destination port; look\n# that tuple up in \"service-ips\"; and if there's a match, execute the\n# associated verdict.)\nchain services {\nip daddr . meta l4proto . th dport vmap @service-ips\n}\n...\n}\n</code></pre><p>Since there's only a single rule, with a roughly <strong>O(1)</strong> map lookup,\npacket processing time is more or less constant regardless of cluster\nsize, and the best/average/worst cases are very similar:</p>\n<figure>\n<img alt=\"kube-proxy nftables first packet latency, at various percentiles, in clusters of various sizes\" src=\"https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/nftables-only.svg\" />\n</figure>\n<p>But note the huge difference in the vertical scale between the\niptables and nftables graphs! In the clusters with 5000 and 10,000\nServices, the p50 (average) latency for nftables is about the same as\nthe p01 (approximately best-case) latency for iptables. In the 30,000\nService cluster, the p99 (approximately worst-case) latency for\nnftables manages to beat out the p01 latency for iptables by a few\nmicroseconds! Here's both sets of data together, but you may have to\nsquint to see the nftables results!:</p>\n<figure>\n<img alt=\"kube-proxy iptables-vs-nftables first packet latency, at various percentiles, in clusters of various sizes\" src=\"https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/iptables-vs-nftables.svg\" />\n</figure>\n<h2 id=\"why-nftables-part-2-control-plane-latency\">Why nftables? Part 2: control plane latency</h2>\n<p>While the improvements to data plane latency in large clusters are\ngreat, there's another problem with iptables kube-proxy that often\nkeeps users from even being able to grow their clusters to that size:\nthe time it takes kube-proxy to program new iptables rules when\nServices and their endpoints change.</p>\n<p>With both iptables and nftables, the total size of the ruleset as a\nwhole (actual rules, plus associated data) is <strong>O(n)</strong> in the combined\nnumber of Services and their endpoints. Originally, the iptables\nbackend would rewrite every rule on every update, and with tens of\nthousands of Services, this could grow to be hundreds of thousands of\niptables rules. Starting in Kubernetes 1.26, we began improving\nkube-proxy so that it could skip updating <em>most</em> of the unchanged\nrules in each update, but the limitations of <code>iptables-restore</code> as an\nAPI meant that it was still always necessary to send an update that's\n<strong>O(n)</strong> in the number of Services (though with a noticeably smaller\nconstant than it used to be). Even with those optimizations, it can\nstill be necessary to make use of kube-proxy's <code>minSyncPeriod</code> config\noption to ensure that it doesn't spend every waking second trying to\npush iptables updates.</p>\n<p>The nftables APIs allow for doing much more incremental updates, and\nwhen kube-proxy in nftables mode does an update, the size of the\nupdate is only <strong>O(n)</strong> in the number of Services and endpoints that\nhave changed since the last sync, regardless of the total number of\nServices and endpoints. The fact that the nftables API allows each\nnftables-using component to have its own private table also means that\nthere is no global lock contention between components like with\niptables. As a result, kube-proxy's nftables updates can be done much\nmore efficiently than with iptables.</p>\n<p>(Unfortunately I don't have cool graphs for this part.)</p>\n<h2 id=\"why-not-nftables\">Why <em>not</em> nftables?</h2>\n<p>All that said, there are a few reasons why you might not want to jump\nright into using the nftables backend for now.</p>\n<p>First, the code is still fairly new. While it has plenty of unit\ntests, performs correctly in our CI system, and has now been used in\nthe real world by multiple users, it has not seen anything close to as\nmuch real-world usage as the iptables backend has, so we can't promise\nthat it is as stable and bug-free.</p>\n<p>Second, the nftables mode will not work on older Linux distributions;\ncurrently it requires a 5.13 or newer kernel. Additionally, because of\nbugs in early versions of the <code>nft</code> command line tool, you should not\nrun kube-proxy in nftables mode on nodes that have an old (earlier\nthan 1.0.0) version of <code>nft</code> in the host filesystem (or else\nkube-proxy's use of nftables may interfere with other uses of nftables\non the system).</p>\n<p>Third, you may have other networking components in your cluster, such\nas the pod network or NetworkPolicy implementation, that do not yet\nsupport kube-proxy in nftables mode. You should consult the\ndocumentation (or forums, bug tracker, etc.) for any such components\nto see if they have problems with nftables mode. (In many cases they\nwill not; as long as they don't try to directly interact with or\noverride kube-proxy's iptables rules, they shouldn't care whether\nkube-proxy is using iptables or nftables.) Additionally, observability\nand monitoring tools that have not been updated may report less data\nfor kube-proxy in nftables mode than they do for kube-proxy in\niptables mode.</p>\n<p>Finally, kube-proxy in nftables mode is intentionally not 100%\ncompatible with kube-proxy in iptables mode. There are a few old\nkube-proxy features whose default behaviors are less secure, less\nperformant, or less intuitive than we'd like, but where we felt that\nchanging the default would be a compatibility break. Since the\nnftables mode is opt-in, this gave us a chance to fix those bad\ndefaults without breaking users who weren't expecting changes. (In\nparticular, with nftables mode, NodePort Services are now only\nreachable on their nodes' default IPs, as opposed to being reachable\non all IPs, including <code>127.0.0.1</code>, with iptables mode.) The\n<a href=\"https://kubernetes.io/docs/reference/networking/virtual-ips/#migrating-from-iptables-mode-to-nftables\">kube-proxy documentation</a> has more information about this, including\ninformation about metrics you can look at to determine if you are\nrelying on any of the changed functionality, and what configuration\noptions are available to get more backward-compatible behavior.</p>\n<h2 id=\"trying-out-nftables-mode\">Trying out nftables mode</h2>\n<p>Ready to try it out? In Kubernetes 1.31 and later, you just need to\npass <code>--proxy-mode nftables</code> to kube-proxy (or set <code>mode: nftables</code> in\nyour kube-proxy config file).</p>\n<p>If you are using kubeadm to set up your cluster, the kubeadm\ndocumentation explains <a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/control-plane-flags/#customizing-kube-proxy\">how to pass a <code>KubeProxyConfiguration</code> to\n<code>kubeadm init</code></a>. You can also <a href=\"https://kind.sigs.k8s.io/docs/user/configuration/#kube-proxy-mode\">deploy nftables-based clusters with\n<code>kind</code></a>.</p>\n<p>You can also convert existing clusters from iptables (or ipvs) mode to\nnftables by updating the kube-proxy configuration and restarting the\nkube-proxy pods. (You do not need to reboot the nodes: when restarting\nin nftables mode, kube-proxy will delete any existing iptables or ipvs\nrules, and likewise, if you later revert back to iptables or ipvs\nmode, it will delete any existing nftables rules.)</p>\n<h2 id=\"future-plans\">Future plans</h2>\n<p>As mentioned above, while nftables is now the <em>best</em> kube-proxy mode,\nit is not the <em>default</em>, and we do not yet have a plan for changing\nthat. We will continue to support the iptables mode for a long time.</p>\n<p>The future of the IPVS mode of kube-proxy is less certain: its main\nadvantage over iptables was that it was faster, but certain aspects of\nthe IPVS architecture and APIs were awkward for kube-proxy's purposes\n(for example, the fact that the <code>kube-ipvs0</code> device needs to have\n<em>every</em> Service IP address assigned to it), and some parts of\nKubernetes Service proxying semantics were difficult to implement\nusing IPVS (particularly the fact that some Services had to have\ndifferent endpoints depending on whether you connected to them from a\nlocal or remote client). And now, the nftables mode has the same\nperformance as IPVS mode (actually, slightly better), without any of\nthe downsides:</p>\n<figure>\n<img alt=\"kube-proxy ipvs-vs-nftables first packet latency, at various percentiles, in clusters of various sizes\" src=\"https://kubernetes.io/blog/2025/02/28/nftables-kube-proxy/ipvs-vs-nftables.svg\" />\n</figure>\n<p>(In theory the IPVS mode also has the advantage of being able to use\nvarious other IPVS functionality, like alternative &quot;schedulers&quot; for\nbalancing endpoints. In practice, this ended up not being very useful,\nbecause kube-proxy runs independently on every node, and the IPVS\nschedulers on each node had no way of sharing their state with the\nproxies on other nodes, thus thwarting the effort to balance traffic\nmore cleverly.)</p>\n<p>While the Kubernetes project does not have an immediate plan to drop\nthe IPVS backend, it is probably doomed in the long run, and people\nwho are currently using IPVS mode should try out the nftables mode\ninstead (and file bugs if you think there is missing functionality in\nnftables mode that you can't work around).</p>\n<h2 id=\"learn-more\">Learn more</h2>\n<ul>\n<li>\n<p>&quot;<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/3866-nftables-proxy/README.md\">KEP-3866: Add an nftables-based kube-proxy backend</a>&quot; has the\nhistory of the new feature.</p>\n</li>\n<li>\n<p>&quot;<a href=\"https://youtu.be/yOGHb2HjslY?si=6O4PVJu7fGpReo1U\">How the Tables Have Turned: Kubernetes Says Goodbye to IPTables</a>&quot;,\nfrom KubeCon/CloudNativeCon North America 2024, talks about porting\nkube-proxy and Calico from iptables to nftables.</p>\n</li>\n<li>\n<p>&quot;<a href=\"https://youtu.be/uYo2O3jbJLk?si=py2AXzMJZ4PuhxNg\">From Observability to Performance</a>&quot;, from KubeCon/CloudNativeCon\nNorth America 2024. (This is where the kube-proxy latency data came\nfrom; the <a href=\"https://docs.google.com/spreadsheets/d/1-ryDNc6gZocnMHEXC7mNtqknKSOv5uhXFKDx8Hu3AYA/edit\">raw data for the charts</a> is also available.)</p>\n</li>\n</ul>",
      "timestamp": 1741512160.5328658,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "The Cloud Controller Manager Chicken and Egg Problem",
      "link": "https://kubernetes.io/blog/2025/02/14/cloud-controller-manager-chicken-egg-problem/",
      "published": "Fri, 14 Feb 2025 00:00:00 +0000",
      "summary": "<p>Kubernetes 1.31\n<a href=\"https://kubernetes.io/blog/2024/05/20/completing-cloud-provider-migration/\">completed the largest migration in Kubernetes history</a>, removing the in-tree\ncloud provider. While the component migration is now done, this leaves some additional\ncomplexity for users and installer projects (for example, kOps or Cluster API) . We will go\nover those additional steps and failure points and make recommendations for cluster owners.\nThis migration was complex and some logic had to be extracted from the core components,\nbuilding four new subsystems.</p>\n<ol>\n<li><strong>Cloud controller manager</strong> (<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/2392-cloud-controller-manager/README.md\">KEP-2392</a>)</li>\n<li><strong>API server network proxy</strong> (<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-api-machinery/1281-network-proxy\">KEP-1281</a>)</li>\n<li><strong>kubelet credential provider plugins</strong> (<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2133-kubelet-credential-providers\">KEP-2133</a>)</li>\n<li><strong>Storage migration to use <a href=\"https://github.com/container-storage-interface/spec?tab=readme-ov-file#container-storage-interface-csi-specification-\">CSI</a></strong> (<a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/625-csi-migration/README.md\">KEP-625</a>)</li>\n</ol>\n<p>The <a href=\"https://kubernetes.io/docs/concepts/architecture/cloud-controller/\">cloud controller manager is part of the control plane</a>. It is a critical component\nthat replaces some functionality that existed previously in the kube-controller-manager and the\nkubelet.</p>\n<figure>\n<img alt=\"Components of Kubernetes\" src=\"https://kubernetes.io/images/docs/components-of-kubernetes.svg\" /> <figcaption>\n<p>Components of Kubernetes</p>\n</figcaption>\n</figure>\n<p>One of the most critical functionalities of the cloud controller manager is the node controller,\nwhich is responsible for the initialization of the nodes.</p>\n<p>As you can see in the following diagram, when the <strong>kubelet</strong> starts, it registers the Node\nobject with the apiserver, Tainting the node so it can be processed first by the\ncloud-controller-manager. The initial Node is missing the cloud-provider specific information,\nlike the Node Addresses and the Labels with the cloud provider specific information like the\nNode, Region and Instance type information.</p>\n<figure class=\"diagram-medium \">\n<img alt=\"Chicken and egg problem sequence diagram\" src=\"https://kubernetes.io/blog/2025/02/14/cloud-controller-manager-chicken-egg-problem/ccm-chicken-egg-problem-sequence-diagram.svg\" /> <figcaption>\n<p>Chicken and egg problem sequence diagram</p>\n</figcaption>\n</figure>\n<p>This new initialization process adds some latency to the node readiness. Previously, the kubelet\nwas able to initialize the node at the same time it created the node. Since the logic has moved\nto the cloud-controller-manager, this can cause a <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#chicken-and-egg\">chicken and egg problem</a>\nduring the cluster bootstrapping for those Kubernetes architectures that do not deploy the\ncontroller manager as the other components of the control plane, commonly as static pods,\nstandalone binaries or daemonsets/deployments with tolerations to the taints and using\n<code>hostNetwork</code> (more on this below)</p>\n<h2 id=\"examples-of-the-dependency-problem\">Examples of the dependency problem</h2>\n<p>As noted above, it is possible during bootstrapping for the cloud-controller-manager to be\nunschedulable and as such the cluster will not initialize properly. The following are a few\nconcrete examples of how this problem can be expressed and the root causes for why they might\noccur.</p>\n<p>These examples assume you are running your cloud-controller-manager using a Kubernetes resource\n(e.g. Deployment, DaemonSet, or similar) to control its lifecycle. Because these methods\nrely on Kubernetes to schedule the cloud-controller-manager, care must be taken to ensure it\nwill schedule properly.</p>\n<h3 id=\"example-cloud-controller-manager-not-scheduling-due-to-uninitialized-taint\">Example: Cloud controller manager not scheduling due to uninitialized taint</h3>\n<p>As <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/#running-cloud-controller-manager\">noted in the Kubernetes documentation</a>, when the kubelet is started with the command line\nflag <code>--cloud-provider=external</code>, its corresponding <code>Node</code> object will have a no schedule taint\nnamed <code>node.cloudprovider.kubernetes.io/uninitialized</code> added. Because the cloud-controller-manager\nis responsible for removing the no schedule taint, this can create a situation where a\ncloud-controller-manager that is being managed by a Kubernetes resource, such as a <code>Deployment</code>\nor <code>DaemonSet</code>, may not be able to schedule.</p>\n<p>If the cloud-controller-manager is not able to be scheduled during the initialization of the\ncontrol plane, then the resulting <code>Node</code> objects will all have the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> no schedule taint. It also means that this taint\nwill not be removed as the cloud-controller-manager is responsible for its removal. If the no\nschedule taint is not removed, then critical workloads, such as the container network interface\ncontrollers, will not be able to schedule, and the cluster will be left in an unhealthy state.</p>\n<h3 id=\"example-cloud-controller-manager-not-scheduling-due-to-not-ready-taint\">Example: Cloud controller manager not scheduling due to not-ready taint</h3>\n<p>The next example would be possible in situations where the container network interface (CNI) is\nwaiting for IP address information from the cloud-controller-manager (CCM), and the CCM has not\ntolerated the taint which would be removed by the CNI.</p>\n<p>The <a href=\"https://kubernetes.io/docs/reference/labels-annotations-taints/#node-kubernetes-io-not-ready\">Kubernetes documentation describes</a> the <code>node.kubernetes.io/not-ready</code> taint as follows:</p>\n<blockquote>\n<p>&quot;The Node controller detects whether a Node is ready by monitoring its health and adds or removes this taint accordingly.&quot;</p>\n</blockquote>\n<p>One of the conditions that can lead to a Node resource having this taint is when the container\nnetwork has not yet been initialized on that node. As the cloud-controller-manager is responsible\nfor adding the IP addresses to a Node resource, and the IP addresses are needed by the container\nnetwork controllers to properly configure the container network, it is possible in some\ncircumstances for a node to become stuck as not ready and uninitialized permanently.</p>\n<p>This situation occurs for a similar reason as the first example, although in this case, the\n<code>node.kubernetes.io/not-ready</code> taint is used with the no execute effect and thus will cause the\ncloud-controller-manager not to run on the node with the taint. If the cloud-controller-manager is\nnot able to execute, then it will not initialize the node. It will cascade into the container\nnetwork controllers not being able to run properly, and the node will end up carrying both the\n<code>node.cloudprovider.kubernetes.io/uninitialized</code> and <code>node.kubernetes.io/not-ready</code> taints,\nleaving the cluster in an unhealthy state.</p>\n<h2 id=\"our-recommendations\">Our Recommendations</h2>\n<p>There is no one ‚Äúcorrect way‚Äù to run a cloud-controller-manager. The details will depend on the\nspecific needs of the cluster administrators and users. When planning your clusters and the\nlifecycle of the cloud-controller-managers please consider the following guidance:</p>\n<p>For cloud-controller-managers running in the same cluster, they are managing.</p>\n<ol>\n<li>Use host network mode, rather than the pod network: in most cases, a cloud controller manager\nwill need to communicate with an API service endpoint associated with the infrastructure.\nSetting ‚ÄúhostNetwork‚Äù to true will ensure that the cloud controller is using the host\nnetworking instead of the container network and, as such, will have the same network access as\nthe host operating system. It will also remove the dependency on the networking plugin. This\nwill ensure that the cloud controller has access to the infrastructure endpoint (always check\nyour networking configuration against your infrastructure provider‚Äôs instructions).</li>\n<li>Use a scalable resource type. <code>Deployments</code> and <code>DaemonSets</code> are useful for controlling the\nlifecycle of a cloud controller. They allow easy access to running multiple copies for redundancy\nas well as using the Kubernetes scheduling to ensure proper placement in the cluster. When using\nthese primitives to control the lifecycle of your cloud controllers and running multiple\nreplicas, you must remember to enable leader election, or else your controllers will collide\nwith each other which could lead to nodes not being initialized in the cluster.</li>\n<li>Target the controller manager containers to the control plane. There might exist other\ncontrollers which need to run outside the control plane (for example, Azure‚Äôs node manager\ncontroller). Still, the controller managers themselves should be deployed to the control plane.\nUse a node selector or affinity stanza to direct the scheduling of cloud controllers to the\ncontrol plane to ensure that they are running in a protected space. Cloud controllers are vital\nto adding and removing nodes to a cluster as they form a link between Kubernetes and the\nphysical infrastructure. Running them on the control plane will help to ensure that they run\nwith a similar priority as other core cluster controllers and that they have some separation\nfrom non-privileged user workloads.\n<ol>\n<li>It is worth noting that an anti-affinity stanza to prevent cloud controllers from running\non the same host is also very useful to ensure that a single node failure will not degrade\nthe cloud controller performance.</li>\n</ol>\n</li>\n<li>Ensure that the tolerations allow operation. Use tolerations on the manifest for the cloud\ncontroller container to ensure that it will schedule to the correct nodes and that it can run\nin situations where a node is initializing. This means that cloud controllers should tolerate\nthe <code>node.cloudprovider.kubernetes.io/uninitialized</code> taint, and it should also tolerate any\ntaints associated with the control plane (for example, <code>node-role.kubernetes.io/control-plane</code>\nor <code>node-role.kubernetes.io/master</code>). It can also be useful to tolerate the\n<code>node.kubernetes.io/not-ready</code> taint to ensure that the cloud controller can run even when the\nnode is not yet available for health monitoring.</li>\n</ol>\n<p>For cloud-controller-managers that will not be running on the cluster they manage (for example,\nin a hosted control plane on a separate cluster), then the rules are much more constrained by the\ndependencies of the environment of the cluster running the cloud-controller-manager. The advice\nfor running on a self-managed cluster may not be appropriate as the types of conflicts and network\nconstraints will be different. Please consult the architecture and requirements of your topology\nfor these scenarios.</p>\n<h3 id=\"example\">Example</h3>\n<p>This is an example of a Kubernetes Deployment highlighting the guidance shown above. It is\nimportant to note that this is for demonstration purposes only, for production uses please\nconsult your cloud provider‚Äôs documentation.</p>\n<pre tabindex=\"0\"><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nname: cloud-controller-manager\nnamespace: kube-system\nspec:\nreplicas: 2\nselector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\nstrategy:\ntype: Recreate\ntemplate:\nmetadata:\nlabels:\napp.kubernetes.io/name: cloud-controller-manager\nannotations:\nkubernetes.io/description: Cloud controller manager for my infrastructure\nspec:\ncontainers: # the container details will depend on your specific cloud controller manager\n- name: cloud-controller-manager\ncommand:\n- /bin/my-infrastructure-cloud-controller-manager\n- --leader-elect=true\n- -v=1\nimage: registry/my-infrastructure-cloud-controller-manager@latest\nresources:\nrequests:\ncpu: 200m\nmemory: 50Mi\nhostNetwork: true # these Pods are part of the control plane\nnodeSelector:\nnode-role.kubernetes.io/control-plane: \"\"\naffinity:\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- topologyKey: \"kubernetes.io/hostname\"\nlabelSelector:\nmatchLabels:\napp.kubernetes.io/name: cloud-controller-manager\ntolerations:\n- effect: NoSchedule\nkey: node-role.kubernetes.io/master\noperator: Exists\n- effect: NoExecute\nkey: node.kubernetes.io/unreachable\noperator: Exists\ntolerationSeconds: 120\n- effect: NoExecute\nkey: node.kubernetes.io/not-ready\noperator: Exists\ntolerationSeconds: 120\n- effect: NoSchedule\nkey: node.cloudprovider.kubernetes.io/uninitialized\noperator: Exists\n- effect: NoSchedule\nkey: node.kubernetes.io/not-ready\noperator: Exists\n</code></pre><p>When deciding how to deploy your cloud controller manager it is worth noting that\ncluster-proportional, or resource-based, pod autoscaling is not recommended. Running multiple\nreplicas of a cloud controller manager is good practice for ensuring high-availability and\nredundancy, but does not contribute to better performance. In general, only a single instance\nof a cloud controller manager will be reconciling a cluster at any given time.</p>",
      "timestamp": 1741512160.5328698,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Spotlight on SIG Architecture: Enhancements",
      "link": "https://kubernetes.io/blog/2025/01/21/sig-architecture-enhancements/",
      "published": "Tue, 21 Jan 2025 00:00:00 +0000",
      "summary": "<p><em>This is the fourth interview of a SIG Architecture Spotlight series that will cover the different\nsubprojects, and we will be covering <a href=\"https://github.com/kubernetes/community/blob/master/sig-architecture/README.md#enhancements\">SIG Architecture:\nEnhancements</a>.</em></p>\n<p>In this SIG Architecture spotlight we talked with <a href=\"https://github.com/kikisdeliveryservice\">Kirsten\nGarrison</a>, lead of the Enhancements subproject.</p>\n<h2 id=\"the-enhancements-subproject\">The Enhancements subproject</h2>\n<p><strong>Frederico (FSM): Hi Kirsten, very happy to have the opportunity to talk about the Enhancements\nsubproject. Let's start with some quick information about yourself and your role.</strong></p>\n<p><strong>Kirsten Garrison (KG)</strong>: I‚Äôm a lead of the Enhancements subproject of SIG-Architecture and\ncurrently work at Google. I first got involved by contributing to the service-catalog project with\nthe help of <a href=\"https://github.com/carolynvs\">Carolyn Van Slyck</a>. With time, <a href=\"https://github.com/kubernetes/sig-release/blob/master/releases/release-1.17/release_team.md\">I joined the Release\nteam</a>,\neventually becoming the Enhancements Lead and a Release Lead shadow. While on the release team, I\nworked on some ideas to make the process better for the SIGs and Enhancements team (the opt-in\nprocess) based on my team‚Äôs experiences. Eventually, I started attending Subproject meetings and\ncontributing to the Subproject‚Äôs work.</p>\n<p><strong>FSM: You mentioned the Enhancements subproject: how would you describe its main goals and areas of\nintervention?</strong></p>\n<p><strong>KG</strong>: The <a href=\"https://github.com/kubernetes/community/blob/master/sig-architecture/README.md#enhancements\">Enhancements\nSubproject</a>\nprimarily concerns itself with the <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-architecture/0000-kep-process/README.md\">Kubernetes Enhancement\nProposal</a>\n(<em>KEP</em> for short)‚Äîthe &quot;design&quot; documents required for all features and significant changes\nto the Kubernetes project.</p>\n<h2 id=\"the-kep-and-its-impact\">The KEP and its impact</h2>\n<p><strong>FSM: The improvement of the KEP process was (and is) one in which SIG Architecture was heavily\ninvolved. Could you explain the process to those that aren‚Äôt aware of it?</strong></p>\n<p><strong>KG</strong>: <a href=\"https://kubernetes.io/releases/release/#the-release-cycle\">Every release</a>, the SIGs let the\nRelease Team know which features they intend to work on to be put into the release. As mentioned\nabove, the prerequisite for these changes is a KEP - a standardized design document that all authors\nmust fill out and approve in the first weeks of the release cycle. Most features <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/#feature-stages\">will move\nthrough 3\nphases</a>:\nalpha, beta and finally GA so approving a feature represents a significant commitment for the SIG.</p>\n<p>The KEP serves as the full source of truth of a feature. The <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/NNNN-kep-template/README.md\">KEP\ntemplate</a>\nhas different requirements based on what stage a feature is in, but it generally requires a detailed\ndiscussion of the design and the impact as well as providing artifacts of stability and\nperformance. The KEP takes quite a bit of iterative work between authors, SIG reviewers, api review\nteam and the Production Readiness Review team<sup id=\"fnref:1\"><a class=\"footnote-ref\" href=\"https://kubernetes.io/feed.xml#fn:1\">1</a></sup> before it is approved. Each set of reviewers is\nlooking to make sure that the proposal meets their standards in order to have a stable and\nperformant Kubernetes release. Only after all approvals are secured, can an author go forth and\nmerge their feature in the Kubernetes code base.</p>\n<p><strong>FSM: I see, quite a bit of additional structure was added. Looking back, what were the most\nsignificant improvements of that approach?</strong></p>\n<p><strong>KG</strong>: In general, I think that the improvements with the most impact had to do with focusing on\nthe core intent of the KEP. KEPs exist not just to memorialize designs, but provide a structured way\nto discuss and come to an agreement about different facets of the change. At the core of the KEP\nprocess is communication and consideration.</p>\n<p>To that end, some of the significant changes revolve around a more detailed and accessible KEP\ntemplate. A significant amount of work was put in over time to get the\n<a href=\"https://github.com/kubernetes/enhancements\">k/enhancements</a> repo into its current form -- a\ndirectory structure organized by SIG with the contours of the modern KEP template (with\nProposal/Motivation/Design Details subsections). We might take that basic structure for granted\ntoday, but it really represents the work of many people trying to get the foundation of this process\nin place over time.</p>\n<p>As Kubernetes matures, we‚Äôve needed to think about more than just the end goal of getting a single\nfeature merged. We need to think about things like: stability, performance, setting and meeting user\nexpectations. And as we‚Äôve thought about those things the template has grown more detailed. The\naddition of the Production Readiness Review was major as well as the enhanced testing requirements\n(varying at different stages of a KEP‚Äôs lifecycle).</p>\n<h2 id=\"current-areas-of-focus\">Current areas of focus</h2>\n<p><strong>FSM: Speaking of maturing, we‚Äôve <a href=\"https://kubernetes.io/blog/2024/08/13/kubernetes-v1-31-release/\">recently released Kubernetes\nv1.31</a>, and work on v1.32 <a href=\"https://github.com/fsmunoz/sig-release/tree/release-1.32/releases/release-1.32\">has\nstarted</a>. Are there\nany areas that the Enhancements sub-project is currently addressing that might change the way things\nare done?</strong></p>\n<p><strong>KG</strong>: We‚Äôre currently working on two things:</p>\n<ol>\n<li><em>Creating a Process KEP template.</em> Sometimes people want to harness the KEP process for\nsignificant changes that are more process oriented rather than feature oriented. We want to\nsupport this because memorializing changes is important and giving people a better tool to do so\nwill only encourage more discussion and transparency.</li>\n<li><em>KEP versioning.</em> While our template changes aim to be as non-disruptive as possible, we\nbelieve that it will be easier to track and communicate those changes to the community better with\na versioned KEP template and the policies that go alongside such versioning.</li>\n</ol>\n<p>Both features will take some time to get right and fully roll out (just like a KEP feature) but we\nbelieve that they will both provide improvements that will benefit the community at large.</p>\n<p><strong>FSM: You mentioned improvements: I remember when project boards for Enhancement tracking were\nintroduced in recent releases, to great effect and unanimous applause from release team members. Was\nthis a particular area of focus for the subproject?</strong></p>\n<p><strong>KG</strong>: The Subproject provided support to the Release Team‚Äôs Enhancement team in the migration away\nfrom using the spreadsheet to a project board. The collection and tracking of enhancements has\nalways been a logistical challenge. During my time on the Release Team, I helped with the transition\nto an opt-in system of enhancements, whereby the SIG leads &quot;opt-in&quot; KEPs for release tracking. This\nhelped to enhance communication between authors and SIGs before any significant work was undertaken\non a KEP and removed toil from the Enhancements team. This change used the existing tools to avoid\nintroducing too many changes at once to the community. Later, the Release Team approached the\nSubproject with an idea of leveraging GitHub Project Boards to further improve the collection\nprocess. This was to be a move away from the use of complicated spreadsheets to using repo-native\nlabels on <a href=\"https://github.com/kubernetes/enhancements\">k/enhancement</a> issues and project boards.</p>\n<p><strong>FSM: That surely adds an impact on simplifying the workflow...</strong></p>\n<p><strong>KG</strong>: Removing sources of friction and promoting clear communication is very important to the\nEnhancements Subproject. At the same time, it‚Äôs important to give careful consideration to\ndecisions that impact the community as a whole. We want to make sure that changes are balanced to\ngive an upside and while not causing any regressions and pain in the rollout. We supported the\nRelease Team in ideation as well as through the actual migration to the project boards. It was a\ngreat success and exciting to see the team make high impact changes that helped everyone involved in\nthe KEP process!</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p><strong>FSM: For those reading that might be curious and interested in helping, how would you describe the\nrequired skills for participating in the sub-project?</strong></p>\n<p><strong>KG</strong>: Familiarity with KEPs either via experience or taking time to look through the\nkubernetes/enhancements repo is helpful. All are welcome to participate if interested - we can take\nit from there.</p>\n<p><strong>FSM: Excellent! Many thanks for your time and insight -- any final comments you would like to\nshare with our readers?</strong></p>\n<p><strong>KG</strong>: The Enhancements process is one of the most important parts of Kubernetes and requires\nenormous amounts of coordination and collaboration of people and teams across the project to make it\nsuccessful. I‚Äôm thankful and inspired by everyone‚Äôs continued hard work and dedication to making the\nproject great. This is truly a wonderful community.</p>\n<div class=\"footnotes\">\n<hr />\n<ol>\n<li id=\"fn:1\">\n<p>For more information, check the <a href=\"https://kubernetes.io/blog/2023/11/02/sig-architecture-production-readiness-spotlight-2023/\">Production Readiness Review spotlight\ninterview</a>\nin this series.&#160;<a class=\"footnote-backref\" href=\"https://kubernetes.io/feed.xml#fnref:1\">&#x21a9;&#xfe0e;</a></p>\n</li>\n</ol>\n</div>",
      "timestamp": 1741512160.5328739,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Kubernetes 1.32: Moving Volume Group Snapshots to Beta",
      "link": "https://kubernetes.io/blog/2024/12/18/kubernetes-1-32-volume-group-snapshot-beta/",
      "published": "Wed, 18 Dec 2024 00:00:00 +0000",
      "summary": "<p>Volume group snapshots were <a href=\"https://kubernetes.io/blog/2023/05/08/kubernetes-1-27-volume-group-snapshot-alpha/\">introduced</a>\nas an Alpha feature with the Kubernetes 1.27 release.\nThe recent release of Kubernetes v1.32 moved that support to <strong>beta</strong>.\nThe support for volume group snapshots relies on a set of\n<a href=\"https://kubernetes-csi.github.io/docs/group-snapshot-restore-feature.html#volume-group-snapshot-apis\">extension APIs for group snapshots</a>.\nThese APIs allow users to take crash consistent snapshots for a set of volumes.\nBehind the scenes, Kubernetes uses a label selector to group multiple PersistentVolumeClaims\nfor snapshotting.\nA key aim is to allow you restore that set of snapshots to new volumes and\nrecover your workload based on a crash consistent recovery point.</p>\n<p>This new feature is only supported for <a href=\"https://kubernetes-csi.github.io/docs/\">CSI</a> volume drivers.</p>\n<h2 id=\"an-overview-of-volume-group-snapshots\">An overview of volume group snapshots</h2>\n<p>Some storage systems provide the ability to create a crash consistent snapshot of\nmultiple volumes. A group snapshot represents <em>copies</em> made from multiple volumes, that\nare taken at the same point-in-time. A group snapshot can be used either to rehydrate\nnew volumes (pre-populated with the snapshot data) or to restore existing volumes to\na previous state (represented by the snapshots).</p>\n<h2 id=\"why-add-volume-group-snapshots-to-kubernetes\">Why add volume group snapshots to Kubernetes?</h2>\n<p>The Kubernetes volume plugin system already provides a powerful abstraction that\nautomates the provisioning, attaching, mounting, resizing, and snapshotting of block\nand file storage.</p>\n<p>Underpinning all these features is the Kubernetes goal of workload portability:\nKubernetes aims to create an abstraction layer between distributed applications and\nunderlying clusters so that applications can be agnostic to the specifics of the\ncluster they run on and application deployment requires no cluster specific knowledge.</p>\n<p>There was already a <a href=\"https://kubernetes.io/docs/concepts/storage/volume-snapshots/\">VolumeSnapshot</a> API\nthat provides the ability to take a snapshot of a persistent volume to protect against\ndata loss or data corruption. However, there are other snapshotting functionalities\nnot covered by the VolumeSnapshot API.</p>\n<p>Some storage systems support consistent group snapshots that allow a snapshot to be\ntaken from multiple volumes at the same point-in-time to achieve write order consistency.\nThis can be useful for applications that contain multiple volumes. For example,\nan application may have data stored in one volume and logs stored in another volume.\nIf snapshots for the data volume and the logs volume are taken at different times,\nthe application will not be consistent and will not function properly if it is restored\nfrom those snapshots when a disaster strikes.</p>\n<p>It is true that you can quiesce the application first, take an individual snapshot from\neach volume that is part of the application one after the other, and then unquiesce the\napplication after all the individual snapshots are taken. This way, you would get\napplication consistent snapshots.</p>\n<p>However, sometimes the application quiesce can be so time consuming that you want to do it less frequently,\nor it may not be possible to quiesce an application at all.\nFor example, a user may want to run weekly backups with application quiesce\nand nightly backups without application quiesce but with consistent group support which\nprovides crash consistency across all volumes in the group.</p>\n<h2 id=\"kubernetes-apis-for-volume-group-snapshots\">Kubernetes APIs for volume group snapshots</h2>\n<p>Kubernetes' support for <em>volume group snapshots</em> relies on three API kinds that\nare used\nfor managing snapshots:</p>\n<dl>\n<dt>VolumeGroupSnapshot</dt>\n<dd>Created by a Kubernetes user (or perhaps by your own automation) to request\ncreation of a volume group snapshot for multiple persistent volume claims.\nIt contains information about the volume group snapshot operation such as the\ntimestamp when the volume group snapshot was taken and whether it is ready to use.\nThe creation and deletion of this object represents a desire to create or delete a\ncluster resource (a group snapshot).</dd>\n<dt>VolumeGroupSnapshotContent</dt>\n<dd>Created by the snapshot controller for a dynamically created VolumeGroupSnapshot.\nIt contains information about the volume group snapshot including the volume group\nsnapshot ID.\nThis object represents a provisioned resource on the cluster (a group snapshot).\nThe VolumeGroupSnapshotContent object binds to the VolumeGroupSnapshot for which it\nwas created with a one-to-one mapping.</dd>\n<dt>VolumeGroupSnapshotClass</dt>\n<dd>Created by cluster administrators to describe how volume group snapshots should be\ncreated, including the driver information, the deletion policy, etc.</dd>\n</dl>\n<p>These three API kinds are defined as\n<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">CustomResourceDefinitions</a>\n(CRDs).\nThese CRDs must be installed in a Kubernetes cluster for a CSI Driver to support\nvolume group snapshots.</p>\n<h2 id=\"what-components-are-needed-to-support-volume-group-snapshots\">What components are needed to support volume group snapshots</h2>\n<p>Volume group snapshots are implemented in the\n<a href=\"https://github.com/kubernetes-csi/external-snapshotter\">external-snapshotter</a> repository.\nImplementing volume group snapshots meant adding or changing several components:</p>\n<ul>\n<li>Added new CustomResourceDefinitions for VolumeGroupSnapshot and two supporting APIs.</li>\n<li>Volume group snapshot controller logic is added to the common snapshot controller.</li>\n<li>Adding logic to make CSI calls into the snapshotter sidecar controller.</li>\n</ul>\n<p>The volume snapshot controller and CRDs are deployed once per\ncluster, while the sidecar is bundled with each CSI driver.</p>\n<p>Therefore, it makes sense to deploy the volume snapshot controller and CRDs as a cluster addon.</p>\n<p>The Kubernetes project recommends that Kubernetes distributors\nbundle and deploy the volume snapshot controller and CRDs as part\nof their Kubernetes cluster management process (independent of any CSI Driver).</p>\n<h2 id=\"what-s-new-in-beta\">What's new in Beta?</h2>\n<ul>\n<li>\n<p>The VolumeGroupSnapshot feature in CSI spec moved to GA in the <a href=\"https://github.com/container-storage-interface/spec/releases/tag/v1.11.0\">v1.11.0 release</a>.</p>\n</li>\n<li>\n<p>The snapshot validation webhook was deprecated in external-snapshotter v8.0.0 and it is now removed.\nMost of the validation webhook logic was added as validation rules into the CRDs.\nMinimum required Kubernetes version is 1.25 for these validation rules.\nOne thing in the validation webhook not moved to CRDs is the prevention of creating\nmultiple default volume snapshot classes and multiple default volume group snapshot classes\nfor the same CSI driver.\nWith the removal of the validation webhook, an error will still be raised when dynamically\nprovisioning a VolumeSnapshot or VolumeGroupSnapshot when multiple default volume snapshot\nclasses or multiple default volume group snapshot classes for the same CSI driver exist.</p>\n</li>\n<li>\n<p>The <code>enable-volumegroup-snapshot</code> flag in the snapshot-controller and the CSI snapshotter\nsidecar has been replaced by a feature gate.\nSince VolumeGroupSnapshot is a new API, the feature moves to Beta but the feature gate is\ndisabled by default.\nTo use this feature, enable the feature gate by adding the flag <code>--feature-gates=CSIVolumeGroupSnapshot=true</code>\nwhen starting the snapshot-controller and the CSI snapshotter sidecar.</p>\n</li>\n<li>\n<p>The logic to dynamically create the VolumeGroupSnapshot and its corresponding individual\nVolumeSnapshot and VolumeSnapshotContent objects are moved from the CSI snapshotter to the common\nsnapshot-controller.\nNew RBAC rules are added to the common snapshot-controller and some RBAC rules are removed from\nthe CSI snapshotter sidecar accordingly.</p>\n</li>\n</ul>\n<h2 id=\"how-do-i-use-kubernetes-volume-group-snapshots\">How do I use Kubernetes volume group snapshots</h2>\n<h3 id=\"creating-a-new-group-snapshot-with-kubernetes\">Creating a new group snapshot with Kubernetes</h3>\n<p>Once a VolumeGroupSnapshotClass object is defined and you have volumes you want to\nsnapshot together, you may request a new group snapshot by creating a VolumeGroupSnapshot\nobject.</p>\n<p>The source of the group snapshot specifies whether the underlying group snapshot\nshould be dynamically created or if a pre-existing VolumeGroupSnapshotContent\nshould be used.</p>\n<p>A pre-existing VolumeGroupSnapshotContent is created by a cluster administrator.\nIt contains the details of the real volume group snapshot on the storage system which\nis available for use by cluster users.</p>\n<p>One of the following members in the source of the group snapshot must be set.</p>\n<ul>\n<li><code>selector</code> - a label query over PersistentVolumeClaims that are to be grouped\ntogether for snapshotting. This selector will be used to match the label\nadded to a PVC.</li>\n<li><code>volumeGroupSnapshotContentName</code> - specifies the name of a pre-existing\nVolumeGroupSnapshotContent object representing an existing volume group snapshot.</li>\n</ul>\n<h4 id=\"dynamically-provision-a-group-snapshot\">Dynamically provision a group snapshot</h4>\n<p>In the following example, there are two PVCs.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-console\"><span style=\"display: flex;\"><span><span style=\"color: #888;\">NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS VOLUMEATTRIBUTESCLASS AGE\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">pvc-0 Bound pvc-6e1f7d34-a5c5-4548-b104-01e72c72b9f2 100Mi RWO csi-hostpath-sc &lt;unset&gt; 2m15s\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">pvc-1 Bound pvc-abc640b3-2cc1-4c56-ad0c-4f0f0e636efa 100Mi RWO csi-hostpath-sc &lt;unset&gt; 2m7s\n</span></span></span></code></pre></div><p>Label the PVCs.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-console\"><span style=\"display: flex;\"><span><span style=\"color: #000080; font-weight: bold;\">%</span> kubectl label pvc pvc-0 <span style=\"color: #b8860b;\">group</span><span style=\"color: #666;\">=</span>myGroup\n</span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">persistentvolumeclaim/pvc-0 labeled\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\"></span><span>\n</span></span></span><span style=\"display: flex;\"><span><span></span><span style=\"color: #000080; font-weight: bold;\">%</span> kubectl label pvc pvc-1 <span style=\"color: #b8860b;\">group</span><span style=\"color: #666;\">=</span>myGroup\n</span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">persistentvolumeclaim/pvc-1 labeled\n</span></span></span></code></pre></div><p>For dynamic provisioning, a selector must be set so that the snapshot controller can find PVCs\nwith the matching labels to be snapshotted together.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>groupsnapshot.storage.k8s.io/v1beta1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>VolumeGroupSnapshot<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">metadata</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>snapshot-daily-20241217<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">namespace</span>:<span style=\"color: #bbb;\"> </span>demo-namespace<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">spec</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">volumeGroupSnapshotClassName</span>:<span style=\"color: #bbb;\"> </span>csi-groupSnapclass<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">source</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">selector</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">matchLabels</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">group</span>:<span style=\"color: #bbb;\"> </span>myGroup<span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><p>In the VolumeGroupSnapshot spec, a user can specify the VolumeGroupSnapshotClass which\nhas the information about which CSI driver should be used for creating the group snapshot.\nA VolumGroupSnapshotClass is required for dynamic provisioning.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>groupsnapshot.storage.k8s.io/v1beta1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>VolumeGroupSnapshotClass<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">metadata</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>csi-groupSnapclass<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">annotations</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">kubernetes.io/description</span>:<span style=\"color: #bbb;\"> </span><span style=\"color: #b44;\">\"Example group snapshot class\"</span><span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">driver</span>:<span style=\"color: #bbb;\"> </span>example.csi.k8s.io<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">deletionPolicy</span>:<span style=\"color: #bbb;\"> </span>Delete<span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><p>As a result of the volume group snapshot creation, a corresponding VolumeGroupSnapshotContent\nobject will be created with a volumeGroupSnapshotHandle pointing to a resource on the storage\nsystem.</p>\n<p>Two individual volume snapshots will be created as part of the volume group snapshot creation.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-console\"><span style=\"display: flex;\"><span><span style=\"color: #888;\">NAME READYTOUSE SOURCEPVC RESTORESIZE SNAPSHOTCONTENT AGE\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">snapshot-0962a745b2bf930bb385b7b50c9b08af471f1a16780726de19429dd9c94eaca0 true pvc-0 100Mi snapcontent-0962a745b2bf930bb385b7b50c9b08af471f1a16780726de19429dd9c94eaca0 16m\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">snapshot-da577d76bd2106c410616b346b2e72440f6ec7b12a75156263b989192b78caff true pvc-1 100Mi snapcontent-da577d76bd2106c410616b346b2e72440f6ec7b12a75156263b989192b78caff 16m\n</span></span></span></code></pre></div><h4 id=\"importing-an-existing-group-snapshot-with-kubernetes\">Importing an existing group snapshot with Kubernetes</h4>\n<p>To import a pre-existing volume group snapshot into Kubernetes, you must also import\nthe corresponding individual volume snapshots.</p>\n<p>Identify the individual volume snapshot handles, manually construct a\nVolumeSnapshotContent object first, then create a VolumeSnapshot object pointing to\nthe VolumeSnapshotContent object. Repeat this for every individual volume snapshot.</p>\n<p>Then manually create a VolumeGroupSnapshotContent object, specifying the\nvolumeGroupSnapshotHandle and individual volumeSnapshotHandles already existing\non the storage system.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>groupsnapshot.storage.k8s.io/v1beta1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>VolumeGroupSnapshotContent<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">metadata</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>static-group-content<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">spec</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">deletionPolicy</span>:<span style=\"color: #bbb;\"> </span>Delete<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">driver</span>:<span style=\"color: #bbb;\"> </span>hostpath.csi.k8s.io<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">source</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">groupSnapshotHandles</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">volumeGroupSnapshotHandle</span>:<span style=\"color: #bbb;\"> </span>e8779136-a93e-11ef-9549-66940726f2fd<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">volumeSnapshotHandles</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span>- e8779147-a93e-11ef-9549-66940726f2fd<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span>- e8783cd0-a93e-11ef-9549-66940726f2fd<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">volumeGroupSnapshotRef</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>static-group-snapshot<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">namespace</span>:<span style=\"color: #bbb;\"> </span>demo-namespace<span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><p>After that create a VolumeGroupSnapshot object pointing to the VolumeGroupSnapshotContent\nobject.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>groupsnapshot.storage.k8s.io/v1beta1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>VolumeGroupSnapshot<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">metadata</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>static-group-snapshot<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">namespace</span>:<span style=\"color: #bbb;\"> </span>demo-namespace<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">spec</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">source</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">volumeGroupSnapshotContentName</span>:<span style=\"color: #bbb;\"> </span>static-group-content<span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><h3 id=\"how-to-use-group-snapshot-for-restore-in-kubernetes\">How to use group snapshot for restore in Kubernetes</h3>\n<p>At restore time, the user can request a new PersistentVolumeClaim to be created from\na VolumeSnapshot object that is part of a VolumeGroupSnapshot. This will trigger\nprovisioning of a new volume that is pre-populated with data from the specified\nsnapshot. The user should repeat this until all volumes are created from all the\nsnapshots that are part of a group snapshot.</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>v1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>PersistentVolumeClaim<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">metadata</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>examplepvc-restored-2024-12-17<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">namespace</span>:<span style=\"color: #bbb;\"> </span>demo-namespace<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">spec</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">storageClassName</span>:<span style=\"color: #bbb;\"> </span>example-foo-nearline<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">dataSource</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">name</span>:<span style=\"color: #bbb;\"> </span>snapshot-0962a745b2bf930bb385b7b50c9b08af471f1a16780726de19429dd9c94eaca0<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>VolumeSnapshot<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">apiGroup</span>:<span style=\"color: #bbb;\"> </span>snapshot.storage.k8s.io<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">accessModes</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span>- ReadWriteOncePod<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">resources</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">requests</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">storage</span>:<span style=\"color: #bbb;\"> </span>100Mi<span style=\"color: #bbb;\"> </span><span style=\"color: #080; font-style: italic;\"># must be enough storage to fit the existing snapshot</span><span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><h2 id=\"as-a-storage-vendor-how-do-i-add-support-for-group-snapshots-to-my-csi-driver\">As a storage vendor, how do I add support for group snapshots to my CSI driver?</h2>\n<p>To implement the volume group snapshot feature, a CSI driver <strong>must</strong>:</p>\n<ul>\n<li>Implement a new group controller service.</li>\n<li>Implement group controller RPCs: <code>CreateVolumeGroupSnapshot</code>, <code>DeleteVolumeGroupSnapshot</code>, and <code>GetVolumeGroupSnapshot</code>.</li>\n<li>Add group controller capability <code>CREATE_DELETE_GET_VOLUME_GROUP_SNAPSHOT</code>.</li>\n</ul>\n<p>See the <a href=\"https://github.com/container-storage-interface/spec/blob/master/spec.md\">CSI spec</a>\nand the <a href=\"https://kubernetes-csi.github.io/docs/\">Kubernetes-CSI Driver Developer Guide</a>\nfor more details.</p>\n<p>As mentioned earlier, it is strongly recommended that Kubernetes distributors\nbundle and deploy the volume snapshot controller and CRDs as part\nof their Kubernetes cluster management process (independent of any CSI Driver).</p>\n<p>As part of this recommended deployment process, the Kubernetes team provides a number of\nsidecar (helper) containers, including the\n<a href=\"https://kubernetes-csi.github.io/docs/external-snapshotter.html\">external-snapshotter sidecar container</a>\nwhich has been updated to support volume group snapshot.</p>\n<p>The external-snapshotter watches the Kubernetes API server for\nVolumeGroupSnapshotContent objects, and triggers <code>CreateVolumeGroupSnapshot</code> and\n<code>DeleteVolumeGroupSnapshot</code> operations against a CSI endpoint.</p>\n<h2 id=\"what-are-the-limitations\">What are the limitations?</h2>\n<p>The beta implementation of volume group snapshots for Kubernetes has the following limitations:</p>\n<ul>\n<li>Does not support reverting an existing PVC to an earlier state represented by\na snapshot (only supports provisioning a new volume from a snapshot).</li>\n<li>No application consistency guarantees beyond any guarantees provided by the storage system\n(e.g. crash consistency). See this <a href=\"https://github.com/kubernetes/community/blob/30d06f49fba22273f31b3c616b74cf8745c19b3d/wg-data-protection/data-protection-workflows-white-paper.md#quiesce-and-unquiesce-hooks\">doc</a>\nfor more discussions on application consistency.</li>\n</ul>\n<h2 id=\"what-s-next\">What‚Äôs next?</h2>\n<p>Depending on feedback and adoption, the Kubernetes project plans to push the volume\ngroup snapshot implementation to general availability (GA) in a future release.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li>The <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/3476-volume-group-snapshot\">design spec</a>\nfor the volume group snapshot feature.</li>\n<li>The <a href=\"https://github.com/kubernetes-csi/external-snapshotter\">code repository</a> for volume group\nsnapshot APIs and controller.</li>\n<li>CSI <a href=\"https://kubernetes-csi.github.io/docs/\">documentation</a> on the group snapshot feature.</li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>This project, like all of Kubernetes, is the result of hard work by many contributors\nfrom diverse backgrounds working together. On behalf of SIG Storage, I would like to\noffer a huge thank you to the contributors who stepped up these last few quarters\nto help the project reach beta:</p>\n<ul>\n<li>Ben Swartzlander (<a href=\"https://github.com/bswartz\">bswartz</a>)</li>\n<li>Cici Huang (<a href=\"https://github.com/cici37\">cici37</a>)</li>\n<li>Hemant Kumar (<a href=\"https://github.com/gnufied\">gnufied</a>)</li>\n<li>James Defelice (<a href=\"https://github.com/jdef\">jdef</a>)</li>\n<li>Jan ≈†afr√°nek (<a href=\"https://github.com/jsafrane\">jsafrane</a>)</li>\n<li>Madhu Rajanna (<a href=\"https://github.com/Madhu-1\">Madhu-1</a>)</li>\n<li>Manish M Yathnalli (<a href=\"https://github.com/manishym\">manishym</a>)</li>\n<li>Michelle Au (<a href=\"https://github.com/msau42\">msau42</a>)</li>\n<li>Niels de Vos (<a href=\"https://github.com/nixpanic\">nixpanic</a>)</li>\n<li>Leonardo Cecchi (<a href=\"https://github.com/leonardoce\">leonardoce</a>)</li>\n<li>Rakshith R (<a href=\"https://github.com/Rakshith-R\">Rakshith-R</a>)</li>\n<li>Raunak Shah (<a href=\"https://github.com/RaunakShah\">RaunakShah</a>)</li>\n<li>Saad Ali (<a href=\"https://github.com/saad-ali\">saad-ali</a>)</li>\n<li>Xing Yang (<a href=\"https://github.com/xing-yang\">xing-yang</a>)</li>\n<li>Yati Padia (<a href=\"https://github.com/yati1998\">yati1998</a>)</li>\n</ul>\n<p>For those interested in getting involved with the design and development of CSI or\nany part of the Kubernetes Storage system, join the\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe always welcome new contributors.</p>\n<p>We also hold regular <a href=\"https://github.com/kubernetes/community/tree/master/wg-data-protection\">Data Protection Working Group meetings</a>.\nNew attendees are welcome to join our discussions.</p>",
      "timestamp": 1741512160.532878,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Enhancing Kubernetes API Server Efficiency with API Streaming",
      "link": "https://kubernetes.io/blog/2024/12/17/kube-apiserver-api-streaming/",
      "published": "Tue, 17 Dec 2024 00:00:00 +0000",
      "summary": "<p>Managing Kubernetes clusters efficiently is critical, especially as their size is growing.\nA significant challenge with large clusters is the memory overhead caused by <strong>list</strong> requests.</p>\n<p>In the existing implementation, the kube-apiserver processes <strong>list</strong> requests by assembling the entire response in-memory before transmitting any data to the client.\nBut what if the response body is substantial, say hundreds of megabytes? Additionally, imagine a scenario where multiple <strong>list</strong> requests flood in simultaneously, perhaps after a brief network outage.\nWhile <a href=\"https://kubernetes.io/docs/concepts/cluster-administration/flow-control/\">API Priority and Fairness</a> has proven to reasonably protect kube-apiserver from CPU overload, its impact is visibly smaller for memory protection.\nThis can be explained by the differing nature of resource consumption by a single API request - the CPU usage at any given time is capped by a constant, whereas memory, being uncompressible, can grow proportionally with the number of processed objects and is unbounded.\nThis situation poses a genuine risk, potentially overwhelming and crashing any kube-apiserver within seconds due to out-of-memory (OOM) conditions. To better visualize the issue, let's consider the below graph.</p>\n<figure class=\"diagram-large clickable-zoom\">\n<img alt=\"Monitoring graph showing kube-apiserver memory usage\" src=\"https://kubernetes.io/blog/2024/12/17/kube-apiserver-api-streaming/kube-apiserver-memory_usage.png\" />\n</figure>\n<p>The graph shows the memory usage of a kube-apiserver during a synthetic test.\n(see the <a href=\"https://kubernetes.io/feed.xml#the-synthetic-test\">synthetic test</a> section for more details).\nThe results clearly show that increasing the number of informers significantly boosts the server's memory consumption.\nNotably, at approximately 16:40, the server crashed when serving only 16 informers.</p>\n<h2 id=\"why-does-kube-apiserver-allocate-so-much-memory-for-list-requests\">Why does kube-apiserver allocate so much memory for list requests?</h2>\n<p>Our investigation revealed that this substantial memory allocation occurs because the server before sending the first byte to the client must:</p>\n<ul>\n<li>fetch data from the database,</li>\n<li>deserialize the data from its stored format,</li>\n<li>and finally construct the final response by converting and serializing the data into a client requested format</li>\n</ul>\n<p>This sequence results in significant temporary memory consumption.\nThe actual usage depends on many factors like the page size, applied filters (e.g. label selectors), query parameters, and sizes of individual objects.</p>\n<p>Unfortunately, neither <a href=\"https://kubernetes.io/docs/concepts/cluster-administration/flow-control/\">API Priority and Fairness</a> nor Golang's garbage collection or Golang memory limits can prevent the system from exhausting memory under these conditions.\nThe memory is allocated suddenly and rapidly, and just a few requests can quickly deplete the available memory, leading to resource exhaustion.</p>\n<p>Depending on how the API server is run on the node, it might either be killed through OOM by the kernel when exceeding the configured memory limits during these uncontrolled spikes, or if limits are not configured it might have even worse impact on the control plane node.\nAnd worst, after the first API server failure, the same requests will likely hit another control plane node in an HA setup with probably the same impact.\nPotentially a situation that is hard to diagnose and hard to recover from.</p>\n<h2 id=\"streaming-list-requests\">Streaming list requests</h2>\n<p>Today, we're excited to announce a major improvement.\nWith the graduation of the <em>watch list</em> feature to beta in Kubernetes 1.32, client-go users can opt-in (after explicitly enabling <code>WatchListClient</code> feature gate)\nto streaming lists by switching from <strong>list</strong> to (a special kind of) <strong>watch</strong> requests.</p>\n<p><strong>Watch</strong> requests are served from the <em>watch cache</em>, an in-memory cache designed to improve scalability of read operations.\nBy streaming each item individually instead of returning the entire collection, the new method maintains constant memory overhead.\nThe API server is bound by the maximum allowed size of an object in etcd plus a few additional allocations.\nThis approach drastically reduces the temporary memory usage compared to traditional <strong>list</strong> requests, ensuring a more efficient and stable system,\nespecially in clusters with a large number of objects of a given type or large average object sizes where despite paging memory consumption used to be high.</p>\n<p>Building on the insight gained from the synthetic test (see the <a href=\"https://kubernetes.io/feed.xml#the-synthetic-test\">synthetic test</a>, we developed an automated performance test to systematically evaluate the impact of the <em>watch list</em> feature.\nThis test replicates the same scenario, generating a large number of Secrets with a large payload, and scaling the number of informers to simulate heavy <strong>list</strong> request patterns.\nThe automated test is executed periodically to monitor memory usage of the server with the feature enabled and disabled.</p>\n<p>The results showed significant improvements with the <em>watch list</em> feature enabled.\nWith the feature turned on, the kube-apiserver‚Äôs memory consumption stabilized at approximately <strong>2 GB</strong>.\nBy contrast, with the feature disabled, memory usage increased to approximately <strong>20GB</strong>, a <strong>10x</strong> increase!\nThese results confirm the effectiveness of the new streaming API, which reduces the temporary memory footprint.</p>\n<h2 id=\"enabling-api-streaming-for-your-component\">Enabling API Streaming for your component</h2>\n<p>Upgrade to Kubernetes 1.32. Make sure your cluster uses etcd in version 3.4.31+ or 3.5.13+.\nChange your client software to use watch lists. If your client code is written in Golang, you'll want to enable <code>WatchListClient</code> for client-go.\nFor details on enabling that feature, read <a href=\"https://kubernetes.io/blog/2024/08/12/feature-gates-in-client-go\">Introducing Feature Gates to Client-Go: Enhancing Flexibility and Control</a>.</p>\n<h2 id=\"what-s-next\">What's next?</h2>\n<p>In Kubernetes 1.32, the feature is enabled in kube-controller-manager by default despite its beta state.\nThis will eventually be expanded to other core components like kube-scheduler or kubelet; once the feature becomes generally available, if not earlier.\nOther 3rd-party components are encouraged to opt-in to the feature during the beta phase, especially when they are at risk of accessing a large number of resources or kinds with potentially large object sizes.</p>\n<p>For the time being, <a href=\"https://kubernetes.io/docs/concepts/cluster-administration/flow-control/\">API Priority and Fairness</a> assigns a reasonable small cost to <strong>list</strong> requests.\nThis is necessary to allow enough parallelism for the average case where <strong>list</strong> requests are cheap enough.\nBut it does not match the spiky exceptional situation of many and large objects.\nOnce the majority of the Kubernetes ecosystem has switched to <em>watch list</em>, the <strong>list</strong> cost estimation can be changed to larger values without risking degraded performance in the average case,\nand with that increasing the protection against this kind of requests that can still hit the API server in the future.</p>\n<h2 id=\"the-synthetic-test\">The synthetic test</h2>\n<p>In order to reproduce the issue, we conducted a manual test to understand the impact of <strong>list</strong> requests on kube-apiserver memory usage.\nIn the test, we created 400 Secrets, each containing 1 MB of data, and used informers to retrieve all Secrets.</p>\n<p>The results were alarming, only 16 informers were needed to cause the test server to run out of memory and crash, demonstrating how quickly memory consumption can grow under such conditions.</p>\n<p>Special shout out to <a href=\"https://github.com/deads2k\">@deads2k</a> for his help in shaping this feature.</p>",
      "timestamp": 1741512160.5328822,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Kubernetes v1.32 Adds A New CPU Manager Static Policy Option For Strict CPU Reservation",
      "link": "https://kubernetes.io/blog/2024/12/16/cpumanager-strict-cpu-reservation/",
      "published": "Mon, 16 Dec 2024 00:00:00 +0000",
      "summary": "<p>In Kubernetes v1.32, after years of community discussion, we are excited to introduce a\n<code>strict-cpu-reservation</code> option for the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/#static-policy-options\">CPU Manager static policy</a>.\nThis feature is currently in alpha, with the associated policy hidden by default. You can only use the\npolicy if you explicitly enable the alpha behavior in your cluster.</p>\n<h2 id=\"understanding-the-feature\">Understanding the feature</h2>\n<p>The CPU Manager static policy is used to reduce latency or improve performance. The <code>reservedSystemCPUs</code> defines an explicit CPU set for OS system daemons and kubernetes system daemons. This option is designed for Telco/NFV type use cases where uncontrolled interrupts/timers may impact the workload performance. you can use this option to define the explicit cpuset for the system/kubernetes daemons as well as the interrupts/timers, so the rest CPUs on the system can be used exclusively for workloads, with less impact from uncontrolled interrupts/timers. More details of this parameter can be found on the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#explicitly-reserved-cpu-list\">Explicitly Reserved CPU List</a> page.</p>\n<p>If you want to protect your system daemons and interrupt processing, the obvious way is to use the <code>reservedSystemCPUs</code> option.</p>\n<p>However, until the Kubernetes v1.32 release, this isolation was only implemented for guaranteed\npods that made requests for a whole number of CPUs. At pod admission time, the kubelet only\ncompares the CPU <em>requests</em> against the allocatable CPUs. In Kubernetes, limits can be higher than\nthe requests; the previous implementation allowed burstable and best-effort pods to use up\nthe capacity of <code>reservedSystemCPUs</code>, which could then starve host OS services of CPU - and we\nknow that people saw this in real life deployments.\nThe existing behavior also made benchmarking (for both infrastructure and workloads) results inaccurate.</p>\n<p>When this new <code>strict-cpu-reservation</code> policy option is enabled, the CPU Manager static policy will not allow any workload to use the reserved system CPU cores.</p>\n<h2 id=\"enabling-the-feature\">Enabling the feature</h2>\n<p>To enable this feature, you need to turn on both the <code>CPUManagerPolicyAlphaOptions</code> feature gate and the <code>strict-cpu-reservation</code> policy option. And you need to remove the <code>/var/lib/kubelet/cpu_manager_state</code> file if it exists and restart kubelet.</p>\n<p>With the following kubelet configuration:</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-yaml\"><span style=\"display: flex;\"><span><span style=\"color: #008000; font-weight: bold;\">kind</span>:<span style=\"color: #bbb;\"> </span>KubeletConfiguration<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">apiVersion</span>:<span style=\"color: #bbb;\"> </span>kubelet.config.k8s.io/v1beta1<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">featureGates</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span>...<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">CPUManagerPolicyOptions</span>:<span style=\"color: #bbb;\"> </span><span style=\"color: #a2f; font-weight: bold;\">true</span><span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">CPUManagerPolicyAlphaOptions</span>:<span style=\"color: #bbb;\"> </span><span style=\"color: #a2f; font-weight: bold;\">true</span><span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">cpuManagerPolicy</span>:<span style=\"color: #bbb;\"> </span>static<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">cpuManagerPolicyOptions</span>:<span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"> </span><span style=\"color: #008000; font-weight: bold;\">strict-cpu-reservation</span>:<span style=\"color: #bbb;\"> </span><span style=\"color: #b44;\">\"true\"</span><span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #008000; font-weight: bold;\">reservedSystemCPUs</span>:<span style=\"color: #bbb;\"> </span><span style=\"color: #b44;\">\"0,32,1,33,16,48\"</span><span style=\"color: #bbb;\">\n</span></span></span><span style=\"display: flex;\"><span><span style=\"color: #bbb;\"></span><span style=\"color: #00f; font-weight: bold;\">...</span><span style=\"color: #bbb;\">\n</span></span></span></code></pre></div><p>When <code>strict-cpu-reservation</code> is not set or set to false:</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-console\"><span style=\"display: flex;\"><span><span style=\"color: #000080; font-weight: bold;\">#</span> cat /var/lib/kubelet/cpu_manager_state\n</span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">{\"policyName\":\"static\",\"defaultCpuSet\":\"0-63\",\"checksum\":1058907510}\n</span></span></span></code></pre></div><p>When <code>strict-cpu-reservation</code> is set to true:</p>\n<div class=\"highlight\"><pre tabindex=\"0\"><code class=\"language-console\"><span style=\"display: flex;\"><span><span style=\"color: #000080; font-weight: bold;\">#</span> cat /var/lib/kubelet/cpu_manager_state\n</span></span><span style=\"display: flex;\"><span><span style=\"color: #888;\">{\"policyName\":\"static\",\"defaultCpuSet\":\"2-15,17-31,34-47,49-63\",\"checksum\":4141502832}\n</span></span></span></code></pre></div><h2 id=\"monitoring-the-feature\">Monitoring the feature</h2>\n<p>You can monitor the feature impact by checking the following CPU Manager counters:</p>\n<ul>\n<li><code>cpu_manager_shared_pool_size_millicores</code>: report shared pool size, in millicores (e.g. 13500m)</li>\n<li><code>cpu_manager_exclusive_cpu_allocation_count</code>: report exclusively allocated cores, counting full cores (e.g. 16)</li>\n</ul>\n<p>Your best-effort workloads may starve if the <code>cpu_manager_shared_pool_size_millicores</code> count is zero for prolonged time.</p>\n<p>We believe any pod that is required for operational purpose like a log forwarder should not run as best-effort, but you can review and adjust the amount of CPU cores reserved as needed.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Strict CPU reservation is critical for Telco/NFV use cases. It is also a prerequisite for enabling the all-in-one type of deployments where workloads are placed on nodes serving combined control+worker+storage roles.</p>\n<p>We want you to start using the feature and looking forward to your feedback.</p>\n<h2 id=\"further-reading\">Further reading</h2>\n<p>Please check out the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\">Control CPU Management Policies on the Node</a>\ntask page to learn more about the CPU Manager, and how it fits in relation to the other node-level resource managers.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>This feature is driven by the <a href=\"https://github.com/Kubernetes/community/blob/master/sig-node/README.md\">SIG Node</a>. If you are interested in helping develop this feature, sharing feedback, or participating in any other ongoing SIG Node projects, please attend the SIG Node meeting for more details.</p>",
      "timestamp": 1741512160.5328865,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Kubernetes v1.32: Memory Manager Goes GA",
      "link": "https://kubernetes.io/blog/2024/12/13/memory-manager-goes-ga/",
      "published": "Fri, 13 Dec 2024 00:00:00 +0000",
      "summary": "<p>With Kubernetes 1.32, the memory manager has officially graduated to General Availability (GA),\nmarking a significant milestone in the journey toward efficient and predictable memory allocation for containerized applications.\nSince Kubernetes v1.22, where it graduated to beta, the memory manager has proved itself reliable, stable and a good complementary feature for the\n<a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\">CPU Manager</a>.</p>\n<p>As part of kubelet's workload admission process,\nthe memory manager provides topology hints\nto optimize memory allocation and alignment.\nThis enables users to allocate exclusive\nmemory for Pods in the <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/#guaranteed\">Guaranteed</a> QoS class.\nMore details about the process can be found in the memory manager goes to beta <a href=\"https://kubernetes.io/blog/2021/08/11/kubernetes-1-22-feature-memory-manager-moves-to-beta/\">blog</a>.</p>\n<p>Most of the changes introduced since the Beta are bug fixes, internal refactoring and\nobservability improvements, such as metrics and better logging.</p>\n<h2 id=\"observability-improvements\">Observability improvements</h2>\n<p>As part of the effort\nto increase the observability of memory manager, new metrics have been added\nto provide some statistics on memory allocation patterns.</p>\n<ul>\n<li>\n<p><strong>memory_manager_pinning_requests_total</strong> -\ntracks the number of times the pod spec required the memory manager to pin memory pages.</p>\n</li>\n<li>\n<p><strong>memory_manager_pinning_errors_total</strong> -\ntracks the number of times the pod spec required the memory manager\nto pin memory pages, but the allocation failed.</p>\n</li>\n</ul>\n<h2 id=\"improving-memory-manager-reliability-and-consistency\">Improving memory manager reliability and consistency</h2>\n<p>The kubelet does not guarantee pod ordering\nwhen admitting pods after a restart or reboot.</p>\n<p>In certain edge cases, this behavior could cause\nthe memory manager to reject some pods,\nand in more extreme cases, it may cause kubelet to fail upon restart.</p>\n<p>Previously, the beta implementation lacked certain checks and logic to prevent\nthese issues.</p>\n<p>To stabilize the memory manager for general availability (GA) readiness,\nsmall but critical refinements have been\nmade to the algorithm, improving its robustness and handling of edge cases.</p>\n<h2 id=\"future-development\">Future development</h2>\n<p>There is more to come for the future of Topology Manager in general,\nand memory manager in particular.\nNotably, ongoing efforts are underway\nto extend <a href=\"https://github.com/kubernetes/kubernetes/pull/128560\">memory manager support to Windows</a>,\nenabling CPU and memory affinity on a Windows operating system.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>This feature is driven by the <a href=\"https://github.com/Kubernetes/community/blob/master/sig-node/README.md\">SIG Node</a> community.\nPlease join us to connect with the community\nand share your ideas and feedback around the above feature and\nbeyond.\nWe look forward to hearing from you!</p>",
      "timestamp": 1741512160.5328903,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Kubernetes v1.32: QueueingHint Brings a New Possibility to Optimize Pod Scheduling",
      "link": "https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/",
      "published": "Thu, 12 Dec 2024 00:00:00 +0000",
      "summary": "<p>The Kubernetes <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/\">scheduler</a> is the core\ncomponent that selects the nodes on which new Pods run. The scheduler processes\nthese new Pods <strong>one by one</strong>. Therefore, the larger your clusters, the more important\nthe throughput of the scheduler becomes.</p>\n<p>Over the years, Kubernetes SIG Scheduling has improved the throughput\nof the scheduler in multiple enhancements. This blog post describes a major improvement to the\nscheduler in Kubernetes v1.32: a\n<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/#extension-points\">scheduling context element</a>\nnamed <em>QueueingHint</em>. This page provides background knowledge of the scheduler and explains how\nQueueingHint improves scheduling throughput.</p>\n<h2 id=\"scheduling-queue\">Scheduling queue</h2>\n<p>The scheduler stores all unscheduled Pods in an internal component called the <em>scheduling queue</em>.</p>\n<p>The scheduling queue consists of the following data structures:</p>\n<ul>\n<li><strong>ActiveQ</strong>: holds newly created Pods or Pods that are ready to be retried for scheduling.</li>\n<li><strong>BackoffQ</strong>: holds Pods that are ready to be retried but are waiting for a backoff period to end. The\nbackoff period depends on the number of unsuccessful scheduling attempts performed by the scheduler on that Pod.</li>\n<li><strong>Unschedulable Pod Pool</strong>: holds Pods that the scheduler won't attempt to schedule for one of the\nfollowing reasons:\n<ul>\n<li>The scheduler previously attempted and was unable to schedule the Pods. Since that attempt, the cluster\nhasn't changed in a way that could make those Pods schedulable.</li>\n<li>The Pods are blocked from entering the scheduling cycles by PreEnqueue Plugins,\nfor example, they have a <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/#configuring-pod-schedulinggates\">scheduling gate</a>,\nand get blocked by the scheduling gate plugin.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"scheduling-framework-and-plugins\">Scheduling framework and plugins</h2>\n<p>The Kubernetes scheduler is implemented following the Kubernetes\n<a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/\">scheduling framework</a>.</p>\n<p>And, all scheduling features are implemented as plugins\n(e.g., <a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\">Pod affinity</a>\nis implemented in the <code>InterPodAffinity</code> plugin.)</p>\n<p>The scheduler processes pending Pods in phases called <em>cycles</em> as follows:</p>\n<ol>\n<li>\n<p><strong>Scheduling cycle</strong>: the scheduler takes pending Pods from the activeQ component of the scheduling\nqueue <em>one by one</em>. For each Pod, the scheduler runs the filtering/scoring logic from every scheduling plugin. The\nscheduler then decides on the best node for the Pod, or decides that the Pod can't be scheduled at that time.</p>\n<p>If the scheduler decides that a Pod can't be scheduled, that Pod enters the Unschedulable Pod Pool\ncomponent of the scheduling queue. However, if the scheduler decides to place the Pod on a node,\nthe Pod goes to the binding cycle.</p>\n</li>\n<li>\n<p><strong>Binding cycle</strong>: the scheduler communicates the node placement decision to the Kubernetes API\nserver. This operation bounds the Pod to the selected node.</p>\n</li>\n</ol>\n<p>Aside from some exceptions, most unscheduled Pods enter the unschedulable pod pool after each scheduling\ncycle. The Unschedulable Pod Pool component is crucial because of how the scheduling cycle processes Pods one by one. If the scheduler had to constantly retry placing unschedulable Pods, instead of offloading those\nPods to the Unschedulable Pod Pool, multiple scheduling cycles would be wasted on those Pods.</p>\n<h2 id=\"improvements-to-retrying-pod-scheduling-with-queuinghint\">Improvements to retrying Pod scheduling with QueuingHint</h2>\n<p>Unschedulable Pods only move back into the ActiveQ or BackoffQ components of the scheduling\nqueue if changes in the cluster might allow the scheduler to place those Pods on nodes.</p>\n<p>Prior to v1.32, each plugin registered which cluster changes could solve their failures, an object creation, update, or deletion in the cluster (called <em>cluster events</em>),\nwith <code>EnqueueExtensions</code> (<code>EventsToRegister</code>),\nand the scheduling queue retries a pod with an event that is registered by a plugin that rejected the pod in a previous scheduling cycle.</p>\n<p>Additionally, we had an internal feature called <code>preCheck</code>, which helped further filtering of events for efficiency, based on Kubernetes core scheduling constraints;\nFor example, <code>preCheck</code> could filter out node-related events when the node status is <code>NotReady</code>.</p>\n<p>However, we had two issues for those approaches:</p>\n<ul>\n<li>Requeueing with events was too broad, could lead to scheduling retries for no reason.\n<ul>\n<li>A new scheduled Pod <em>might</em> solve the <code>InterPodAffinity</code>'s failure, but not all of them do.\nFor example, if a new Pod is created, but without a label matching <code>InterPodAffinity</code> of the unschedulable pod, the pod wouldn't be schedulable.</li>\n</ul>\n</li>\n<li><code>preCheck</code> relied on the logic of in-tree plugins and was not extensible to custom plugins,\nlike in issue <a href=\"https://github.com/kubernetes/kubernetes/issues/110175\">#110175</a>.</li>\n</ul>\n<p>Here QueueingHints come into play;\na QueueingHint subscribes to a particular kind of cluster event, and make a decision about whether each incoming event could make the Pod schedulable.</p>\n<p>For example, consider a Pod named <code>pod-a</code> that has a required Pod affinity. <code>pod-a</code> was rejected in\nthe scheduling cycle by the <code>InterPodAffinity</code> plugin because no node had an existing Pod that matched\nthe Pod affinity specification for <code>pod-a</code>.</p>\n<figure>\n<img alt=\"A diagram showing the scheduling queue and pod-a rejected by InterPodAffinity plugin\" src=\"https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/queueinghint1.svg\" /> <figcaption>\n<p>A diagram showing the scheduling queue and pod-a rejected by InterPodAffinity plugin</p>\n</figcaption>\n</figure>\n<p><code>pod-a</code> moves into the Unschedulable Pod Pool. The scheduling queue records which plugin caused\nthe scheduling failure for the Pod. For <code>pod-a</code>, the scheduling queue records that the <code>InterPodAffinity</code>\nplugin rejected the Pod.</p>\n<p><code>pod-a</code> will never be schedulable until the InterPodAffinity failure is resolved.\nThere're some scenarios that the failure could be resolved, one example is an existing running pod gets a label update and becomes matching a Pod affinity.\nFor this scenario, the <code>InterPodAffinity</code> plugin's <code>QueuingHint</code> callback function checks every Pod label update that occurs in the cluster.\nThen, if a Pod gets a label update that matches the Pod affinity requirement of <code>pod-a</code>, the <code>InterPodAffinity</code>,\nplugin's <code>QueuingHint</code> prompts the scheduling queue to move <code>pod-a</code> back into the ActiveQ or\nthe BackoffQ component.</p>\n<figure>\n<img alt=\"A diagram showing the scheduling queue and pod-a being moved by InterPodAffinity QueueingHint\" src=\"https://kubernetes.io/blog/2024/12/12/scheduler-queueinghint/queueinghint2.svg\" /> <figcaption>\n<p>A diagram showing the scheduling queue and pod-a being moved by InterPodAffinity QueueingHint</p>\n</figcaption>\n</figure>\n<h2 id=\"queueinghint-s-history-and-what-s-new-in-v1-32\">QueueingHint's history and what's new in v1.32</h2>\n<p>At SIG Scheduling, we have been working on the development of QueueingHint since\nKubernetes v1.28.</p>\n<p>While QueuingHint isn't user-facing, we implemented the <code>SchedulerQueueingHints</code> feature gate as a\nsafety measure when we originally added this feature. In v1.28, we implemented QueueingHints with a\nfew in-tree plugins experimentally, and made the feature gate enabled by default.</p>\n<p>However, users reported a memory leak, and consequently we disabled the feature gate in a\npatch release of v1.28. From v1.28 until v1.31, we kept working on the QueueingHint implementation\nwithin the rest of the in-tree plugins and fixing bugs.</p>\n<p>In v1.32, we made this feature enabled by default again. We finished implementing QueueingHints\nin all plugins and also identified the cause of the memory leak!</p>\n<p>We thank all the contributors who participated in the development of this feature and those who reported and investigated the earlier issues.</p>\n<h2 id=\"getting-involved\">Getting involved</h2>\n<p>These features are managed by Kubernetes <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a>.</p>\n<p>Please join us and share your feedback.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/4247-queueinghint/README.md\">KEP-4247: Per-plugin callback functions for efficient requeueing in the scheduling queue</a></li>\n</ul>",
      "timestamp": 1741512160.532894,
      "translated": false
    },
    {
      "feed_name": "Kubernetes Official Blog",
      "source_language": "en",
      "title": "Kubernetes v1.32: Penelope",
      "link": "https://kubernetes.io/blog/2024/12/11/kubernetes-v1-32-release/",
      "published": "Wed, 11 Dec 2024 00:00:00 +0000",
      "summary": "<p><strong>Editors:</strong> Matteo Bianchi, Edith Puclla, William Rizzo, Ryota Sawada, Rashan Smith</p>\n<p>Announcing the release of Kubernetes v1.32: Penelope!</p>\n<p>In line with previous releases, the release of Kubernetes v1.32 introduces new stable, beta, and alpha features.\nThe consistent delivery of high-quality releases underscores the strength of our development cycle and the vibrant\nsupport from our community.\nThis release consists of 44 enhancements in total.\nOf those enhancements, 13 have graduated to Stable, 12 are entering Beta, and 19 have entered in Alpha.</p>\n<h2 id=\"release-theme-and-logo\">Release theme and logo</h2>\n<figure class=\"release-logo \">\n<img alt=\"Kubernetes v1.32 logo: Penelope from the Odyssey, a helm and a purple geometric background\" src=\"https://kubernetes.io/blog/2024/12/11/kubernetes-v1-32-release/k8s-1.32.png\" />\n</figure>\n<p>The Kubernetes v1.32 Release Theme is &quot;Penelope&quot;.</p>\n<p>If Kubernetes is Ancient Greek for &quot;pilot&quot;, in this release we start from that origin\nand reflect on the last 10 years of Kubernetes and our accomplishments:\neach release cycle is a journey, and just like Penelope, in &quot;The Odyssey&quot;,<br />\nweaved for 10 years -- each night removing parts of what she had done during the day --\nso does each release add new features and removes others, albeit here with a much\nclearer purpose of constantly improving Kubernetes.\nWith v1.32 being the last release in the year Kubernetes marks its first decade anniversary,\nwe wanted to honour all of those that have been part of the global Kubernetes crew\nthat roams the cloud-native seas through perils and challanges:\nmay we continue to weave the future of Kubernetes together.</p>\n<h2 id=\"updates-to-recent-key-features\">Updates to recent key features</h2>\n<h3 id=\"a-note-on-dra-enhancements\">A note on DRA enhancements</h3>\n<p>In this release, like the previous one, the Kubernetes project continues proposing a number of enhancements to the\nDynamic Resource Allocation (DRA), a key component of the Kubernetes resource management system. These enhancements aim\nto improve the flexibility and efficiency of resource allocation for workloads that require specialized hardware, such\nas GPUs, FPGAs and network adapters.\nThese features are particularly useful for use-cases such as machine learning or high-performance computing\napplications. The core part enabling DRA Structured parameter support <a href=\"https://kubernetes.io/feed.xml#structured-parameter-support\">got promoted to beta</a>.</p>\n<h3 id=\"quality-of-life-improvements-on-nodes-and-sidecar-containers-update\">Quality of life improvements on nodes and sidecar containers update</h3>\n<p><a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a> has the following highlights that go beyond\nKEPs:</p>\n<ol>\n<li>\n<p>The systemd watchdog capability is now used to restart the kubelet when its health check fails, while also limiting\nthe maximum number of restarts within a given time period. This enhances the reliability of the kubelet. For more\ndetails, see pull request <a href=\"https://github.com/kubernetes/kubernetes/pull/127566\">#127566</a>.</p>\n</li>\n<li>\n<p>In cases when an image pull back-off error is encountered, the message displayed in the Pod status has been improved\nto be more human-friendly and to indicate details about why the Pod is in this condition.\nWhen an image pull back-off occurs, the error is appended to the <code>status.containerStatuses[*].state.waiting.message</code>\nfield in the Pod specification with an <code>ImagePullBackOff</code> value in the <code>reason</code> field. This change provides you with\nmore context and helps you to identify the root cause of the issue. For more details, see pull request\n<a href=\"https://github.com/kubernetes/kubernetes/pull/127918\">#127918</a>.</p>\n</li>\n<li>\n<p>The sidecar containers feature is targeting graduation to Stable in v1.33. To view the remaining work items and\nfeedback from users, see comments in the issue\n<a href=\"https://github.com/kubernetes/enhancements/issues/753#issuecomment-2350136594\">#753</a>.</p>\n</li>\n</ol>\n<h2 id=\"highlights-of-features-graduating-to-stable\">Highlights of features graduating to Stable</h2>\n<p><em>This is a selection of some of the improvements that are now stable following the v1.32 release.</em></p>\n<h3 id=\"custom-resource-field-selectors\">Custom Resource field selectors</h3>\n<p>Custom resource field selector allows developers to add field selectors to custom resources, mirroring the functionality\navailable for built-in Kubernetes objects. This allows for more efficient and precise filtering of custom resources,\npromoting better API design practices.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4358\">KEP #4358</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-api-machinery\">SIG API\nMachinery</a>.</p>\n<h3 id=\"support-to-size-memory-backed-volumes\">Support to size memory backed volumes</h3>\n<p>This feature makes it possible to dynamically size memory-backed volumes based on Pod resource limits, improving the\nworkload's portability and overall node resource utilization.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/1967\">KEP #1967</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"bound-service-account-token-improvement\">Bound service account token improvement</h3>\n<p>The inclusion of the node name in the service account token claims allows users to use such information during\nauthorization and admission (ValidatingAdmissionPolicy).\nFurthermore this improvement keeps service account credentials from being a privilege escalation path for nodes.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4193\">KEP #4193</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"structured-authorization-configuration\">Structured authorization configuration</h3>\n<p>Multiple authorizers can be configured in the API server to allow for structured authorization decisions,\nwith support for CEL match conditions in webhooks.\nThis work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/3221\">KEP #3221</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"auto-remove-pvcs-created-by-statefulset\">Auto remove PVCs created by StatefulSet</h3>\n<p>PersistentVolumeClaims (PVCs) created by StatefulSets get automatically deleted when no longer needed,\nwhile ensuring data persistence during StatefulSet updates and node maintenance.\nThis feature simplifies storage management for StatefulSets and reduces the risk of orphaned PVCs.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/1847\">KEP #1847</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-apps\">SIG\nApps</a>.</p>\n<h2 id=\"highlights-of-features-graduating-to-beta\">Highlights of features graduating to Beta</h2>\n<p><em>This is a selection of some of the improvements that are now beta following the v1.32 release.</em></p>\n<h3 id=\"job-api-managed-by-mechanism\">Job API managed-by mechanism</h3>\n<p>The <code>managedBy</code> field for Jobs was promoted to beta in the v1.32 release. This feature enables external controllers\n(like <a href=\"https://kueue.sigs.k8s.io/\">Kueue</a>) to manage Job synchronization, offering greater flexibility and integration\nwith advanced workload management systems.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4368\">KEP #4368</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-apps\">SIG\nApps</a>.</p>\n<h3 id=\"only-allow-anonymous-auth-for-configured-endpoints\">Only allow anonymous auth for configured endpoints</h3>\n<p>This feature lets admins specify which endpoints are allowed for anonymous requests. For example, the admin\ncan choose to only allow anonymous access to health endpoints like <code>/healthz</code>, <code>/livez</code>, and <code>/readyz</code> while\nmaking sure preventing anonymous access to other cluster endpoints or resources even if a user\nmisconfigures RBAC.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4633\">KEP #4633</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG\nAuth</a>.</p>\n<h3 id=\"per-plugin-callback-functions-for-accurate-requeueing-in-kube-scheduler-enhancements\">Per-plugin callback functions for accurate requeueing in kube-scheduler¬†enhancements</h3>\n<p>This feature enhances scheduling throughput with more efficient scheduling retry decisions by\nper-plugin callback functions (QueueingHint). All plugins now have QueueingHints.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4247\">KEP #4247</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG\nScheduling</a>.</p>\n<h3 id=\"recover-from-volume-expansion-failure\">Recover from volume expansion failure</h3>\n<p>This feature lets users recover from volume expansion failure by retrying with a smaller size. This enhancement ensures\nthat volume expansion is more resilient and reliable, reducing the risk of data loss or corruption during the process.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/1790\">KEP #1790</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">SIG\nStorage</a>.</p>\n<h3 id=\"volume-group-snapshot\">Volume group snapshot</h3>\n<p>This feature introduces a VolumeGroupSnapshot API, which lets users take a snapshot of multiple volumes together, ensuring data consistency across the volumes.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/3476\">KEP #3476</a>, by <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">SIG\nStorage</a>.</p>\n<h3 id=\"structured-parameter-support\">Structured parameter support</h3>\n<p>The core part of Dynamic Resource Allocation (DRA), the structured parameter support, got promoted to beta.\nThis allows the kube-scheduler and Cluster Autoscaler to simulate claim allocation directly, without needing a\nthird-party driver.\nThese components can now predict whether resource requests can be fulfilled based on the cluster's current state without actually\ncommitting to the allocation. By eliminating the need for a third-party driver to validate or test allocations, this\nfeature improves planning and decision-making for resource distribution, making the scheduling and scaling processes\nmore efficient.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/4381\">KEP #4381</a>, by WG Device\nManagement (a cross functional team containing <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a>,\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a> and <a href=\"https://github.com/kubernetes/community/tree/master/sig-autoscaling\">SIG\nAutoscaling</a>).</p>\n<h3 id=\"label-and-field-selector-authorization\">Label and field selector authorization</h3>\n<p>Label and field selectors can be used in authorization decisions. The node authorizer\nautomatically takes advantage of this to limit nodes to list or watch their pods only.\nWebhook authorizers can be updated to limit requests based on the label or field selector used.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4601\">KEP #4601</a>\nby <a href=\"https://github.com/kubernetes/community/tree/master/sig-auth\">SIG Auth</a>.</p>\n<h2 id=\"highlights-of-new-features-in-alpha\">Highlights of new features in Alpha</h2>\n<p><em>This is a selection of key improvements introduced as alpha features in the v1.32 release.</em></p>\n<h3 id=\"asynchronous-preemption-in-the-kubernetes-scheduler\">Asynchronous preemption in the¬†Kubernetes Scheduler</h3>\n<p>The Kubernetes scheduler has been enhanced with Asynchronous Preemption, a feature that improves scheduling throughput\nby handling preemption operations asynchronously. Preemption ensures higher-priority pods get the resources they need by\nevicting lower-priority ones, but this process previously involved heavy operations like API calls to delete pods,\nslowing down the scheduler. With this enhancement, such tasks are now processed in parallel, allowing the scheduler to\ncontinue scheduling other pods without delays.\nThis improvement is particularly beneficial in clusters with high Pod churn or frequent scheduling failures, ensuring a\nmore efficient and resilient scheduling process.</p>\n<p>This work was done as a part of KEP <a href=\"https://github.com/kubernetes/enhancements/issues/4832\">#4832</a>\nby <a href=\"https://github.com/kubernetes/community/tree/master/sig-scheduling\">SIG Scheduling</a>.</p>\n<h3 id=\"mutating-admission-policies-using-cel-expressions\">Mutating admission policies using CEL expressions</h3>\n<p>This feature leverages CEL's object instantiation and JSON Patch strategies, combined with Server Side Apply‚Äôs merge\nalgorithms. It simplifies policy definition, reduces mutation conflicts, and enhances admission control performance\nwhile laying a foundation for more robust, extensible policy frameworks in Kubernetes.</p>\n<p>The Kubernetes API server now supports Common Expression Language (CEL)-based Mutating Admission Policies, providing a\nlightweight, efficient alternative to mutating admission webhooks. With this enhancement, administrators can use CEL to\ndeclare mutations like setting labels, defaulting fields, or injecting sidecars with simple, declarative expressions.\nThis approach reduces operational complexity, eliminates the need for webhooks, and integrates directly with the\nkube-apiserver, offering faster and more reliable in-process mutation handling.</p>\n<p>This work was done as a part of <a href=\"https://github.com/kubernetes/enhancements/issues/3962\">KEP #3962</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-api-machinery\">SIG API\nMachinery</a>.</p>\n<h3 id=\"pod-level-resource-specifications\">Pod-level resource specifications</h3>\n<p>This enhancement simplifies resource management in Kubernetes by introducing the ability to set resource requests and\nlimits at the Pod level, creating a shared pool that all containers in the Pod can dynamically use. This is particularly\nvaluable for workloads with containers that have fluctuating or bursty resource needs, as it minimizes over-provisioning\nand improves overall resource efficiency.</p>\n<p>By leveraging Linux cgroup settings at the Pod level, Kubernetes ensures that these resource limits are enforced while\nenabling tightly coupled containers to collaborate more effectively without hitting artificial constraints. Importantly,\nthis feature maintains backward compatibility with existing container-level resource settings, allowing users to adopt\nit incrementally without disrupting current workflows or existing configurations.</p>\n<p>This marks a significant improvement for multi-container pods, as it reduces the operational complexity of managing\nresource allocations across containers. It also provides a performance boost for tightly integrated applications, such\nas sidecar architectures, where containers share workloads or depend on each other‚Äôs availability to perform optimally.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/2837\">KEP #2837</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"allow-zero-value-for-sleep-action-of-prestop-hook\">Allow zero value for sleep action of PreStop hook</h3>\n<p>This enhancement introduces the ability to set a zero-second sleep duration for the PreStop lifecycle hook in\nKubernetes, offering a more flexible and no-op option for resource validation and customization. Previously, attempting\nto define a zero value for the sleep action resulted in validation errors, restricting its use. With this update, users\ncan configure a zero-second duration as a valid sleep setting, enabling immediate execution and termination behaviors\nwhere needed.</p>\n<p>The enhancement is backward-compatible, introduced as an opt-in feature controlled by the\n<code>PodLifecycleSleepActionAllowZero</code> feature gate. This change is particularly beneficial for scenarios requiring PreStop\nhooks for validation or admission webhook processing without requiring an actual sleep duration. By aligning with the\ncapabilities of the <code>time.After</code> Go function, this update simplifies configuration and expands usability for Kubernetes\nworkloads.</p>\n<p>This work was done as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4818\">KEP #4818</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG\nNode</a>.</p>\n<h3 id=\"dra-standardized-network-interface-data-for-resource-claim-status\">DRA: Standardized network interface data for resource claim status</h3>\n<p>This enhancement adds a new field that allows drivers to report specific device status data for each allocated object\nin a ResourceClaim. It also establishes a standardized way to represent networking devices information.</p>\n<p>This work was done as a part of\n<a href=\"https://github.com/kubernetes/enhancements/issues/4817\">KEP #4817</a>, by\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-network\">SIG Network</a>.</p>\n<h3 id=\"new-statusz-and-flagz-endpoints-for-core-components\">New statusz and flagz endpoints for core components</h3>\n<p>You can enable two new HTTP endpoints, <code>/statusz</code> and <code>/flagz</code>, for core components.\nThese enhance cluster debuggability by gaining insight into what versions (e.g. Golang version) that component is\nrunning as, along with details about its uptime, and which command line flags that component was executed with;\nmaking it easier to diagnose both runtime and configuration issues.</p>\n<p>This work was done as part of\n<a href=\"https://github.com/kubernetes/enhancements/issues/4827\">KEP #4827</a>\nand <a href=\"https://github.com/kubernetes/enhancements/issues/4828\">KEP #4828</a> by\n<a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation\">SIG Instrumentation</a>.</p>\n<h3 id=\"windows-strikes-back\">Windows strikes back!</h3>\n<p>Support for graceful shutdowns of Windows nodes in Kubernetes clusters has been added.\nBefore this release, Kubernetes provided graceful node shutdown functionality for Linux nodes\nbut lacked equivalent support for Windows. This enhancement enables the kubelet on Windows nodes to handle system\nshutdown events properly. Doing so, it ensures that Pods running on Windows nodes are gracefully terminated,\nallowing workloads to be rescheduled without disruption. This improvement enhances the reliability and stability\nof clusters that include Windows nodes, especially during a planned maintenance or any system updates.</p>\n<p>Moreover CPU and memory affinity support has been added for Windows nodes with nodes, with improvements\nto the CPU manager, memory manager and topology manager.</p>\n<p>This work was done respectively as part of <a href=\"https://github.com/kubernetes/enhancements/issues/4802\">KEP #4802</a>\nand <a href=\"https://github.com/kubernetes/enhancements/issues/4885\">KEP #4885</a> by <a href=\"https://github.com/kubernetes/community/tree/master/sig-windows\">SIG\nWindows</a>.</p>\n<h2 id=\"graduations-deprecations-and-removals-in-1-32\">Graduations, deprecations, and removals in 1.32</h2>\n<h3 id=\"graduations-to-stable\">Graduations to Stable</h3>\n<p>This lists all the features that graduated to stable (also known as <em>general availability</em>). For a full list of updates\nincluding new features and graduations from alpha to beta, see the release notes.</p>\n<p>This release includes a total of 13 enhancements promoted to Stable:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3221\">Structured Authorization Configuration</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4193\">Bound service account token improvements</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4358\">Custom Resource Field Selectors</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4420\">Retry Generate Name</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1860\">Make Kubernetes aware of the LoadBalancer behaviour</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2681\">Field <code>status.hostIPs</code> added for Pod</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4292\">Custom profile in kubectl debug</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1769\">Memory Manager</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1967\">Support to size memory backed volumes</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3545\">Improved multi-numa alignment in Topology Manager</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4026\">Add job creation timestamp to job annotations</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/4017\">Add Pod Index Label for StatefulSets and Indexed Jobs</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1847\">Auto remove PVCs created by StatefulSet</a></li>\n</ul>\n<h3 id=\"deprecations-and-removals\">Deprecations and removals</h3>\n<p>As Kubernetes develops and matures, features may be deprecated, removed, or replaced with better ones for the project's\noverall health.\nSee the Kubernetes <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-policy/\">deprecation and removal policy</a> for more details on\nthis process.</p>\n<h4 id=\"withdrawal-of-the-old-dra-implementation\">Withdrawal of the old DRA implementation</h4>\n<p>The enhancement <a href=\"https://github.com/kubernetes/enhancements/issues/3063\">#3063</a> introduced Dynamic Resource Allocation\n(DRA) in Kubernetes 1.26.</p>\n<p>However, in Kubernetes v1.32, this approach to DRA will be significantly changed. Code related to the original\nimplementation will be removed, leaving KEP <a href=\"https://github.com/kubernetes/enhancements/issues/4381\">#4381</a> as the &quot;new&quot;\nbase functionality.</p>\n<p>The decision to change the existing approach originated from its incompatibility with cluster autoscaling as resource\navailability was non-transparent, complicating decision-making for both Cluster Autoscaler and controllers.\nThe newly added Structured Parameter model substitutes the functionality.</p>\n<p>This removal will allow Kubernetes to handle new hardware requirements and resource claims more predictably, bypassing\nthe complexities of back and forth API calls to the kube-apiserver.</p>\n<p>See the enhancement issue <a href=\"https://github.com/kubernetes/enhancements/issues/3063\">#3063</a> to find out more.</p>\n<h4 id=\"api-removals\">API removals</h4>\n<p>There is one API removal in <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-32\">Kubernetes v1.32</a>:</p>\n<ul>\n<li>The <code>flowcontrol.apiserver.k8s.io/v1beta3</code> API version of FlowSchema and PriorityLevelConfiguration has been removed.\nTo prepare for this, you can edit your existing manifests and rewrite client software to use the\n<code>flowcontrol.apiserver.k8s.io/v1 API</code> version, available since v1.29.\nAll existing persisted objects are accessible via the new API. Notable changes in flowcontrol.apiserver.k8s.io/v1beta3\ninclude that the PriorityLevelConfiguration <code>spec.limited.nominalConcurrencyShares</code> field only defaults to 30 when\nunspecified, and an explicit value of 0 is not changed to 30.</li>\n</ul>\n<p>For more information, refer to the <a href=\"https://kubernetes.io/docs/reference/using-api/deprecation-guide/#v1-32\">API deprecation guide</a>.</p>\n<h3 id=\"release-notes-and-upgrade-actions-required\">Release notes and upgrade actions required</h3>\n<p>Check out the full details of the Kubernetes v1.32 release in our <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.32.md\">release\nnotes</a>.</p>\n<h2 id=\"availability\">Availability</h2>\n<p>Kubernetes v1.32 is available for download on <a href=\"https://github.com/kubernetes/kubernetes/releases/tag/v1.32.0\">GitHub</a> or\non the <a href=\"https://kubernetes.io/releases/download/\">Kubernetes download page</a>.</p>\n<p>To get started with Kubernetes, check out these <a href=\"https://kubernetes.io/docs/tutorials/\">interactive tutorials</a> or run local Kubernetes\nclusters using <a href=\"https://minikube.sigs.k8s.io/\">minikube</a>. You can also easily install v1.32 using\n<a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\">kubeadm</a>.</p>\n<h2 id=\"release-team\">Release team</h2>\n<p>Kubernetes is only possible with the support, commitment, and hard work of its community.\nEach release team is made up of dedicated community volunteers who work together to build the many pieces that make up\nthe Kubernetes releases you rely on.\nThis requires the specialized skills of people from all corners of our community, from the code itself to its\ndocumentation and project management.</p>\n<p>We would like to thank the entire <a href=\"https://github.com/kubernetes/sig-release/blob/master/releases/release-1.32/release-team.md\">release\nteam</a> for the hours spent\nhard at work to deliver the Kubernetes v1.32 release to our community.\nThe Release Team's membership ranges from first-time shadows to returning team leads with experience forged over several\nrelease cycles.\nA very special thanks goes out our release lead, Frederico Mu√±oz, for leading the release team so gracefully and handle\nany matter with the uttermost care, making sure this release was executed smoothly and efficiently.\nLast but not least a big thanks goes to all the release members - leads and shadows alike - and to the following SIGs\nfor the terrific work and outcome achieved during these 14 weeks of release work:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-docs\">SIG Docs</a> - for the fundamental support in docs and\nblog reviews and continous collaboration with release Comms and Docs;</li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-k8s-infra\">SIG k8s Infra</a> and <a href=\"https://github.com/kubernetes/community/tree/master/sig-testing\">SIG\nTesting</a> - for the outstanding work in keeping the\ntesting framework in check, along with all the infra components necessary;</li>\n<li><a href=\"https://github.com/kubernetes/community/tree/master/sig-release\">SIG Release</a> and\nall the release managers - for the incredible support provided throughout the orchestration of the entire release,\naddressing even the most challenging issues in a graceful and timely manner.</li>\n</ul>\n<h2 id=\"project-velocity\">Project velocity</h2>\n<p>The CNCF K8s <a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&amp;var-period=m&amp;var-repogroup_name=All\">DevStats\nproject</a>\naggregates a number of interesting data points related to the velocity of Kubernetes and various sub-projects. This\nincludes everything from individual contributions to the number of companies that are contributing and is an\nillustration of the depth and breadth of effort that goes into evolving this ecosystem.</p>\n<p>In the v1.32 release cycle, which ran for 14 weeks (September 9th to December 11th), we saw contributions to Kubernetes\nfrom as many as 125 different companies and 559 individuals as of writing.</p>\n<p>In the whole Cloud Native ecosystem, the figure goes up to 433 companies counting 2441 total contributors. This sees an\nincrease of 7% more overall contributions compared to the <a href=\"https://kubernetes.io/blog/2024/08/13/kubernetes-v1-31-release/#project-velocity\">previous\nrelease</a> cycle, along with 14%\nincrease in the number of companies involved, showcasing strong interest and community behind the Cloud Native projects.</p>\n<p>Source for this data:</p>\n<ul>\n<li><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&amp;from=1725832800000&amp;to=1733961599000&amp;var-period=d28&amp;var-repogroup_name=Kubernetes&amp;var-repo_name=kubernetes%2Fkubernetes\">Companies contributing to\nKubernetes</a></li>\n<li><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&amp;from=1725832800000&amp;to=1733961599000&amp;var-period=d28&amp;var-repogroup_name=All&amp;var-repo_name=kubernetes%2Fkubernetes\">Overall ecosystem\ncontributions</a></li>\n</ul>\n<p>By contribution we mean when someone makes a commit, code review, comment, creates an issue or PR, reviews a PR\n(including blogs and documentation) or comments on issues and PRs.</p>\n<p>If you are interested in contributing visit <a href=\"https://www.kubernetes.dev/docs/guide/#getting-started\">Getting Started</a> on\nour contributor website.</p>\n<p><a href=\"https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1&amp;var-period=m&amp;var-repogroup_name=All\">Check out\nDevStats</a>\nto learn more about the overall velocity of the Kubernetes project and community.</p>\n<h2 id=\"event-updates\">Event updates</h2>\n<p>Explore the upcoming Kubernetes and cloud-native events from March to June 2025, featuring KubeCon and KCD Stay informed\nand engage with the Kubernetes community.</p>\n<p><strong>March 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Beijing, China</strong></a>: In March | Beijing, China</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Guadalajara, Mexico</strong></a>: March 16, 2025 | Guadalajara,\nMexico</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Rio de Janeiro, Brazil</strong></a>: March 22, 2025 | Rio de\nJaneiro, Brazil</li>\n</ul>\n<p><strong>April 2025</strong></p>\n<ul>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-europe\"><strong>KubeCon + CloudNativeCon Europe 2025</strong></a>: April\n1-4, 2025 | London, United Kingdom</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Budapest, Hungary</strong></a>: April 23, 2025 | Budapest,\nHungary</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Chennai, India</strong></a>: April 26, 2025 | Chennai, India</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Auckland, New Zealand</strong></a>: April 28, 2025 | Auckland,\nNew Zealand</li>\n</ul>\n<p><strong>May 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Helsinki, Finland</strong></a>: May 6, 2025 | Helsinki, Finland</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: San Francisco, USA</strong></a>: May 8, 2025 | San Francisco, USA</li>\n<li><a href=\"https://community.cncf.io/events/details/cncf-kcd-texas-presents-kcd-texas-austin-2025/\"><strong>KCD - Kubernetes Community Days: Austin,\nUSA</strong></a>: May 15, 2025 | Austin,\nUSA</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Seoul, South Korea</strong></a>: May 22, 2025 | Seoul, South\nKorea</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Istanbul, Turkey</strong></a>: May 23, 2025 | Istanbul, Turkey</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Heredia, Costa Rica</strong></a>: May 31, 2025 | Heredia, Costa\nRica</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: New York, USA</strong></a>: In May | New York, USA</li>\n</ul>\n<p><strong>June 2025</strong></p>\n<ul>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Bratislava, Slovakia</strong></a>: June 5, 2025 | Bratislava,\nSlovakia</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Bangalore, India</strong></a>: June 6, 2025 | Bangalore, India</li>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-china/\"><strong>KubeCon + CloudNativeCon China 2025</strong></a>: June\n10-11, 2025 | Hong Kong</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Antigua Guatemala, Guatemala</strong></a>: June 14, 2025 |\nAntigua Guatemala, Guatemala</li>\n<li><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-japan\"><strong>KubeCon + CloudNativeCon Japan 2025</strong></a>: June\n16-17, 2025 | Tokyo, Japan</li>\n<li><a href=\"https://www.cncf.io/kcds/\"><strong>KCD - Kubernetes Community Days: Nigeria, Africa</strong></a>: June 19, 2025 | Nigeria, Africa</li>\n</ul>\n<h2 id=\"upcoming-release-webinar\">Upcoming release webinar</h2>\n<p>Join members of the Kubernetes v1.32 release team on <strong>Thursday, January 9th 2025 at 5:00 PM (UTC)</strong>, to learn about the\nrelease highlights of this release, as well as deprecations and removals to help plan for upgrades.\nFor more information and registration, visit the <a href=\"https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-live-webinar-kubernetes-132-release/\">event\npage</a>\non the CNCF Online Programs site.</p>\n<h2 id=\"get-involved\">Get involved</h2>\n<p>The simplest way to get involved with Kubernetes is by joining one of the many <a href=\"https://www.kubernetes.dev/community/community-groups/#special-interest-groups\">Special Interest\nGroups</a> (SIGs) that align with your\ninterests.\nHave something you‚Äôd like to broadcast to the Kubernetes community?\nShare your voice at our weekly <a href=\"https://github.com/kubernetes/community/tree/master/communication\">community meeting</a>,\nand through the channels below.\nThank you for your continued feedback and support.</p>\n<ul>\n<li>Follow us on Bluesky <a href=\"https://bsky.app/profile/did:plc:kyg4uikmq7lzpb76ugvxa6ul\">@Kubernetes.io</a> for latest updates</li>\n<li>Join the community discussion on <a href=\"https://discuss.kubernetes.io/\">Discuss</a></li>\n<li>Join the community on <a href=\"http://slack.k8s.io/\">Slack</a></li>\n<li>Post questions (or answer questions) on <a href=\"http://stackoverflow.com/questions/tagged/kubernetes\">Stack Overflow</a></li>\n<li>Share your Kubernetes\n<a href=\"https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform\">story</a></li>\n<li>Read more about what‚Äôs happening with Kubernetes on the <a href=\"https://kubernetes.io/blog/\">blog</a></li>\n<li>Learn more about the <a href=\"https://github.com/kubernetes/sig-release/tree/master/release-team\">Kubernetes Release Team</a></li>\n</ul>",
      "timestamp": 1741512160.532898,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "APM Alone Is Not Enough: Enter Internet Performance Monitoring",
      "link": "https://devops.com/apm-alone-is-not-enough-enter-internet-performance-monitoring/?utm_source=rss&utm_medium=rss&utm_campaign=apm-alone-is-not-enough-enter-internet-performance-monitoring",
      "published": "Fri, 07 Mar 2025 21:33:16 +0000",
      "summary": "<div><img alt=\"someone typing on a keyboard, DevOps news\" class=\"attachment-large size-large wp-post-image\" height=\"336\" src=\"https://devops.com/wp-content/uploads/2024/04/typing-on-keyboard-thomas-lefebvre-gp8BLyaTaA0-unsplash.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"someone typing on a keyboard, DevOps news\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2024/04/typing-on-keyboard-thomas-lefebvre-gp8BLyaTaA0-unsplash-150x150.jpg\" width=\"150\" />Key Takeaways: Application performance monitoring (APM) was built for a world that no longer exists‚Äîwhere applications ran in controlled environments. Cloud, APIs and the Internet are the substrate of digital experiences today, making Internet Performance Monitoring (IPM) an attractive approach to achieving the true visibility required to ensure reliability, resilience and user satisfaction. APM Was [&#8230;]",
      "timestamp": 1741512162.7272503,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Survey Surfaces Lack of DevOps Visibility into Consumption of Cloud Infrastructure",
      "link": "https://devops.com/survey-surfaces-lack-of-devops-visibility-into-consumption-of-cloud-infrastructure/?utm_source=rss&utm_medium=rss&utm_campaign=survey-surfaces-lack-of-devops-visibility-into-consumption-of-cloud-infrastructure",
      "published": "Fri, 07 Mar 2025 20:37:38 +0000",
      "summary": "<div><img alt=\"developers, finds, costs, tool sprawl, productivity, survey, IT, DevOps, industrial, devops, coding, platform, BMC Mainframe Survey\" class=\"attachment-large size-large wp-post-image\" height=\"432\" src=\"https://devops.com/wp-content/uploads/2023/08/survey-e1720497078508.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"developers, finds, costs, tool sprawl, productivity, survey, IT, DevOps, industrial, devops, coding, platform, BMC Mainframe Survey\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2023/08/survey-e1685038398145-150x150.jpg\" width=\"150\" />A survey of engineering leaders and developers from the U.S. and United Kingdom (UK) conducted by Harness finds less than half have access to real-time insights into idle cloud resources (43%), unused or orphaned resources (39%), and over or under-provisioned workloads.",
      "timestamp": 1741512162.7272549,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "DeepSource Open Sources Globstar Alternative to Semgrep to Analyze Code",
      "link": "https://devops.com/deepsource-open-sources-globstar-alternative-to-semgrep-to-analyze-code/?utm_source=rss&utm_medium=rss&utm_campaign=deepsource-open-sources-globstar-alternative-to-semgrep-to-analyze-code",
      "published": "Fri, 07 Mar 2025 16:21:13 +0000",
      "summary": "<div><img alt=\"code security\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/10/DevSecOps2.jpg\" style=\"margin-bottom: 0px;\" width=\"767\" /></div><img alt=\"code security\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/10/DevSecOps2-150x150.jpg\" width=\"150\" />DeepSource has made available an open source static code analysis tool, dubbed Globstar, that DevSecOps teams can employ to embed code checkers in their pipelines.",
      "timestamp": 1741512162.7272582,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Bad Actor Targets Linux, macOS Developers with Typosquatted Go Packages",
      "link": "https://devops.com/bad-actor-targets-linux-macos-developers-with-typosquatted-go-packages/?utm_source=rss&utm_medium=rss&utm_campaign=bad-actor-targets-linux-macos-developers-with-typosquatted-go-packages",
      "published": "Fri, 07 Mar 2025 13:03:49 +0000",
      "summary": "<div><img alt=\"Go, attacker,\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2021/06/Approaching-Security-as-a-Fundamental-Element-of-Software-Development.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"Go, attacker,\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2021/06/Approaching-Security-as-a-Fundamental-Element-of-Software-Development-150x150.jpg\" width=\"150\" />The attacker published at least seven malicious packages on the Go Module Mirror that, if installed, will deliver a backdoor.",
      "timestamp": 1741512162.7272615,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Critical Security Flaw Exposes Perforce Users to Administrative Takeover",
      "link": "https://devops.com/critical-security-flaw-exposes-perforce-users-to-administrative-takeover/?utm_source=rss&utm_medium=rss&utm_campaign=critical-security-flaw-exposes-perforce-users-to-administrative-takeover",
      "published": "Fri, 07 Mar 2025 06:05:45 +0000",
      "summary": "<div><img alt=\"perforce, software, attackers, vulnerability, open source security vulnerability\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/07/opensourcevulnerability.jpg\" style=\"margin-bottom: 0px;\" width=\"764\" /></div><img alt=\"perforce, software, attackers, vulnerability, open source security vulnerability\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/07/opensourcevulnerability-150x150.jpg\" width=\"150\" />Perforce software faces a severe authentication bypass vulnerability affecting all versions, allowing attackers to gain full administrative access without authentication.",
      "timestamp": 1741512162.727265,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Survey Pinpoints Inhibitors of Java Developer Productivity",
      "link": "https://devops.com/survey-pinpoints-inhibitors-of-java-developer-productivity/?utm_source=rss&utm_medium=rss&utm_campaign=survey-pinpoints-inhibitors-of-java-developer-productivity",
      "published": "Thu, 06 Mar 2025 17:23:53 +0000",
      "summary": "<div><img alt=\"Java, productivity, developer, platform, startups, CraC, Spring OpenJDK Java\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/09/java2.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"Java, productivity, developer, platform, startups, CraC, Spring OpenJDK Java\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/09/java2-150x150.jpg\" width=\"150\" />A survey of 731 developers, team leads, managers and executives who work with Java pinpoints inhibitors of Java developer productivity.",
      "timestamp": 1741512162.7272685,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Dynatrace Acquires Metis: Revolutionizing Database Observability with AI",
      "link": "https://devops.com/dynatrace-acquires-metis-revolutionizing-database-observability-with-ai/?utm_source=rss&utm_medium=rss&utm_campaign=dynatrace-acquires-metis-revolutionizing-database-observability-with-ai",
      "published": "Thu, 06 Mar 2025 16:21:33 +0000",
      "summary": "<div><img alt=\"Dynatrace, observability, telemetry, New Relic, Observe, Gen AI, Generative AI, modern, applications, risk, observability, AI, unified observability, binoculars\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2024/04/binoculars-observability-details-tito-pixel-KBPzLjwdFbI-unsplash-1.jpg\" style=\"margin-bottom: 0px;\" width=\"769\" /></div><img alt=\"Dynatrace, observability, telemetry, New Relic, Observe, Gen AI, Generative AI, modern, applications, risk, observability, AI, unified observability, binoculars\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2024/04/binoculars-observability-details-tito-pixel-KBPzLjwdFbI-unsplash-1-150x150.jpg\" width=\"150\" />Dynatrace's acquisition of Metis brings AI-powered database observability to DevOps teams, enhancing troubleshooting and optimization for developers and SREs.",
      "timestamp": 1741512162.7272713,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Building Complex Software at Scale with Tameem Hourani",
      "link": "https://devops.com/building-complex-software-at-scale-with-tameem-hourani/?utm_source=rss&utm_medium=rss&utm_campaign=building-complex-software-at-scale-with-tameem-hourani",
      "published": "Thu, 06 Mar 2025 16:20:03 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/11/CICD-Best-Practiced-for-Software-Development.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/11/CICD-Best-Practiced-for-Software-Development-150x150.jpg\" width=\"150\" />RapDev founder Tameem Hourani dives into what it really takes for software engineering teams to develop and deploy complex software at scale. Hourani talks about the challenges of maintaining a blameless culture in DevOps, even as software complexity continues to grow. The discussion explores how teams can strike a balance between rapid innovation and system [&#8230;]",
      "timestamp": 1741512162.727275,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Profiles, Traces and the Power of Unified Telemetry Data",
      "link": "https://devops.com/profiles-traces-and-the-power-of-unified-telemetry-data/?utm_source=rss&utm_medium=rss&utm_campaign=profiles-traces-and-the-power-of-unified-telemetry-data",
      "published": "Wed, 05 Mar 2025 15:39:48 +0000",
      "summary": "<div><img alt=\"profiles, metrics, performance, optimized metrics services MTTR DORA metrics Perforce Helix Software delivery metrics\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/04/Software-delivery-metrics.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"profiles, metrics, performance, optimized metrics services MTTR DORA metrics Perforce Helix Software delivery metrics\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/04/Software-delivery-metrics-150x150.jpg\" width=\"150\" />Metrics, logs, traces and profiles hold information that businesses need to run more cost-effective and resilient infrastructure.",
      "timestamp": 1741512162.727278,
      "translated": false
    },
    {
      "feed_name": "DevOps.com Kubernetes Section",
      "source_language": "en",
      "title": "Revolutionizing CI/CD with Low-Code/No-Code: Streamlining DevOps Workflows",
      "link": "https://devops.com/revolutionizing-ci-cd-with-low-code-no-code-streamlining-devops-workflows/?utm_source=rss&utm_medium=rss&utm_campaign=revolutionizing-ci-cd-with-low-code-no-code-streamlining-devops-workflows",
      "published": "Wed, 05 Mar 2025 12:20:05 +0000",
      "summary": "<div><img alt=\"CI/CD, LC/NC, low code, tools, crowdstrike, Microsoft CrowdStrike update outage\" class=\"attachment-large size-large wp-post-image\" height=\"330\" src=\"https://devops.com/wp-content/uploads/2020/11/How-Low-Code-Is-Transforming-Software-Development.jpg\" style=\"margin-bottom: 0px;\" width=\"770\" /></div><img alt=\"CI/CD, LC/NC, low code, tools, crowdstrike, Microsoft CrowdStrike update outage\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://devops.com/wp-content/uploads/2020/11/How-Low-Code-Is-Transforming-Software-Development-150x150.jpg\" width=\"150\" />Low-code/no-code (LCNC) platforms now enable organizations to implement CI/CD using an automation system that enables people with little or no coding experience to build and modify applications.",
      "timestamp": 1741512162.7272813,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Vulnerability-Free Java Containers: A Practical Guide",
      "link": "https://thenewstack.io/vulnerability-free-java-containers-a-practical-guide/",
      "published": "Sat, 08 Mar 2025 17:00:50 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"682\" src=\"https://cdn.thenewstack.io/media/2025/03/28dac346-coffee-3077843_1280-1024x682.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>In today&#8217;s cloud native landscape, securing Java applications isn&#8217;t just about the code we write but the entire container stack.</p>\n<p>The post <a href=\"https://thenewstack.io/vulnerability-free-java-containers-a-practical-guide/\">Vulnerability-Free Java Containers: A Practical Guide</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224205,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "KDE Neon Is the Linux Distribution With the Dynamic Desktop",
      "link": "https://thenewstack.io/kde-neon-is-the-linux-distribution-with-the-dynamic-desktop/",
      "published": "Sat, 08 Mar 2025 15:00:21 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"637\" src=\"https://cdn.thenewstack.io/media/2025/03/79f58a6f-neaonhero-1-1024x637.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>There&#8217;s no debating that Linux is rife with choice. It doesn&#8217;t matter what application we&#8217;re talking about, Linux has multiple</p>\n<p>The post <a href=\"https://thenewstack.io/kde-neon-is-the-linux-distribution-with-the-dynamic-desktop/\">KDE Neon Is the Linux Distribution With the Dynamic Desktop</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224255,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "GitHub Rolls Out Free Secret Risk Assessment Tool",
      "link": "https://thenewstack.io/github-rolls-out-free-secret-risk-assessment-tool/",
      "published": "Sat, 08 Mar 2025 14:00:57 +0000",
      "summary": "<img alt=\"Dev News logo\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"577\" src=\"https://cdn.thenewstack.io/media/2024/04/d8b458d6-dev_news_img-2-2-1024x577.png\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>GitHub is introducing a free secret risk assessment tool to help development organizations understand their secret leak exposure across GitHub.</p>\n<p>The post <a href=\"https://thenewstack.io/github-rolls-out-free-secret-risk-assessment-tool/\">GitHub Rolls Out Free Secret Risk Assessment Tool</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224293,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Developer Review of Warp for Windows, an AI Terminal App",
      "link": "https://thenewstack.io/developer-review-of-warp-for-windows-an-ai-terminal-app/",
      "published": "Sat, 08 Mar 2025 13:00:59 +0000",
      "summary": "<img alt=\"warp\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"576\" src=\"https://cdn.thenewstack.io/media/2025/03/287fd338-mathew-schwartz-sb7rurrmac4-unsplashb-1024x576.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>While I have been using the Warp terminal on my MacBook for some time, there has always been one problem:</p>\n<p>The post <a href=\"https://thenewstack.io/developer-review-of-warp-for-windows-an-ai-terminal-app/\">Developer Review of Warp for Windows, an AI Terminal App</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224336,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Anthropic‚Äôs MCP Bridges LLMs to the Apps They Need",
      "link": "https://thenewstack.io/model-context-protocol-bridges-llms-to-the-apps-they-need/",
      "published": "Fri, 07 Mar 2025 19:30:04 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"683\" src=\"https://cdn.thenewstack.io/media/2025/03/da0fefca-tamanna-rumee-8yd0ndi1shy-unsplash-mcp-1024x683.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>&#8220;This is very much like microservices, but we are bringing in intelligence,&#8221; said Mahesh Murag, Anthropic engineer for applied AI,</p>\n<p>The post <a href=\"https://thenewstack.io/model-context-protocol-bridges-llms-to-the-apps-they-need/\">Anthropic&#8217;s MCP Bridges LLMs to the Apps They Need</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224374,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Magic Methods: The Secret to Elegant Python Code",
      "link": "https://thenewstack.io/magic-methods-the-secret-to-elegant-python-code/",
      "published": "Fri, 07 Mar 2025 19:00:05 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"682\" src=\"https://cdn.thenewstack.io/media/2025/02/1f29e963-magic-1081149_1280-1024x682.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>There is a way to make Python objects behave and read more like real-world actions and conversation. You can do</p>\n<p>The post <a href=\"https://thenewstack.io/magic-methods-the-secret-to-elegant-python-code/\">Magic Methods: The Secret to Elegant Python Code</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224412,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Choosing Manual or Auto-Instrumentation for Mobile Observability",
      "link": "https://thenewstack.io/choosing-manual-or-auto-instrumentation-for-mobile-observability/",
      "published": "Fri, 07 Mar 2025 18:30:57 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"576\" src=\"https://cdn.thenewstack.io/media/2025/03/e1131f83-embrace-1024x576.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>As applications run in production, you&#8217;ll need to find out what&#8217;s happening. You might want to know if you&#8217;re overloading</p>\n<p>The post <a href=\"https://thenewstack.io/choosing-manual-or-auto-instrumentation-for-mobile-observability/\">Choosing Manual or Auto-Instrumentation for Mobile Observability</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.422445,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "How AI Is Reshaping Software Engineering: Key Takeaways From DeveloperWeek 2025",
      "link": "https://thenewstack.io/how-ai-is-reshaping-software-engineering-key-takeaways-from-developerweek-2025/",
      "published": "Fri, 07 Mar 2025 18:00:35 +0000",
      "summary": "<img alt=\"\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"768\" src=\"https://cdn.thenewstack.io/media/2025/03/35ed70ad-mimi-thian-5zns3wk6sug-unsplash-1024x768.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>AI is transforming how software is built, happening faster than most of us expected. But what does this shift mean</p>\n<p>The post <a href=\"https://thenewstack.io/how-ai-is-reshaping-software-engineering-key-takeaways-from-developerweek-2025/\">How AI Is Reshaping Software Engineering: Key Takeaways From DeveloperWeek 2025</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224489,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "Streamlining Kubernetes Implementation With GitOps: Best Practices",
      "link": "https://thenewstack.io/streamlining-kubernetes-implementation-with-gitops-best-practices/",
      "published": "Fri, 07 Mar 2025 17:30:11 +0000",
      "summary": "<img alt=\"&quot;Streamlining Kubernetes Implementation with GitOps&quot; featued image\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"576\" src=\"https://cdn.thenewstack.io/media/2025/03/8fbb0dae-streamline-kubernetes-gitops-1024x576.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>In the fast-paced world of modern software development, organizations are constantly seeking ways to accelerate the delivery of applications while</p>\n<p>The post <a href=\"https://thenewstack.io/streamlining-kubernetes-implementation-with-gitops-best-practices/\">Streamlining Kubernetes Implementation With GitOps: Best Practices</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224524,
      "translated": false
    },
    {
      "feed_name": "The New Stack Kubernetes",
      "source_language": "en",
      "title": "How to Run DeepSeek Models Locally on a Windows Copilot+ PC",
      "link": "https://thenewstack.io/how-to-run-deepseek-models-locally-on-a-windows-copilot-pc/",
      "published": "Fri, 07 Mar 2025 17:00:53 +0000",
      "summary": "<img alt=\"DeepSeek\" class=\"webfeedsFeaturedVisual wp-post-image wp-stateless-item\" height=\"576\" src=\"https://cdn.thenewstack.io/media/2025/03/f8fb3b89-pexels-bertellifotografia-30530416b-1024x576.jpg\" style=\"display: block; margin: auto; margin-bottom: 20px;\" width=\"1024\" /><p>With the Windows 11 version 24H2, Microsoft has enabled access to the Neural Processing Unit (NPU) on Copilot+ PCs. Although</p>\n<p>The post <a href=\"https://thenewstack.io/how-to-run-deepseek-models-locally-on-a-windows-copilot-pc/\">How to Run DeepSeek Models Locally on a Windows Copilot+ PC</a> appeared first on <a href=\"https://thenewstack.io\">The New Stack</a>.</p>",
      "timestamp": 1741512163.4224563,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #423",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-423/",
      "published": "Fri, 07 Mar 2025 16:35:12 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines Join us...",
      "timestamp": 1741512164.0267434,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #422",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-422/",
      "published": "Fri, 28 Feb 2025 16:48:33 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines ¬†The StrimziCon...",
      "timestamp": 1741512164.0267484,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #421",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-421/",
      "published": "Fri, 21 Feb 2025 16:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines Attending KubeCon...",
      "timestamp": 1741512164.0267525,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #420",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-420/",
      "published": "Fri, 14 Feb 2025 16:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines Want to...",
      "timestamp": 1741512164.0267563,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #419",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-419/",
      "published": "Fri, 07 Feb 2025 15:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines The End...",
      "timestamp": 1741512164.02676,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #418",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-418/",
      "published": "Fri, 31 Jan 2025 16:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines KubeCon +...",
      "timestamp": 1741512164.026764,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #417",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-417/",
      "published": "Fri, 24 Jan 2025 14:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines Announcing the...",
      "timestamp": 1741512164.0267673,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #416",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-416/",
      "published": "Fri, 17 Jan 2025 14:00:00 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Headlines KubeCon +...",
      "timestamp": 1741512164.0267708,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #415",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-415/",
      "published": "Fri, 10 Jan 2025 16:46:35 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. Events KubeCon +...",
      "timestamp": 1741512164.0267746,
      "translated": false
    },
    {
      "feed_name": "KubeWeekly by CNCF",
      "source_language": "en",
      "title": "KubeWeekly #414",
      "link": "https://www.cncf.io/kubeweekly/kubeweekly-414/",
      "published": "Fri, 20 Dec 2024 14:58:22 +0000",
      "summary": "Table of Contents KubeWeekly‚Äîthe newsletter for all things Kubernetes and beyond Find out more about the KubeWeekly newsletter and join the list to receive an email each time a new issue is available. KubeCon + CloudNativeCon...",
      "timestamp": 1741512164.0267782,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Preparing for the DeepSeek moment in your industry: Adapt to change in 2025",
      "link": "https://www.redhat.com/en/blog/preparing-deepseek-moment-your-industry-adapt-change-2025",
      "published": "Fri, 07 Mar 2025 00:00:00 +0000",
      "summary": "There‚Äôs an old saying that the only constant in the technology world is change. Like it or not, the pace of change for IT professionals is going to rapidly increase in 2025 and the coming years.Let‚Äôs ponder a simple question: What is the DeepSeek moment in your industry? For several years, the IT industry believed that the only way to achieve breakthroughs in artificial intelligence (AI) was to build the biggest clusters, spend the most training dollars, and make large language models (LLMs) proprietary. But as new LLMs emerged with open source and open use licenses, creativity was unlocke",
      "timestamp": 1741512164.179823,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Friday Five ‚Äî March 7, 2025",
      "link": "https://www.redhat.com/en/blog/friday-five-march-7-2025-red-hat",
      "published": "Fri, 07 Mar 2025 00:00:00 +0000",
      "summary": "Red Hat MWC Barcelona NewsroomCheck out Red Hat's MWC Barcelona news! From service providers standardizing on Red Hat platforms to major cloud-native transformations and AI innovations, our open source technologies and partner ecosystem are driving telecom innovation. Learn more. Learn more  SiliconANGLE: Red Hat cozies up with telecom providers as open standards gain tractionRed Hat is taking advantage of the growing popularity of the Open Radio Access Network and the related Artificial Intelligence RAN specification to highlight a number of new partnerships it has forged with telecommunicat",
      "timestamp": 1741512164.1798272,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Top 5 reasons to go with your team to Red Hat Summit 2025",
      "link": "https://www.redhat.com/en/blog/top-5-reasons-go-your-team-red-hat-summit-2025",
      "published": "Thu, 06 Mar 2025 00:00:00 +0000",
      "summary": "Staying ahead of the curve in today‚Äôs market requires continuous learning, constant collaboration and innovation. Red Hat Summit is the premiere tech conference for all things Red Hat and open source. But it's more than just a conference. Red Hat Summit is an opportunity for your team to gain firsthand insights, to build expertise, and most importantly, to bring back strategies that result in real business impact.Here‚Äôs why investing in your team‚Äôs attendance is a strategic move for your organization:  1. Strengthen your team‚Äôs proficiency with Red Hat technologies and subscriptions Wh",
      "timestamp": 1741512164.1798308,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Performance and energy consumption: comparing CPU virtualization and emulation efficiency",
      "link": "https://www.redhat.com/en/blog/performance-and-energy-consumption-comparing-cpu-virtualization-and-emulation-efficiency",
      "published": "Thu, 06 Mar 2025 00:00:00 +0000",
      "summary": "Recently, when my workplace laptop needed a hardware refresh and I wanted to replace it with an ARM-based laptop with Linux (a MacBook), I was tasked with comparing the efficiency of using CPU virtualization versus emulation.This article presents my research and benchmark data comparing the performance and power consumption of workloads running under virtualization and emulation.We live in exciting times: After many years with the x86 architecture dominating the market, there are new players. For some years, Amazon has been offering Graviton instances, which consists of using an ARM-based CPU",
      "timestamp": 1741512164.1798341,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "How Ansible Automation Platform supports your automation community of practice",
      "link": "https://www.redhat.com/en/blog/how-ansible-automation-platform-supports-your-automation-community-practice",
      "published": "Thu, 06 Mar 2025 00:00:00 +0000",
      "summary": "As we've shared in recent blogs, bringing teams together to form an automation community of practice can accelerate adoption of Red Hat Ansible Automation Platform across your organization and help you achieve better results with your automation faster. It can also help you advance your automation maturity so you can get more value from all of your IT investments. Today I want to talk about some of the specific features available within Ansible Automation Platform that directly support your community of practice, particularly as you work together to: Standardize your automation development too",
      "timestamp": 1741512164.1798375,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Charge back the cost of OpenShift Virtualization with Red Hat Insights cost management",
      "link": "https://www.redhat.com/en/blog/charge-back-cost-openshift-virtualization-red-hat-insights-cost-management",
      "published": "Thu, 06 Mar 2025 00:00:00 +0000",
      "summary": "Red Hat OpenShift Virtualization, included in Red Hat OpenShift, provides a modern platform for you to run and deploy your new and existing virtual machine (VM) workloads. You may run Red Hat Enterprise Linux, CentOS, and other third-party operating system guests on OpenShift Virtualization.In layman's terms, OpenShift Virtualization runs VMs inside of pods on a namespace on a cluster. Since VMs will be running on a multitenant platform (Red Hat OpenShift), you may want to take advantage of showback and chargeback capabilities of OpenShift Virtualization VMs.The cost management service in Red",
      "timestamp": 1741512164.1798408,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Using Oracle Cloud Infrastructure with bare metal and on-prem Red Hat OpenShift",
      "link": "https://www.redhat.com/en/blog/using-oracle-cloud-infrastructure-bare-metal-and-prem-openshift",
      "published": "Wed, 05 Mar 2025 00:00:00 +0000",
      "summary": "Red Hat OpenShift 4.18 now includes general availability support for Oracle Cloud Infrastructure (OCI) bare metal instances, as well as Oracle‚Äôs on-prem solutions, Oracle Compute Cloud@Customer (C3) and Oracle Private Cloud Appliance (PCA). This expansion aligns with the latest OpenShift 4.18 features, providing you greater flexibility when deploying OpenShift, and enabling a seamless hybrid cloud experience.This collaboration (two years in the making) enhances OpenShift‚Äôs availability on Oracle‚Äôs infrastructure, giving customers a consistent Kubernetes experience across environments. Wh",
      "timestamp": 1741512164.1798441,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Automate the full lifecycle of virtual infrastructure operations",
      "link": "https://www.redhat.com/en/blog/automate-full-lifecycle-virtual-infrastructure-operations",
      "published": "Wed, 05 Mar 2025 00:00:00 +0000",
      "summary": "Virtualization has been a key underlying technology for critical business applications. At its inception, virtualization improved hardware utilization, made IT more efficient and helped reduce costs. As a result, virtual infrastructure became an important part of IT operational technologies, and it remains in use today for many of the same reasons. A variety of business applications run in virtualized environments. As with other components of the IT stack, they need to be managed. But virtual machines (VMs) are only part of the equation. There's a host of related infrastructure which can vary",
      "timestamp": 1741512164.1798477,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Thinking big, starting small: why focused AI is set to win in 2025",
      "link": "https://www.redhat.com/en/blog/thinking-big-starting-small-why-focused-ai-set-win-2025",
      "published": "Tue, 04 Mar 2025 00:00:00 +0000",
      "summary": "In recent conversations with Red Hat customers, when the chat inevitably turns to AI, I‚Äôve found myself frequently repeating the same mantra: small can be beautiful. Let me explain. It certainly doesn‚Äôt hurt to think big when it comes to AI. The opportunities that this technology promises are huge. Customers are entirely justified in having bold, ambitious plans to capture those opportunities. At the same time, I‚Äôm seeing plenty of companies notch up rapid wins with AI by narrowing their focus and thinking smaller. What they have in common is their concentration on very specific workplac",
      "timestamp": 1741512164.1798513,
      "translated": false
    },
    {
      "feed_name": "Red Hat Kubernetes Blog",
      "source_language": "en",
      "title": "Session catalog and agenda builder for Red Hat Summit & AnsibleFest 2025 now available",
      "link": "https://www.redhat.com/en/blog/session-catalog-and-agenda-builder-red-hat-summit-ansiblefest-2025-now-available",
      "published": "Tue, 04 Mar 2025 00:00:00 +0000",
      "summary": "We‚Äôre all counting down the days until Red Hat Summit and AnsibleFest 2025 descends on the Boston Convention  Exhibition Center, May 19-22, 2025. With only 76 days to go, now is the time to start planning your experience. Use our session catalog and agenda builder to begin mapping out your week full of keynotes, hands-on labs, breakout sessions, networking opportunities and more!But first things first, if you haven‚Äôt registered, what are you waiting for? Click here to register now.The Red Hat Summit 2025 session catalog gives you a quick and easy way to see summaries for hundreds of exciti",
      "timestamp": 1741512164.1798546,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Kubectl Quick Reference 2025",
      "link": "https://collabnix.com/kubectl-quick-reference-2025/",
      "published": "Sat, 01 Mar 2025 18:44:13 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2020/05/Kubernetes-2.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Kubectl is the command-line interface for interacting with Kubernetes clusters. It allows you to deploy applications, inspect and manage cluster resources, and view logs. This cheatsheet provides a comprehensive reference of commonly used kubectl commands, organized by operation type. Whether you&#8217;re new to Kubernetes or an experienced administrator, this guide will help you quickly find [&#8230;]",
      "timestamp": 1741512165.625187,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Deploy DeepSeek-R1 using Ollama-Operator on Kubernetes",
      "link": "https://collabnix.com/deploy-deepseek-r1-using-ollama-operator-on-kubernetes/",
      "published": "Thu, 27 Feb 2025 03:50:51 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2025/02/Teal-Futuristic-Technology-Facebook-Cover.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Introduction to DeepSeek-R1 and Ollama In the era of generative AI, efficiently deploying large language models (LLMs) in production environments has become crucial for developers and organizations. DeepSeek-R1 is a powerful quantitative LLM developed for complex natural language processing tasks, offering state-of-the-art performance in text generation, question answering, and semantic analysis. Its optimized architecture makes [&#8230;]",
      "timestamp": 1741512165.6251917,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "How to Install and Set Up Kubectl ‚Äì Kubernetes",
      "link": "https://collabnix.com/how-to-install-and-set-up-kubectl-kubernetes/",
      "published": "Fri, 10 Jan 2025 04:10:12 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2025/01/Screenshot-2025-01-10-at-9.38.59%E2%80%AFAM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Kubernetes, the leading container orchestration platform, requires an efficient tool to interact with its clusters. Enter kubectl, the command-line interface (CLI) that simplifies Kubernetes management. This guide will walk you through installing and configuring kubectl so you can seamlessly manage your Kubernetes clusters. Prerequisites Before you begin, ensure the following: Step 1: Download kubectl The [&#8230;]",
      "timestamp": 1741512165.6251957,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Kubernetes Vs  Amazon EKS:What is the difference?",
      "link": "https://collabnix.com/kubernetes-vs-amazon-ekswhat-is-the-difference/",
      "published": "Thu, 09 Jan 2025 09:53:30 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail not-transparent wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2025/01/awsvseks.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Deploying containerized applications on AWS involves a critical decision: Should you manage Kubernetes yourself on EC2 instances, or leverage Amazon‚Äôs managed Elastic Kubernetes Service (EKS)? This choice significantly affects your organization‚Äôs operational efficiency, cost management, and scalability. By exploring the key differences between self-managed Kubernetes and EKS, you can make an informed decision tailored to [&#8230;]",
      "timestamp": 1741512165.6251996,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Deep Dive into Kubernetes Source Code",
      "link": "https://collabnix.com/deep-dive-into-kubernetes-source-code/",
      "published": "Tue, 31 Dec 2024 06:17:44 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-11.47.28%E2%80%AFAM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Kubernetes, the world‚Äôs most popular container orchestration platform, is an open-source powerhouse. With its rapid evolution and adoption, it‚Äôs essential for contributors and enthusiasts to understand the structure and processes underlying its development. In this article, we will explore the Kubernetes source code repository in detail, analyze its stars, contributors, and branching strategy as of [&#8230;]",
      "timestamp": 1741512165.6252034,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "How to Get the Kubestronaut Jacket?",
      "link": "https://collabnix.com/how-to-get-the-kubestronaut-jacket/",
      "published": "Mon, 30 Dec 2024 14:47:57 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail not-transparent wp-post-image\" height=\"150\" src=\"https://usercontent.one/wp/collabnix.com/wp-content/uploads/2024/12/linkedin_thumb_image-150x150.avif?media=1736482966\" width=\"150\" />If you&#8217;re a part of the Kubernetes community, chances are you&#8217;ve heard about the exclusive Kubestronaut jacket. This iconic jacket is more than just a stylish piece of swag‚Äîit‚Äôs a badge of honor, symbolizing your contributions and engagement within the Kubernetes ecosystem. So, how do you get your hands on one? Let‚Äôs explore. What is [&#8230;]",
      "timestamp": 1741512165.6252072,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "What is Kubernetes in DevOps",
      "link": "https://collabnix.com/what-is-kubernetes-in-devops/",
      "published": "Fri, 27 Dec 2024 11:31:14 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.00.42%E2%80%AFPM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />In the ever-evolving world of DevOps, the need for automation, scalability, and seamless application deployment has led to the rise of containerization. Among the tools driving this shift, Kubernetes has emerged as the gold standard for managing containers. But what exactly is Kubernetes, and why is it a cornerstone of modern DevOps practices? Let‚Äôs dive [&#8230;]",
      "timestamp": 1741512165.6252112,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "20 Kubernetes RSS Feeds that You Must Follow",
      "link": "https://collabnix.com/20-kubernetes-rss-feeds-that-you-must-follow/",
      "published": "Fri, 27 Dec 2024 08:45:36 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2024/12/Screenshot-2024-12-25-at-1.13.46%E2%80%AFPM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />In the world of DevOps and cloud-native technologies, Kubernetes stands out as the go-to platform for automating deployment, scaling, and management of containerized applications. To stay on top of the latest advancements, tips, and tutorials, following the right Kubernetes feeds is essential. Here are the top 20 Kubernetes feeds in 2025 to help you stay [&#8230;]",
      "timestamp": 1741512165.6252148,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Does Kubernetes Have a Future? A Technical Deep Dive and Analysis",
      "link": "https://collabnix.com/does-kubernetes-have-a-future-a-technical-deep-dive-and-analysis/",
      "published": "Sat, 21 Dec 2024 07:13:31 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2024/12/Screenshot-2024-12-21-at-12.45.56%E2%80%AFPM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />Since its inception in 2014, Kubernetes has revolutionized the way we think about deploying and managing containerized applications. As the orchestrator of choice for many organizations, Kubernetes has become synonymous with cloud-native infrastructure. However, with the rapid evolution of technology and new paradigms emerging in the tech landscape, it‚Äôs fair to ask: does Kubernetes have [&#8230;]",
      "timestamp": 1741512165.6252186,
      "translated": false
    },
    {
      "feed_name": "Collabnix Blog",
      "source_language": "en",
      "title": "Docker or Kubernetes: Which One is Right for You?",
      "link": "https://collabnix.com/docker-or-kubernetes-which-one-is-right-for-you/",
      "published": "Sun, 15 Dec 2024 12:24:37 +0000",
      "summary": "<img alt=\"\" class=\"attachment-thumbnail size-thumbnail wp-post-image\" height=\"150\" src=\"https://i0.wp.com/collabnix.com/wp-content/uploads/2024/12/Screenshot-2024-12-15-at-5.57.57%E2%80%AFPM.png?resize=150%2C150&amp;ssl=1\" width=\"150\" />In the world of modern application deployment, two names frequently dominate conversations: Docker and Kubernetes. While they are often mentioned together, it‚Äôs essential to understand that Docker and Kubernetes serve distinct purposes. Docker focuses on development, while Kubernetes focuses on deployment. This post explores the differences, use cases, and how they work together. What is [&#8230;]",
      "timestamp": 1741512165.6252222,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "From Risk to ROI: Making Security Insights Matter to Business Leaders",
      "link": "https://sysdig.com/blog/from-risk-to-roi-making-security-insights-matter-to-business-leaders/",
      "published": "Thu, 06 Mar 2025 15:00:00 +0000",
      "summary": "<p>In today‚Äôs technology landscape, security leaders often find themselves under immense pressure: their resource-constrained teams are expected to mitigate growing...</p>\n<p>The post <a href=\"https://sysdig.com/blog/from-risk-to-roi-making-security-insights-matter-to-business-leaders/\">From Risk to ROI: Making Security Insights Matter to Business Leaders</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152647,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "In-use vulnerability prioritization",
      "link": "https://sysdig.com/blog/smarter-vulnerability-management-with-in-use-prioritization/",
      "published": "Tue, 04 Mar 2025 14:50:00 +0000",
      "summary": "<p>Vulnerability management has always been a challenge, but today‚Äôs security teams are feeling the pressure more than ever. With thousands...</p>\n<p>The post <a href=\"https://sysdig.com/blog/smarter-vulnerability-management-with-in-use-prioritization/\">In-use vulnerability prioritization</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.11527,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Introducing Sysdig Threat Management: Combating threats in cloud security",
      "link": "https://sysdig.com/blog/introducing-sysdig-threat-management/",
      "published": "Thu, 27 Feb 2025 14:55:19 +0000",
      "summary": "<p>Cloud security teams are often faced with an onslaught of noise from their detection tooling, making it nearly impossible to...</p>\n<p>The post <a href=\"https://sysdig.com/blog/introducing-sysdig-threat-management/\">Introducing Sysdig Threat Management: Combating threats in cloud security</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152735,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Inline response actions: Streamlining incident response in the cloud",
      "link": "https://sysdig.com/blog/streamline-incident-response-in-the-cloud-with-inline-response-actions/",
      "published": "Thu, 27 Feb 2025 14:50:00 +0000",
      "summary": "<p>Threat response is a cornerstone of cloud security, but its roots lie in the early days of antivirus software. Back...</p>\n<p>The post <a href=\"https://sysdig.com/blog/streamline-incident-response-in-the-cloud-with-inline-response-actions/\">Inline response actions: Streamlining incident response in the cloud</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.115277,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Extending Falco for Bitcoin",
      "link": "https://sysdig.com/blog/falco-for-bitcoin/",
      "published": "Tue, 25 Feb 2025 14:45:00 +0000",
      "summary": "<p>Plugins are shared libraries that conform to a documented API, hooking into the core functionalities of Falco to allow things...</p>\n<p>The post <a href=\"https://sysdig.com/blog/falco-for-bitcoin/\">Extending Falco for Bitcoin</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152809,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Top cloud misconfigurations: A CSPM perspective",
      "link": "https://sysdig.com/blog/top-cloud-misconfigurations/",
      "published": "Wed, 19 Feb 2025 16:00:00 +0000",
      "summary": "<p>Organizations benefit from the speed of the cloud, but with great power comes great responsibility. An inadvertent cloud misconfiguration can...</p>\n<p>The post <a href=\"https://sysdig.com/blog/top-cloud-misconfigurations/\">Top cloud misconfigurations: A CSPM perspective</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152847,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Introducing Vulnerability Management Enhancements for Sysdig Secure: Focus on Action",
      "link": "https://sysdig.com/blog/introducing-vulnerability-management-enhancements-for-sysdig-secure/",
      "published": "Wed, 19 Feb 2025 14:50:00 +0000",
      "summary": "<p>Vulnerability management in the cloud is more challenging than ever. Security teams are drowning in vulnerability alerts, asked to deal...</p>\n<p>The post <a href=\"https://sysdig.com/blog/introducing-vulnerability-management-enhancements-for-sysdig-secure/\">Introducing Vulnerability Management Enhancements for Sysdig Secure: Focus on Action</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152883,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "Cloud invaders: Spotting compromised users before it‚Äôs too late",
      "link": "https://sysdig.com/blog/spotting-compromised-users/",
      "published": "Wed, 12 Feb 2025 15:15:00 +0000",
      "summary": "<p>Identities have become one of the most common ways modern threat actors gain a foothold in the cloud. From stolen...</p>\n<p>The post <a href=\"https://sysdig.com/blog/spotting-compromised-users/\">Cloud invaders: Spotting compromised users before it‚Äôs too late</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152918,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "LLMjacking targets DeepSeek",
      "link": "https://sysdig.com/blog/llmjacking-targets-deepseek/",
      "published": "Fri, 07 Feb 2025 14:45:00 +0000",
      "summary": "<p>The frequency and popularity of LLMjacking attacks are increasing. Given that trend, it isn't surprising that DeepSeek is being targeted days of its media virality and spike in usage. </p>\n<p>The post <a href=\"https://sysdig.com/blog/llmjacking-targets-deepseek/\">LLMjacking targets DeepSeek</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152952,
      "translated": false
    },
    {
      "feed_name": "Sysdig Kubernetes Blog",
      "source_language": "en",
      "title": "MySpace? Your security",
      "link": "https://sysdig.com/blog/myspace-top-8-cybersecurity-goals-for-2025/",
      "published": "Wed, 05 Feb 2025 14:50:00 +0000",
      "summary": "<p>In the early 2000s, one of the hardest choices many of us faced online was selecting our MySpace &#8220;Top 8&#8221;...</p>\n<p>The post <a href=\"https://sysdig.com/blog/myspace-top-8-cybersecurity-goals-for-2025/\">MySpace? Your security</a> appeared first on <a href=\"https://sysdig.com\">Sysdig</a>.</p>",
      "timestamp": 1741512166.1152987,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Unified Observability with VMware Operations for Applications",
      "link": "https://blogs.vmware.com/management/2023/09/unified-observability-aria-operations-for-applications.html",
      "published": "Thu, 28 Sep 2023 12:00:00 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"122\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/09/metrics_logs_traces_dashboard.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>You‚Äôre big on data and so are we. Data is essential for us to understand how our applications are performing, get visibility into events and errors, and proactively rectify problem areas for better business agility. Developers are faced with challenges when it comes to managing data and their private, public, and multi-cloud environments. Disparate tools &#8230; <a href=\"https://blogs.vmware.com/management/2023/09/unified-observability-aria-operations-for-applications.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/09/unified-observability-aria-operations-for-applications.html\">Unified Observability with VMware Operations for Applications</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851204,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Unified Observability with Logs in VMware Aria Operations of Applications",
      "link": "https://blogs.vmware.com/management/2023/09/unified-observability-with-logs.html",
      "published": "Thu, 21 Sep 2023 02:04:52 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"82\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/09/OpApps_TracesToLogs_BlogPicture.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>Unified Observability is a well-rounded look into your applications and infrastructure across your full stack ‚Ä¶giving platform and application developers and even SRE engineers a deeper look into issues and infrastructure, sometimes even before they snowball into a bigger problem. VMware Aria Operations for Applications has knocked it out of the park with the general &#8230; <a href=\"https://blogs.vmware.com/management/2023/09/unified-observability-with-logs.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/09/unified-observability-with-logs.html\">Unified Observability with Logs in VMware Aria Operations of Applications</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.085126,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "What‚Äôs New in VMware Aria Operations for Applications ‚Äì August 2023",
      "link": "https://blogs.vmware.com/management/2023/08/vmware-aria-operations-for-applications.html",
      "published": "Fri, 11 Aug 2023 15:00:00 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"170\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/08/OpApps_Logs_BlogPicture.png?w=199\" style=\"margin-bottom: 10px;\" width=\"199\" /></div>\n<p>*Formerly Tanzu Observability aka Wavefront by VMware&#160; We are very excited to announce the latest updates for‚ÄØVMware Aria Operations for Applications. With this release we are able to unify Metrics, Traces, and Logs in a single-pane-of-glass, effectively unifying the three pillars of observability, so as to empower Cloud Administrators, Operators, SREs (site reliability engineers) and &#8230; <a href=\"https://blogs.vmware.com/management/2023/08/vmware-aria-operations-for-applications.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/08/vmware-aria-operations-for-applications.html\">What‚Äôs New in VMware Aria Operations for Applications ‚Äì August 2023¬†</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.08513,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Announcing VMware Aria Hub April Release",
      "link": "https://blogs.vmware.com/management/2023/05/announcing-vmware-aria-hub-april-release.html",
      "published": "Mon, 08 May 2023 12:00:00 +0000",
      "summary": "<div><img alt=\"VMware Aria Hub\" class=\"attachment-medium size-medium wp-post-image\" height=\"124\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/05/VMware-Aria-Hub-Blog.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>Following our initial launch last November, we‚Äôre excited to introduce the April release of VMware Aria Hub, a true multi-cloud management platform with centralized views and controls powered by cloud-scale, graph-based data store technology. Try VMware Aria Hub Free Tier Sign up now to try VMware Aria Hub Free Tier. We‚Äôll send you an email &#8230; <a href=\"https://blogs.vmware.com/management/2023/05/announcing-vmware-aria-hub-april-release.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/05/announcing-vmware-aria-hub-april-release.html\">Announcing VMware Aria Hub April Release</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851336,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Query Analyzer in VMware Aria Operations for Applications",
      "link": "https://blogs.vmware.com/management/2023/03/query-analyzer-in-vmware-aria-operations-for-applications.html",
      "published": "Tue, 21 Mar 2023 06:26:30 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"91\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/03/DetectedIssuesDetail_QueryAnalyzer.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>With the recent release of the VMware Aria Operations for Applications product we have released the Query Analyzer feature which allows you to analyze your queries and subqueries. When you expect to see certain data in VMware Aria Operations for Applications, but it doesn‚Äôt show up for some reason, charts will display a&#160;No Data&#160;message. If &#8230; <a href=\"https://blogs.vmware.com/management/2023/03/query-analyzer-in-vmware-aria-operations-for-applications.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/03/query-analyzer-in-vmware-aria-operations-for-applications.html\">Query Analyzer in VMware Aria Operations for Applications</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851376,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Alert Targets Improvements in VMware Aria Operations for Applications",
      "link": "https://blogs.vmware.com/management/2023/03/alert-targets-improvements-in-vmware-aria-operations-for-applications.html",
      "published": "Wed, 15 Mar 2023 07:32:09 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"63\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/03/AriaApps_AlertTargets_BlogPost_AlertTargetsRouteRecipients.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>With the recent release of the VMware Aria Operations for Applications product we have made some improvements to the Alert Targets Browser Page. Alert targets allow a user to specify when and how to send notifications.‚Äã During an alert target creation, you can specify a webhook, an email address or a PagerDuty key in the &#8230; <a href=\"https://blogs.vmware.com/management/2023/03/alert-targets-improvements-in-vmware-aria-operations-for-applications.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/03/alert-targets-improvements-in-vmware-aria-operations-for-applications.html\">Alert Targets Improvements in VMware Aria Operations for Applications</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851414,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Usage Portal Improvements in VMware Aria Operations for Applications",
      "link": "https://blogs.vmware.com/management/2023/03/usage-portal.html",
      "published": "Wed, 08 Mar 2023 07:08:58 +0000",
      "summary": "<div><img alt=\"Usage Trends\" class=\"attachment-medium size-medium wp-post-image\" height=\"116\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/03/AriaApps_UsagePortal_BlogPost_UsageTrends.png?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>With the recent release of the VMware Aria Operations for Applications product we have made some improvements to the Usage Portal. In addition to the dashboard for analyzing overall usage, VMware Aria Operations for Applications supports ingestion policies for&#160; usage by particular accounts, groups, sources, metric namespaces, or even point tags. As an administrator, it &#8230; <a href=\"https://blogs.vmware.com/management/2023/03/usage-portal.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/03/usage-portal.html\">Usage Portal Improvements in VMware Aria Operations for Applications</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851452,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Cloud Consumption Interface ‚ÄúCCI‚Äù with VMware Aria Automation Free Tier and vSphere+ Subscription",
      "link": "https://blogs.vmware.com/management/2023/01/introducing-cci-cloud-consumption-interface-with-aria-automation-free-tier-and-vsphere-subscription.html",
      "published": "Wed, 25 Jan 2023 15:13:16 +0000",
      "summary": "<div><img alt=\"VMware Aria Automation\" class=\"attachment-medium size-medium wp-post-image\" height=\"124\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2023/01/Aria-Automation-Logo-Blog.jpg?w=220\" style=\"margin-bottom: 10px;\" width=\"220\" /></div>\n<p>With the launch of Aria Automation Oct 2022 ( Formerly vRealize Automation Cloud); we announced the initial Availability (IA) of Cloud Consumption Interface (CCI for short) capability within Aria Automation Consumption ( Formerly VMware Service Broker ) and included as part of vSphere+ subscription. Check the Announcement blog Here and a technical blog Here if &#8230; <a href=\"https://blogs.vmware.com/management/2023/01/introducing-cci-cloud-consumption-interface-with-aria-automation-free-tier-and-vsphere-subscription.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2023/01/introducing-cci-cloud-consumption-interface-with-aria-automation-free-tier-and-vsphere-subscription.html\">Cloud Consumption Interface &#8220;CCI&#8221; with VMware Aria Automation Free Tier and vSphere+ Subscription</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851498,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "Introducing the Tanzu Mission Control Integration for VMware Aria Automation",
      "link": "https://blogs.vmware.com/management/2022/08/introducing-the-tanzu-mission-control-integration-for-vrealize-automation-cloud.html",
      "published": "Mon, 01 Aug 2022 16:00:00 +0000",
      "summary": "<div><img alt=\"\" class=\"attachment-medium size-medium wp-post-image\" height=\"170\" src=\"https://blogs.vmware.com/management/wp-content/uploads/sites/74/2022/07/vrac_and_tmc.png?w=188\" style=\"margin-bottom: 10px;\" width=\"188\" /></div>\n<p>With the July 2022 release of VMware Aria Automation (formerly known as: vRealize Automation Cloud), Tanzu Kubernetes Clusters deployed through VMware Aria Automation can be automatically added to Tanzu Mission Control Cluster Groups and therefore inherit the associated Access, Security, Quota and Custom policies. This new functionality builds on the existing integration with Tanzu Kubernetes &#8230; <a href=\"https://blogs.vmware.com/management/2022/08/introducing-the-tanzu-mission-control-integration-for-vrealize-automation-cloud.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2022/08/introducing-the-tanzu-mission-control-integration-for-vrealize-automation-cloud.html\">Introducing the Tanzu Mission Control Integration for VMware Aria Automation</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851533,
      "translated": false
    },
    {
      "feed_name": "VMware Kubernetes Blog",
      "source_language": "en",
      "title": "How to configure log sources to forward logs to vRealize Log Insight Cloud",
      "link": "https://blogs.vmware.com/management/2021/12/how-to-configure-log-sources-to-forward-logs-to-vrealize-log-insight-cloud.html",
      "published": "Tue, 21 Dec 2021 18:24:29 +0000",
      "summary": "<p>In this blog, I will describe following for vRealize Log Insight Cloud&#160; What is log source?&#160; What are supported&#160;agents ?&#160;&#160; How to configure various log sources&#160; Overview&#160; VMware vRealize¬Æ Log Insight Cloud&#x2122; offers IT teams unified visibility across private, hybrid and native public clouds by adding structure to unstructured log data, providing intuitive dashboards and &#8230; <a href=\"https://blogs.vmware.com/management/2021/12/how-to-configure-log-sources-to-forward-logs-to-vrealize-log-insight-cloud.html\">Continued</a></p>\n<p>The post <a href=\"https://blogs.vmware.com/management/2021/12/how-to-configure-log-sources-to-forward-logs-to-vrealize-log-insight-cloud.html\">How to configure log sources to forward logs to vRealize Log Insight Cloud</a> appeared first on <a href=\"https://blogs.vmware.com/management\">VMware Cloud Management</a>.</p>",
      "timestamp": 1741512167.0851567,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "Beautifying our UI: Enhancing GitLab's deployment experience",
      "link": "https://about.gitlab.com/blog/2025/03/06/beautifying-our-ui-enhancing-gitlabs-deployment-experience",
      "published": "2025-03-06T00:00:00.000Z",
      "summary": "<p>At GitLab, we‚Äôve implemented an innovative approach to improving our experience called <a href=\"https://handbook.gitlab.com/handbook/product/ux/product-design/#beautifying-our-ui\">Beautifying our UI</a>. This unique initiative pairs one product designer with a frontend engineer for a milestone or two, and empowers them to make self-directed usability improvements across the platform. Ultimately, this helps build a more polished product experience, as these pairs can quickly address pain points, refine interactions, and deliver thoughtful improvements that make the platform more efficient and enjoyable to use.</p>\n<p>In this iteration, <a href=\"https://gitlab.com/anna_vovchenko\">Anna Vovchenko</a> and I decided to focus on the continuous deployment (<a href=\"https://about.gitlab.com/topics/ci-cd/#what-is-continuous-deployment\">CD</a>) area of the product. Here is how we did it and what we learned.</p>\n<h2>Trying something new</h2>\n<p>As this was our second round going through the process, we wanted to make several small adjustments that in the end helped us deliver even more quality improvements to the product. These process improvements included:</p>\n<ul>\n<li><strong>Extended timeline:</strong> We decided this time around we wanted to extend the initiative to span two milestones. This gave us the time to tackle more complex problems, but also gave us space for additional planning at the start.</li>\n<li><strong>Structured planning:</strong> While it was encouraged in the past to work directly in merge requests, we found it helped to use the initial issue as a place to plan and seek out problems ahead of time. Rather than purely focusing on the ad-hoc, we incorporated a planning phase similar to milestone planning, helping the partnership identify and prioritize potential improvements beforehand.</li>\n<li><strong>Product manager integration:</strong> As we focused on one area for this round of the project, we also decided to involve the product manager of the team more actively in the process. This ensured alignment on larger changes, reduced surprises when MRs were merged and allowed us to gather valuable feedback throughout the implementation.</li>\n<li><strong>Engaging the community:</strong> We expanded our improvement efforts by inviting contributions from community members, accelerating our ability to implement fixes and enhancements across the platform.</li>\n<li><strong>Strategic timing:</strong> We chose to run this iteration during a traditionally slower period, allowing teams to focus more deeply on these improvements without competing priorities.</li>\n</ul>\n<p>These refinements maintained the initiative's core strength of direct designer-engineer collaboration, while adding structure that helped our pair work more effectively.</p>\n<h2>What were the main improvements?</h2>\n<p>During the two milestones, our pairing implemented several significant improvements that enhance the user experience across the CD space. Here's a look at what we accomplished:</p>\n<h3>Enhanced environment list view</h3>\n<p>One of the larger changes made during this cycle of \"Beautifying our UI\" was a redesigned Environment List page to make deployment information more accessible. Previously, users had to click through collapsible sections to view crucial deployment details, and viewing important details at a glance was difficult. Now, this information is immediately visible, bringing the most important deployment information to the forefront where users need it.</p>\n<p><img alt=\"Beautifying UI - Environments page before\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3PNIW6wr7PjXj56eIckxYR/118bd0134f6ef21dd4876e50842ba5d6/Before_Environments_Page.png\" /></p>\n<p><strong>Before:</strong> The original design relied on collapsible sections, requiring users to click to reveal deployment information. This meant that users couldn't immediately see the status of their deployments, making it harder to quickly assess the state of their environments.</p>\n<p><img alt=\"Beautifying UI - Environments page after\" src=\"https://images.ctfassets.net/r9o86ar0p03f/5IXx6EwEFpIlU5IpvlASUV/ab333877441cf3c2ea8dd722f095bac0/After_Environments_Page.png\" /></p>\n<p><strong>After:</strong> The new design surfaces critical deployment information directly in the list view, including:</p>\n<ul>\n<li>Deployment status with clear visual indicators</li>\n<li>Who triggered the deployment along with timestamps</li>\n<li>Commit information and version tags</li>\n<li>Actions to take on the environment</li>\n<li>Latest deployment indicators</li>\n</ul>\n<p>This redesign eliminates the need for extra clicks and gives users immediate visibility into their deployment and environment statuses. The new layout maintains a clean interface while presenting more actionable information upfront.</p>\n<h3>Improved deploy keys filtering</h3>\n<p>Another larger enhancement was made to our deploy keys interface to improve searchability while maintaining performance. This change addresses a critical user need for quickly finding specific deploy keys in large repositories, which was broken when pagination was introduced earlier last year.</p>\n<p><img alt=\"Beautifying UI - Deploy key before\" src=\"https://images.ctfassets.net/r9o86ar0p03f/0wZRhTpbwYkWBBLB8HhYn/83724f401fc61a85ea5d7f0cf9ebf1ee/Deploy_Key_Before.png\" /></p>\n<p><strong>Before:</strong> The previous interface displayed deploy keys in a paginated list without a dedicated search function. While pagination helped with performance when handling thousands of keys, users had lost the ability to quickly search through their deploy keys using the browser search functionality, forcing them to manually scan through multiple pages.</p>\n<p><img alt=\"Beautifying UI - Deploy key after\" src=\"https://images.ctfassets.net/r9o86ar0p03f/63bgcl0bSSoGQXZW8Dx4Rk/7a6bb7e089be6d297690a29ff5e4b39a/Deploy_Key_After.png\" /></p>\n<p><strong>After:</strong> The new design introduces a dedicated search field at the top of the deploy keys list, allowing users to:</p>\n<ul>\n<li>Quickly filter deploy keys by name or SHA</li>\n<li>Maintain the performance benefits of pagination</li>\n<li>Find specific keys without browsing through multiple pages</li>\n</ul>\n<p>This improvement strikes the right balance between performance and usability, especially beneficial for teams managing numerous deploy keys across multiple projects.</p>\n<h3>Better Kubernetes agent management</h3>\n<p>We made significant improvements to the Kubernetes agent experience by simplifying the registration process and providing better visibility into agent status. These enhancements work together to create a smoother onboarding experience for teams getting started.</p>\n<p>Our first area of focus was streamlining how users register agents when they have configuration files ready to use. Previously, this process had several pain points that we wanted to address.</p>\n<p><img alt=\"Beautifying UI - Agent before\" src=\"https://images.ctfassets.net/r9o86ar0p03f/4nQ26pVg2pullsURbdUuUO/2ba71a65e0ff6227c611e806daeb4c5f/Agent_Before.png\" /></p>\n<p><strong>Before:</strong></p>\n<ul>\n<li>Only showed connected and previously connected agents</li>\n<li>Connection status was limited to \"Never connected\" or \"Not connected\"</li>\n<li>No clear path to register new agents</li>\n</ul>\n<p><img alt=\"Beautifying UI - Agent after\" src=\"https://images.ctfassets.net/r9o86ar0p03f/1khmWXmfgnZxLkImL98jqX/5d50e88e8398b292af8159c25c22865d/Agent_After.png\" /></p>\n<p><strong>After:</strong></p>\n<ul>\n<li>Added a new Available configurations tab showing all potential agent configurations</li>\n<li>Clear \"Register an agent\" call-to-action button for each available configuration</li>\n</ul>\n<p>Next, we turned our attention to making the agent registration modal more intuitive. The previous design created some confusion that we wanted to resolve.</p>\n<p><img alt=\"Beautifying UI - Registration before\" src=\"https://images.ctfassets.net/r9o86ar0p03f/6UGHFXFRTWtMEOMRNnMC3n/308c56bff1ff25512962c9fa2a78ca38/Registration_Before.png\" /></p>\n<p><strong>Before:</strong></p>\n<ul>\n<li>Users faced a confusing dual-purpose search box that both found existing agents and created new ones</li>\n<li>The workflow had too many decision points instead of a clear path forward</li>\n<li>The process for creating vs. selecting an agent wasn't clearly separated</li>\n</ul>\n<p><img alt=\"Beautifying UI - Registration after\" src=\"https://images.ctfassets.net/r9o86ar0p03f/5IqK5YIFaVuVXh2p1zMf4t/575dfe8a2827e61204fe8322639c1294/Registration_After.png\" /></p>\n<p><strong>After:</strong></p>\n<ul>\n<li>Separated the interface into two clear options: bootstrap with Flux or create an agent through the UI</li>\n<li>Streamlined the workflow into a more linear process</li>\n<li>Made the distinction between creating new agents and selecting existing ones more obvious</li>\n<li>Added a success message that clearly shows where to create the optional config file</li>\n</ul>\n<p>These improvements make it immediately clear which agents need attention and provide a straightforward path to register new agents. The reorganized interface better supports both new users setting up their first agent and experienced users managing multiple agents.</p>\n<h2>Additional usability enhancements</h2>\n<p>While working on major interface improvements, we also addressed several focused usability issues that significantly improve the day-to-day experience:</p>\n<ul>\n<li><strong>Enhanced Kubernetes pod search:</strong> Added search functionality for Kubernetes pods on the environment page, making it easier to locate specific pods in large deployments. This was showcased in the <a href=\"https://about.gitlab.com/releases/2025/01/16/gitlab-17-8-released/#search-for-pods-on-the-dashboard-for-kubernetes\">GitLab 17.8 release post</a>.</li>\n<li><strong>Improved Flux status visibility:</strong> Added a \"stopped\" badge to the dashboard view when Flux sync is stopped, providing immediate visibility into sync status. This was also showcased in the <a href=\"https://about.gitlab.com/releases/2025/01/16/gitlab-17-8-released/#view-paused-flux-reconciliations-on-the-dashboard-for-kubernetes\">GitLab 17.8 release post</a>.</li>\n<li><strong>Better release information:</strong> Implemented a clear view of deployments related to a release, improving deployment tracking and visibility.</li>\n<li><strong>Streamlined environment search:</strong> Fixed an issue where users couldn't effectively search the Environments page, improving navigation in large environment lists.</li>\n<li><strong>Enhanced error message display:</strong> Resolved issues with viewing Flux details when long error messages were present, making troubleshooting more straightforward.</li>\n</ul>\n<h2>Looking forward</h2>\n<p>The success of these improvements demonstrates the value of empowering our teams to make direct, meaningful changes to our experience. Beyond the product enhancements, one of the most valuable outcomes has been the strengthened relationship between our Frontend and Design teams. Working together closely on these improvements has fostered better understanding of each other's perspectives, workflows, and constraints, leading to more effective collaboration.</p>\n<p>This deepened partnership has created a foundation for even better collaboration in our regular workflow, as team members now have stronger working relationships and shared understanding of each other's domains. We're excited to continue this initiative in future iterations, not just for the product improvements it generates, but also for its role in building stronger, more cohesive teams.</p>\n<blockquote>\n<p><a href=\"https://handbook.gitlab.com/handbook/product/ux/product-design/#beautifying-our-ui\">Follow along with the \"Beautifying our UI\" project</a> as we continue to make improvements to GitLab.</p>\n</blockquote>\n<h2>Read more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2023/08/15/navigation-research-blog-post/\">How we overhauled GitLab navigation</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/10/15/gitlab-dark-mode-is-getting-a-new-look/\">GitLab dark mode is getting a new look</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2023/07/05/beautifying-of-our-ui/\">Beautifying our UI: Giving GitLab build features a fresh look</a></li>\n</ul>",
      "timestamp": 1741512167.3508258,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "How GitLab measures Red Team impact: The adoption rate metric",
      "link": "https://about.gitlab.com/blog/2025/03/05/how-gitlab-measures-red-team-impact-the-adoption-rate-metric",
      "published": "2025-03-05T00:00:00.000Z",
      "summary": "<p>In early 2024, we started a journey to implement better metrics for <a href=\"https://handbook.gitlab.com/handbook/security/security-operations/red-team/\">our internal Red Team</a>. Our first iteration focused on what we now call the adoption rate metric, which measures how often the recommendations our team makes are accepted and implemented.</p>\n<p>Choosing this metric was very deliberate. While there are many ways to measure a Red Team's impact, we wanted to start with something fundamental: Are we actually driving meaningful security improvements? The adoption rate directly ties our work to real security outcomes, and we could measure it using tools and processes we already had in place.</p>\n<p>In this article, you'll discover how we used GitLab to track these results end-to-end, some lessons we learned (including what we would have done differently), and our plans to tackle the next set of metrics.</p>\n<h2>How we implemented the adoption rate metric</h2>\n<p>We use GitLab extensively for our Red Team planning, execution, and reporting. Every operation wraps up with a report that's written in markdown in a dedicated GitLab project. Each report contains a section called \"Recommendations\" with a list of suggestions to make GitLab more secure.</p>\n<p>Those recommendations are always linked to a dedicated issue, which we open in the project closest to the team who can address it. If we're suggesting a product feature, it goes directly in that tracker. If it's a detection capability, it goes into the detections as code repository. We always assign a directly responsible individual (DRI) in the group that owns that space, and we use <a href=\"https://gitlab.com/gitlab-com/gl-security/security-operations/redteam/redteam-public/resources/red-team-issue-templates/-/blob/main/.gitlab/issue_templates/recommendation.md?ref_type=heads\">this issue template</a> to ensure consistency in describing the problem, the risk, and potential solutions.</p>\n<p><img alt=\"Red team - recommendation-example\" src=\"https://images.ctfassets.net/r9o86ar0p03f/73y1KlWLKWijWmoQjPaS9z/6311f485b2a68bd16c64bd79b434c1eb/recommendation-example__1_.png\" /></p>\n<p>Here's where the tracking logistics come in. We use GitLab labels to classify the recommendation across three categories:</p>\n<ul>\n<li>Detections and alerts (<code>RTRec::Detection</code>)</li>\n<li>Security controls (<code>RTRec::Control</code>)</li>\n<li>Processes and procedures (<code>RTRec::Process</code>)</li>\n</ul>\n<p>We then use another set of labels to follow the lifecycle of that recommendation ‚Äì from review all the way through adoption:</p>\n<ul>\n<li>Under review (<code>RecOutcome::UnderReview</code>)</li>\n<li>Accepted and actively being worked on (<code>RecOutcome::InProgress</code>)</li>\n<li>Accepted but backlogged (<code>RecOutcome::Backlogged</code>)</li>\n<li>Accepted but blocked (<code>RecOutcome::Blocked</code>)</li>\n<li>Fully adopted and closed (<code>RecOutcome::Adopted</code>)</li>\n<li>Partially adopted and closed (<code>RecOutcome::PartiallyAdopted</code>)</li>\n<li>Not adopted and closed (<code>RecOutcome::NotAdopted</code>)</li>\n</ul>\n<h2>How we stay on top of recommendations</h2>\n<p>We use a new GitLab feature called <a href=\"https://docs.gitlab.com/ee/user/glql/\">\"GitLab Query Language\" (GLQL)</a> to build a dynamic Security Recommendations Dashboard inside a GitLab issue.</p>\n<p>This issue allows us to quickly identify things like:</p>\n<ul>\n<li>open recommendations that haven't been updated recently</li>\n<li>open recommendations that have been backlogged for an extended period of time</li>\n<li>closed recommendations that weren't properly labeled with an adoption outcome</li>\n</ul>\n<p>We've found this process encourages the Red Team to follow up on stale recommendations, reaching out to the owners and seeing how we can help get them adopted.</p>\n<p>GLQL is very cool, and allows us to turn a short code block like this:</p>\n<pre><code class=\"language-yaml\">---  \ndisplay: table  \nfields: title, labels(\"RTRec::*\"), labels(\"RecOutcome::*\"), created, updated  \n---  \ngroup = \"gitlab-com\"  \nAND label = \"RTRec::*\"  \nAND opened = true  \n</code></pre>\n<p>... into a dynamic table like this:</p>\n<p><img alt=\"Red Team - GLQL table\" src=\"https://images.ctfassets.net/r9o86ar0p03f/2lPijOJclw45o0Qi6HqdXd/664f11ca26dc8f80e3e1508481ee3abe/glql-table.png\" /></p>\n<p>That table for us is very tactical and we use it to keep things moving. Beyond that, we also visualize the adoption rate trends over time. That allows us to look at things like quarterly adoption rate percentages, how long different types of recommendations take to adopt and implement, and how these figures vary across departments.</p>\n<h2>Lessons learned</h2>\n<p><strong>1. Start with metrics in place; don't wait for your program to mature first.</strong></p>\n<p>Early in our Red Team's development, we focused more on how we would execute operations and less on how we would measure them. The idea of using metrics to distill complex operations into simple numbers felt like it might oversimplify our work. But we've learned that thoughtful metrics don't reduce the value of Red Team operations - they help demonstrate our impact and guide our program's growth. Starting with clear metrics earlier would have accelerated this growth.</p>\n<p>Implementing these metrics later meant spending significant time reformatting years of historical recommendations to enable consistent analysis. Had we planned for metrics from the start, we could have saved ourselves a lot of time and effort.</p>\n<p>We‚Äôre keeping this lesson in mind as we start on our next set of metrics, threat resilience, which we talk about below.</p>\n<p><strong>2. Don't operate in a silo.</strong></p>\n<p>Red Teams aren't the only groups that provide recommendations in a security organization. At GitLab, we have our bug bounty program, our external pentests, product security, security assurance, and security operations.</p>\n<p>On the Red Team, we developed our own recommendations process from scratch. It's been fairly effective, but we have noticed some areas for improvement, particularly around prioritization, project management, and alignment with our organization's risk reporting process.</p>\n<p>We also noticed that some other teams are really good at these areas such as our bug bounty program and the triaging of findings from our external pentests. Those particular groups are very good at delivering product recommendations, and we've been learning from their approach to improve our own delivery methods.</p>\n<p>So we've taken our success with visualizing metrics and are integrating these lessons to create a more standard format that can be used across teams. This will allow us to leverage things that are working well, like our adoption rate metric, and combine them with the more efficiently managed processes used by other groups to ultimately achieve a higher adoption rate and a more secure GitLab.</p>\n<h2>Next up: Measuring our threat resilience</h2>\n<p>Next up for us is implementing metrics around threat resilience. We want to measure how well GitLab can prevent, detect, and respond to the threats most relevant to our organization. We're building a dashboard that will help visualize this data, showing our top threat actors and a series of scores that measure how well we defend against their specific techniques.</p>\n<p>Our goal is to have this dashboard drive decisions around what Red Team operations to conduct, what defensive capabilities to improve, and in general where we should be investing time and effort across our entire security division.</p>\n<p>We hope to consolidate our existing tools in this process and are currently evaluating solutions. We'll share more info when we've achieved some success here.</p>\n<h2>Key takeaways and how to get started</h2>\n<p>If you're looking to measure your Red Team's impact, here's what we've learned:</p>\n<ol>\n<li>Start tracking metrics early, even if they're not perfect.</li>\n<li>Focus on actionable metrics first (like adoption rate).</li>\n<li>Use your existing tools. We used GitLab and Tableau, but the approach works with any tracking system.</li>\n<li>Collaborate across security teams to leverage existing processes when possible.</li>\n</ol>\n<p>We'd love to hear about your experience with metrics in security so drop a comment below or open an issue in one of our <a href=\"https://gitlab.com/gitlab-com/gl-security/security-operations/redteam/redteam-public\">public projects</a>.</p>\n<h2>Read more from GitLab's Red Team</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2023/11/20/stealth-operations-the-evolution-of-gitlabs-red-team/\">Stealth operations: The evolution of GitLab's Red Team</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2023/11/28/how-gitlabs-red-team-automates-c2-testing/\">How GitLab's Red Team automates C2 testing</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2022/05/11/how-we-run-red-team-operations-remotely/\">How we run Red Team operations remotely</a></li>\n</ul>",
      "timestamp": 1741512167.3508306,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "The GitLab AI Security Framework for security leaders",
      "link": "https://about.gitlab.com/blog/2025/03/04/the-gitlab-ai-security-framework-for-security-leaders",
      "published": "2025-03-04T00:00:00.000Z",
      "summary": "<p>As companies rapidly adopt AI technologies, CISOs face a new frontier of security challenges. Many security leaders find themselves grappling with unfamiliar questions: How do we evaluate AI vendors differently from traditional software vendors? What security controls matter most? Where does vendor responsibility end and customer responsibility begin? How do we evaluate AI security risks within the context of the service provided? To help answer these questions, we‚Äôve created the <a href=\"https://trust.gitlab.com/?itemUid=ad3d92c1-889e-49fc-b19c-2434f70071ee&amp;source=click\">GitLab AI Security Framework</a> to show security leaders how GitLab and customers enable secure AI-powered development using GitLab Duo.</p>\n<h2>The genesis of AI security challenges</h2>\n<p>From conversations with security leaders across industries a pattern has emerged: Organizations are rapidly embracing AI technologies to improve delivery while their security teams struggle to establish appropriate security controls.</p>\n<p>This disconnect isn't just a matter of resources or expertise ‚Äì it represents a fundamental shift in how organizations need to approach security in the AI era. Security leaders are witnessing quick and unprecedented adoption of AI across their organizations, from development teams using coding assistants to marketing departments leveraging generative AI.</p>\n<p>While organizations are integrating AI within their own software, many of their current vendor-provided SaaS applications have added AI capabilities as well. Although this adoption drives innovation and efficiency, it also creates a complex set of security considerations that traditional frameworks weren't designed to address. Below are some of the specific challenges we‚Äôve identified.</p>\n<h2>Security challenges in the AI era</h2>\n<p><strong>1. Responsibility and control uncertainty</strong></p>\n<p>The rapid pace of AI adoption has left many organizations without a coherent security governance strategy. Security teams find themselves trying to retrofit existing security frameworks to address AI-specific concerns. Security leaders face challenges in understanding where their responsibilities begin and end when it comes to AI security. The traditional vendor-customer relationship becomes more complex with AI systems, as data flows, model training, and inference processes create new types of interactions and dependencies.</p>\n<p><strong>2. Risk assessment evolution</strong></p>\n<p>Traditional security risk models struggle to capture the unique characteristics of AI systems. Security leaders are finding that standard risk assessment frameworks don't adequately address AI-specific risks. AI security risks will differ based on AI implementation and the context in which it‚Äôs used. The challenge is compounded by the need to evaluate AI vendors without necessarily having deep technical AI expertise on the security team.</p>\n<p><strong>3. Data protection complexities</strong><br />\nAI systems present unique challenges for data protection. The way these systems process, learn from, and generate data creates new privacy and security considerations that organizations should carefully evaluate. CISOs must ensure their data governance frameworks evolve to address how AI systems use and protect sensitive information. AI implementations with inadequate safeguards might inadvertently reveal protected information via AI generated outputs.</p>\n<p><strong>4. Compliance and standards navigation</strong><br />\nThe regulatory landscape for AI security is rapidly evolving, with new standards like ISO 42001 and others emerging alongside existing frameworks. Security leaders must navigate this complex environment while ensuring their AI implementations remain compliant with both current and anticipated regulations. This requires a delicate balance between enabling AI adoption and maintaining robust security controls that satisfy regulatory requirements.</p>\n<h2>Addressing these challenges</h2>\n<p>With the release of <a href=\"https://about.gitlab.com/gitlab-duo/\">GitLab Duo</a>, we recognized these executive-level concerns and developed a comprehensive framework to help organizations navigate AI security in the context of our AI-powered DevSecOps platform. Our AI Security Framework provides details on our privacy-first implementation of AI to enable GitLab Duo, and how we validate the security of our AI vendors. A responsibility matrix is included to help security leaders manage their AI security responsibilities while enabling their organizations to innovate safely. We also compiled a selection of AI-specific security risks to keep in mind and highlighted how GitLab capabilities like <a href=\"https://about.gitlab.com/blog/2025/01/30/how-gitlab-uses-prompt-guardrails-to-help-protect-customers/\">prompt guardrails</a> can help in mitigating them.</p>\n<blockquote>\n<p>Want a deeper look at our security controls? Check out our <a href=\"https://trust.gitlab.com/?itemUid=ad3d92c1-889e-49fc-b19c-2434f70071ee&amp;source=click\">AI Security Framework</a>.</p>\n</blockquote>\n<h2>Learn more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/ai-transparency-center/\">GitLab AI Transparency Center</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2025/01/30/how-gitlab-uses-prompt-guardrails-to-help-protect-customers/\">How GitLab uses prompt guardrails to help protect customers</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2025/01/29/improve-ai-security-in-gitlab-with-composite-identities/\">Improve AI security in GitLab with composite identities</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2025/01/27/secure-compliant-and-ai-powered-get-to-know-3-new-gitlab-features/\">Secure, compliant, and AI-powered: Get to know 3 new GitLab features</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/12/05/icymi-key-ai-and-security-insights-from-our-developer-community/\">ICYMI: Key AI and security insights from our developer community</a></li>\n</ul>",
      "timestamp": 1741512167.3508344,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "Introducing GitLab‚Äôs Open Source Security Hub",
      "link": "https://about.gitlab.com/blog/2025/03/04/introducing-gitlabs-open-source-security-hub",
      "published": "2025-03-04T00:00:00.000Z",
      "summary": "<p>Today we‚Äôre excited to announce the launch of <a href=\"https://about.gitlab.com/security/open-source-resources/\">GitLab‚Äôs Open Source Security Hub</a> ‚Äî a central repository of security-focused projects developed by GitLab‚Äôs internal security team. These tools are designed to help developers, security practitioners, and organizations build safer, more secure software, and more resilient security programs.</p>\n<p>Securing systems is an ongoing challenge for businesses as threat actors continually adapt to new technologies and find creative ways to exploit organizations. Not only are they evolving their tactics, techniques and procedures, but they‚Äôre also <a href=\"https://insights.blackhatmea.com/do-cybercriminals-collaborate-and-build-community/\">collaborating through criminal networks</a>, sharing strategies, stolen data, and malicious tools to launch coordinated attacks at scale.</p>\n<p>As these threats grow in complexity, community-driven collaboration is one of our most powerful defenses. It‚Äôs a notion we‚Äôve long understood in security ‚Äî that <em>defending against adversaries is a shared responsibility</em>. By working together as a community, we can accelerate our collective intelligence and stay ahead of adversaries.</p>\n<p>In open-sourcing our security solutions, we aim to empower teams to adapt faster, respond smarter, and defend better ‚Äî together.</p>\n<p><a href=\"https://about.gitlab.com/security/open-source-resources/\"><img alt=\"open source security hub page image\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3fiRYFlrJB1lo1kGA6dQSs/f4d6c8a365537b753fe81710870f21d8/Screenshot_2025-03-04_at_08.10.05.png\" /></a></p>\n<h2>Why open source security?</h2>\n<p>At GitLab, open source isn‚Äôt just part of our technology ‚Äî it‚Äôs part of our <a href=\"https://about.gitlab.com/company/\">founding story</a>.</p>\n<p>Since day one, we‚Äôve championed the open source philosophy, believing that transparency, collaboration, and community-driven development are keys to building better software. Over the years, GitLab has fostered an open source community with more than <a href=\"https://about.gitlab.com/community/contribute/\">4,000 contributors</a> and has provided a comprehensive DevSecOps platform through its open source <a href=\"https://about.gitlab.com/install/ce-or-ee/\">Community Edition</a>.</p>\n<p>We‚Äôve also been inspired by industry leaders like <a href=\"https://opensource.crowdstrike.com/\">Crowdstrike</a> and <a href=\"https://www.paloaltonetworks.ca/prisma/cloud/open-source-projects\">Palo Alto Networks</a>, who have shown that open-sourcing security tools not only improves innovation but also strengthens the entire security ecosystem. Following in their footsteps, GitLab is committed to supporting the community by sharing tools, templates, and frameworks developed by our security teams.</p>\n<h2>Explore our featured open source security projects</h2>\n<p>We‚Äôre launching the Open Source Security Hub with a range of projects designed to enhance security operations and risk management. Here are some of the featured projects:</p>\n<ul>\n<li>\n<p><strong><a href=\"https://gitlab.com/gitlab-security-oss/risk-mgmt/storm-templates/\">StORM templates</a>:</strong> Streamline your security risk program with templates that standardize risk tracking and reporting.</p>\n</li>\n<li>\n<p><strong><a href=\"https://about.gitlab.com/blog/2024/11/26/unveiling-the-guard-framework-to-automate-security-detections-at-gitlab/\">GUARD Framework</a>:</strong> Automate response and detection with a detections-as-code approach that simplifies detection creation, maintenance, and alert routing.</p>\n</li>\n<li>\n<p><strong><a href=\"https://about.gitlab.com/blog/2024/10/29/new-cis-gitlab-benchmark-scanner-boosts-security-and-compliance/\">GitLab CIS Benchmark Scanner</a>:</strong> Improve your project‚Äôs security posture by auditing against the Center for Internet Security GitLab Benchmark.</p>\n</li>\n</ul>\n<p>Whether you‚Äôre a security engineer, researcher, or developer, your expertise and contributions are invaluable. Join us in strengthening the security ecosystem and collaborating with a community dedicated to making software safer for everyone.</p>\n<blockquote>\n<p><a href=\"https://about.gitlab.com/security/open-source-resources/\">Explore GitLab‚Äôs Open Source Security Hub</a> and contribute to the next chapter of open source security.</p>\n</blockquote>\n<h2>Learn more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2024/10/29/new-cis-gitlab-benchmark-scanner-boosts-security-and-compliance/\">New CIS GitLab Benchmark scanner boosts security and compliance</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/04/17/gitlab-introduces-new-cis-benchmark-for-improved-security/\">GitLab introduces new CIS Benchmark for improved security</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/11/26/unveiling-the-guard-framework-to-automate-security-detections-at-gitlab/\">Unveiling the GUARD framework to automate security detections at GitLab</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2025/01/29/automating-cybersecurity-threat-detections-with-gitlab-ci-cd/\">Automating cybersecurity threat detections with GitLab CI/CD</a></li>\n</ul>",
      "timestamp": 1741512167.350838,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "Build a new website in a few easy steps with GitLab Pages",
      "link": "https://about.gitlab.com/blog/2025/03/03/build-a-new-website-in-a-few-easy-steps-with-gitlab-pages",
      "published": "2025-03-03T00:00:00.000Z",
      "summary": "<p>A personal website is more than just a utility for digital creators and professionals in tech. It's a representation of your brand. But creating one from scratch can be time-consuming and expensive.</p>\n<p>With <a href=\"https://docs.gitlab.com/user/project/pages/\">GitLab Pages</a>, you can host your website with built-in features, including SSL certificates and a GitLab-provided domain. All of this is available on GitLab's free tier, making it an efficient solution for hosting your professional presence.</p>\n<p>We're going to take you on a fun journey to craft a stunning personal website using GitLab Pages! We‚Äôve got a super simple, versatile template that you can easily jazz up to reflect your unique style. So grab your favorite snack, get comfy, and let‚Äôs turn your online presence into something truly fabulous!</p>\n<h2>Prerequisites</h2>\n<p>You will need the following prerequisites before getting started:</p>\n<ul>\n<li>A GitLab account (the <a href=\"https://about.gitlab.com/pricing/\">free tier</a> is sufficient)</li>\n<li>Basic familiarity with HTML/CSS</li>\n<li>Content and images you want to add to your website (optional)</li>\n</ul>\n<p>Once you‚Äôre set up with a GitLab account and have your content handy, you can move on to the next steps.</p>\n<h2>Step 1: Create a new project</h2>\n<ol>\n<li>Sign on to your GitLab account and create a project.</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - welcome screen\" src=\"https://images.ctfassets.net/r9o86ar0p03f/4dl3nWj98rU70tbmPvpjvz/36581e3c9205adb2be77a0ff199bfb61/Capture-2025-02-27-183716.png\" /></p>\n<ol start=\"2\">\n<li>Click <strong>Create blank project</strong>.</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - Create new project screen\" src=\"https://images.ctfassets.net/r9o86ar0p03f/5ohC1jCUPEPoJjPhuZ8Zck/8f46fa26f91b8308cdcb9ac691bb1b66/Capture-2025-02-27-183814.png\" /></p>\n<ol start=\"3\">\n<li>Fill in your project details:\n<ul>\n<li>Name your project <code>yourusername.gitlab.io</code>. Replace <code>yourusername</code> with your GitLab username. <strong>Tip:</strong> The project name determines your website‚Äôs URL. If you name your project <code>yourusername.gitlab.io</code>, your website will be available at <code>https://yourusername.gitlab.io</code> with no additional path. However, if you use any other project name, your site will be available at <code>https://yourusername.gitlab.io/project-name</code>.</li>\n<li>Make the project public.</li>\n</ul>\n</li>\n<li>Click <strong>Create project</strong>.</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - Create blank project screen\" src=\"https://images.ctfassets.net/r9o86ar0p03f/7vA7DCeiekORoxaBW8u1ux/540cc127612cf853945c78239170ab9b/image5.png\" /></p>\n<p><img alt=\"GitLab Pages tutorial - customized get started page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/XOxKyJbbv4zZMvsS6smxa/af54d29c7dc3e7ae8cababa1766ad1d3/image2.png\" /></p>\n<h2>Step 2: Add the template files</h2>\n<p>Start by creating two new files in your repository:</p>\n<p><img alt=\"GitLab Pages tutorial - Add new files to personal page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3qE0dXdnvcvJov81eUQ5m6/55f55e483aa80b10704fb5dfab30d62a/image13.png\" /></p>\n<ol>\n<li>First, create <code>index.html</code>:\n<ul>\n<li>In your project, click the <strong>+</strong> button and select <strong>New file</strong>.</li>\n<li>Name the file <code>index.html</code>.\n<img alt=\"GitLab Pages tutorial - new file page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/NOKS9Scmevhky1X7ptV2M/c809d34d0b8bfa7597dfb6dfa2fc9856/image14.png\" /></li>\n<li>Add your HTML content.\n<ul>\n<li>Use the example HTML provided below. (Pro tip: Users can ask GitLab Duo Chat to generate HTML for enhanced functionality.)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"utf-8\"/&gt;\n    &lt;title&gt;[Your Name] ¬∑ [Your Title]&lt;/title&gt;\n    &lt;meta name=\"description\" content=\"[Your Name] is a [Your Title].\"/&gt;\n    &lt;meta name=\"author\" content=\"[Your Name]\"/&gt;\n    &lt;meta property=\"og:title\" content=\"[Your Name]\" /&gt;\n    &lt;meta property=\"og:description\" content=\"[Your Title]\" /&gt;\n    &lt;meta property=\"og:image\" content=\"og.png\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/&gt;\n    &lt;link href=\"https://unpkg.com/basscss@8.0.2/css/basscss.min.css\" rel=\"stylesheet\"&gt;\n    &lt;link href=\"style.css\" rel=\"stylesheet\"&gt;\n    &lt;link rel=\"shortcut icon\" type=\"image/png\" href=\"favicon.png\"/&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div class=\"content\" id=\"content\"&gt;\n  &lt;div class=\"p2 sm-p4 mt2 sm-mt4 mb2 sm-mb4\"&gt;  \n  &lt;div class=\"fade mt3\"&gt;\n    &lt;a target=\"_new\" href=\"[Your Linkedin URL]\"&gt;\n      &lt;img class=\"photo\" src=\"profile.png\" width=\"64\" height=\"64\"&gt;\n    &lt;/a&gt;\n  &lt;/div&gt;\n  &lt;h2 class=\"mb0 mt4 fade\"&gt;\n    Hello, I'm [Your Name] \n    &lt;span class=\"smallcaps\"&gt;(&lt;/span&gt;\n    &lt;a target=\"_new\" href=\"[Your Linkedin URL]\"&gt;@[Your Handle]&lt;/a&gt;\n    &lt;span class=\"smallcaps\"&gt;)&lt;/span&gt;\n  &lt;/h2&gt;\n  &lt;h2 class=\"mt0 mb4 fade gray\"&gt;\n    I'm a [Your Title]\n  &lt;/h2&gt;\n  &lt;p class=\"mb4 fade\"&gt;\n    I'm a [Your Role] at [Your Company], [Brief company description].\n  &lt;/p&gt;\n  &lt;div class=\"fade\"&gt;\n    &lt;p class=\"fade mb4\"&gt;\n      Your personal statement about what you do and what you're interested in. Add your contact preferences here.\n    &lt;/p&gt;\n  &lt;/div&gt;\n  &lt;p class=\"fade mb4\"&gt;\n    &lt;span class=\"gray\"&gt;‚Äî&lt;/span&gt; \n    [Your Name] \n    &lt;span class=\"smallcaps&gt;(&lt;/span&gt;\n    &lt;a target=\"_new\" href=\"[Your Linkedin URL]\"&gt;@[Your Handle]&lt;/a&gt;\n    &lt;span class=\"smallcaps\"&gt;)&lt;/span&gt;\n  &lt;/p&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt; \n</code></pre>\n<ul>\n<li>Add a commit message (e.g., \"Added index.html\").\n<ul>\n<li>Click <strong>Commit changes</strong>.</li>\n</ul>\n</li>\n</ul>\n<ol start=\"2\">\n<li>Create <code>style.css</code> (follow same steps above).</li>\n</ol>\n<pre><code>body {\n  margin: 0;\n  padding: 0;\n  background: #000;\n  color: #f4f4f4;\n  font-family: \"Graphik Web\", system-ui, -apple-system, BlinkMacSystemFont, \"Helvetica Neue\", \"Helvetica\", \"Segoe UI\", Roboto, Ubuntu, sans-serif;\n  font-weight: 400;\n  font-smooth: antialiased;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\na {\n  color: #ff310a;\n  text-decoration: none;\n}\n\na:hover {\n  color: #CFEF54\n}\n\n.content {\n  max-width: 40rem;\n  margin: 0 auto;\n}\n\nimg.photo {\n  border-radius: 50%;\n}\n\np {\n  font-size: 1.5rem;\n  line-height: 1.4;\n  margin: 0;\n  letter-spacing: -0.05rem;\n}\n\nh2 {\n  font-weight: 400;\n  line-height: 1.3;\n  letter-spacing: -0.05rem;\n}\n\n.smallcaps {\n  font-variant: small-caps;\n  color:#333;\n}\n\n.gray{\n  color: #999;\n}\n\n.preloader {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  height: 100vh;\n  height: -moz-available;\n  height: -webkit-fill-available;\n  height: fill-available;\n  width: 100%;\n  background: #000;\n  position: fixed;\n  top: 0;\n  left: 0;\n  z-index: 9999;\n  transition: opacity 0.3s linear;\n  transform: translate3d(0, 0, 0);\n}\n\nbody.loaded .preloader {\n  opacity: 0;\n}\n\n.fade {\n  animation: fadeIn 1s ease-in-out both;\n}\n\n.fade:nth-child(2) {\n\tanimation-delay: 1s;\n}\n\n.fade:nth-child(3) {\n\tanimation-delay: 2s;\n}\n\n.fade:nth-child(4) {\n\tanimation-delay: 3s;\n}\n\n.fade:nth-child(5) {\n\tanimation-delay: 4s;\n}\n\n.fade:nth-child(6) {\n\tanimation-delay: 5s;\n}\n\n.fade:nth-child(7) {\n\tanimation-delay: 6s;\n}\n\n.fade:nth-child(8) {\n\tanimation-delay: 7s;\n}\n\n.fade:nth-child(9) {\n\tanimation-delay: 8s;\n}\n\n.fade:nth-child(10) {\n\tanimation-delay: 9s;\n}\n\n.fade:nth-child(11) {\n\tanimation-delay: 10s;\n}\n\n.fade:nth-child(12) {\n\tanimation-delay: 11s;\n}\n\n.fade:nth-child(13) {\n\tanimation-delay: 12s;\n}\n\n@keyframes fadeIn {\n\tfrom {\n\t\topacity: 0;\n\t\ttransform: translate3d(0, 0%, 0);\n\t}\n\tto {\n\t\topacity: 1;\n\t\ttransform: translate3d(0, 0, 0);\n\t}\n} \n\n</code></pre>\n<h2>Step 3: Configure GitLab CI file</h2>\n<p>There are two ways to create the GitLab CI configuration file that tells GitLab how to build and deploy your site:</p>\n<p><img alt=\"GitLab Pages tutorial - optimize your workflow with CI/CD pipelines screen\" src=\"https://images.ctfassets.net/r9o86ar0p03f/2LcdHfxew2tIeFmOx7fRZZ/5edd324075a5dfadf4e476ba64b1f22e/image3.png\" /></p>\n<p><strong>Option 1: Use Pipeline Editor (recommended)</strong></p>\n<ol>\n<li>Go to your project's <strong>Build &gt; Pipeline Editor</strong>.</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - pipeline editor/main branch\" src=\"https://images.ctfassets.net/r9o86ar0p03f/7wK5SOd7S9CZlofeDmHjq7/895333b4c644f94cdfe38c0454f6661f/image12.png\" /></p>\n<ol start=\"2\">\n<li>The <code>.gitlab-ci.yml</code> file will be automatically created.</li>\n<li>Copy and paste the following configuration:</li>\n</ol>\n<pre><code>pages:\n  stage: deploy\n  script:\n    - mkdir .public\n    - cp -r * .public\n    - mv .public public\n  artifacts:\n    paths:\n      - public\n  only:\n    - main\n</code></pre>\n<p><img alt=\"GitLab Pages Tutorial - New file in window\" src=\"https://images.ctfassets.net/r9o86ar0p03f/1bzQo7okzBVgNZ2SSj8l95/31edb2e98096bae3e8b0c1ff349cb59b/image4.png\" /></p>\n<p><strong>Option 2: Manual creation</strong></p>\n<p>If you prefer to create the file manually:</p>\n<ol>\n<li>Create a new file named <code>.gitlab-ci.yml</code>.</li>\n<li>Add the following configuration:</li>\n</ol>\n<pre><code>pages:\n  stage: deploy\n  script:\n    - mkdir .public\n    - cp -r * .public\n    - mv .public public\n  artifacts:\n    paths:\n      - public\n  only:\n    - main\n</code></pre>\n<p>The key to getting your site running is the GitLab CI configuration file. This file tells GitLab how to build and deploy your site.</p>\n<p>Let's break down what each part does:</p>\n<p><strong>The script part</strong></p>\n<pre><code>script:\n  - mkdir .public\n  - cp -r * .public\n  - mv .public public\n</code></pre>\n<p>This creates a folder called <code>public</code> and copies all your website files into it. GitLab Pages uses this folder to serve your website by default, though you can <a href=\"https://docs.gitlab.com/user/project/pages/introduction/#customize-the-default-folder\">customize the publishing folder</a> if needed.</p>\n<p><strong>The only part</strong></p>\n<pre><code>only:\n  - main\n\n</code></pre>\n<p>This tells GitLab to only update your website when changes are made to the main branch. This helps prevent accidental updates from experimental changes.</p>\n<h2>Step 4: Watch the magic happen</h2>\n<ol>\n<li>Commit all your changes.</li>\n<li>Go to <strong>Build &gt; Pipelines</strong> to watch your deployment.</li>\n<li>Wait for the pipeline to complete successfully (indicated by a green checkmark).</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - pipeline running for new page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3TWqK19gKq5HvjlEtRqHv5/dd79b1909720c1f923ba7eb48433da18/image6.png\" /></p>\n<p><img alt=\"GitLab Pages tutorial - pipeline passed for new page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/45Ue4IruelSnpSAVomoaxk/411fe710e2d8c4c190d3edaa6df45ee6/image1.png\" /></p>\n<h2>Step 5: Access your website</h2>\n<p>Once the pipeline completes successfully, your website will be available at: <strong>https://[yourusername].gitlab.io/</strong> .</p>\n<p>You can find an overview of your deployed website and additional settings in your project's <strong>Deploy &gt; Pages</strong> section. Here you'll find useful information. including:</p>\n<ul>\n<li>Your website's access URLs</li>\n<li>Domain settings\n<ul>\n<li>By default GitLab enables <strong>Unique domain</strong>. Make sure to disable it if you want to use the GitLab-provided domain. Learn more with the <a href=\"https://docs.gitlab.com/ee/user/project/pages#unique-domains\">unique domain documentation</a>.</li>\n</ul>\n</li>\n<li>HTTPS certificates status</li>\n<li>Recent deployments</li>\n<li>Additional configuration options</li>\n<li>Custom domains</li>\n</ul>\n<p>This section is particularly helpful when setting up custom domains or troubleshooting deployment issues.</p>\n<p><strong>Customize your site</strong></p>\n<p><img alt=\"GitLab Pages tutorial - customize site\" src=\"https://images.ctfassets.net/r9o86ar0p03f/4724zwWSfWACRZgHCI1YCb/af53a7a74c0a4520a07b3cd928aa42b6/image8.png\" /></p>\n<ol>\n<li>Replace all ‚ÄúYour ...‚Äù placeholders in <code>index.html</code> with your information.</li>\n</ol>\n<p><img alt=\"GitLab Pages tutorial - upload file to customize page\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3nBr11ZXG8AHyT3kmFlHkl/fca01562113e48f20371fa3d08233187/image11.png\" /></p>\n<ol start=\"2\">\n<li>Add your images:\n<ul>\n<li>profile.png - your profile photo (64x64px)</li>\n<li>favicon.png - your site favicon (32x32px)</li>\n<li>Og.png - OpenGraph image for social media preview (1200x630px)</li>\n</ul>\n</li>\n</ol>\n<p><strong>See it in action</strong></p>\n<p>If you're familiar with GitLab, feel free to <a href=\"https://gitlab.com/fracazo/fracazo.gitlab.io\">fork my repository</a> to get started quickly.</p>\n<p>Here is the final result:\n<a href=\"https://fracazo.gitlab.io/\">https://fracazo.gitlab.io/</a></p>\n<p><strong>Common issues and solutions</strong></p>\n<ul>\n<li>By default, GitLab enables \"Unique domain\" for Pages projects. To use the simpler GitLab-provided domain (like <code>username.gitlab.io</code>), go to <strong>Deploy &gt; Pages</strong> and disable the \"Use unique domain\" option. While unique domains offer some technical advantages, like better asset path handling, you might prefer the cleaner URL structure for a personal website.</li>\n<li>If your pipeline fails, check that you're using <code>main</code> instead of <code>master</code> in your <code>.gitlab-ci.yml</code> file.</li>\n<li>Ensure your group and project is public for GitLab Pages to work.</li>\n<li>If any jobs fail in your pipeline, you can check the job log for detailed error messages to help with troubleshooting.</li>\n</ul>\n<p>With GitLab Pages and this template, you can have a professional/personal website up and running in minutes. The template is clean, responsive, and easy to customize. As you grow professionally, you can easily update your site directly through GitLab.</p>\n<p>You can automate the deployment process by leveraging GitLab's CI/CD capabilities and focusing on creating great content.</p>\n<p>The best part? All of this is available on GitLab's free tier, making it an excellent option for free hosting of your personal projects, documentation sites, or even small business websites. For more advanced features and configurations, check out our <a href=\"https://docs.gitlab.com/ee/user/project/pages/\">Pages documentation</a>.</p>\n<h2>What‚Äôs next for GitLab Pages?</h2>\n<p>We're constantly working to make GitLab Pages even better for creators and developers. Here are some exciting improvements coming soon:</p>\n<h3>Simplified domain management</h3>\n<p>We have some exciting updates coming to GitLab Pages that will make managing your domains even easier and more fun! You can look forward to a streamlined dashboard that brings all your domain settings together in one friendly space, making everything easily accessible.</p>\n<p>You‚Äôll stay informed with real-time updates on your DNS and SSL certificate statuses, helping you keep your domains secure and running smoothly.</p>\n<h3>Custom domain setup</h3>\n<p>Setting up custom domains will be a breeze with our easy-to-follow process, guiding you every step of the way. Plus, you'll be able to set up your custom domains to automatically redirect visitors from your old website address to your new one ‚Äì perfect for when you want all your traffic to go to one main website. Learn more about <a href=\"https://docs.gitlab.com/ee/user/project/pages/custom_domains_ssl_tls_certification/index.html#set-up-a-custom-domain\">custom domains</a>.</p>\n<blockquote>\n<p>Get started with GitLab Pages today with <a href=\"https://about.gitlab.com/pricing/\">GitLab's free tier</a>!</p>\n</blockquote>\n<h2>Learn more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2024/09/23/gitlab-pages-features-review-apps-and-multiple-website-deployment/\">GitLab Pages features review apps and multiple website deployment</a></li>\n<li><a href=\"https://docs.gitlab.com/user/project/pages/#parallel-deployments\">GitLab Pages: Multiple website deployment documentation</a></li>\n<li><a href=\"https://gitlab.com/pages\">GitLab Pages examples</a></li>\n</ul>",
      "timestamp": 1741512167.3508415,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "Build and run containers in Remote Development workspaces",
      "link": "https://about.gitlab.com/blog/2025/03/03/build-and-run-containers-in-remote-development-workspaces",
      "published": "2025-03-03T00:00:00.000Z",
      "summary": "<p>Development environments often require the ability to build and run containers as part of their local development. Securely running containers within containers can be challenging. This article will provide a step-by-step guide to securely build and run containers in a workspace.</p>\n<p>You will learn how to:</p>\n<ul>\n<li><a href=\"https://about.gitlab.com/atom.xml#create-a-kubernetes-cluster-on-aws-eks\">Create a Kubernetes cluster on AWS EKS</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#configure-sysbox\">Configure Sysbox</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#configure-gitlab-agent-for-kubernetes-and-gitlab-workspaces-proxy\">Configure GitLab agent for Kubernetes and GitLab Workspaces Proxy</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#configure-sudo-access-for-a-workspace-with-sysbox\">Configure sudo access for a workspace with Sysbox</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#configure-ingress-controller\">Configure Ingress Controller</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#build-containers-inside-a-workspace\">Build containers inside a workspace</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#run-containers-inside-a-workspace\">Run containers inside a workspace</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#get-started-today\">Get started today</a></li>\n</ul>\n<h2>Create a Kubernetes cluster on AWS EKS</h2>\n<p>Install the <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\">AWS CLI</a> on your local machine. Next, configure a <a href=\"https://docs.aws.amazon.com/cli/latest/reference/configure/\">named profile</a> and export it to ensure all the following <code>aws</code> commands use the set credentials.</p>\n<pre><code>aws configure --profile gitlab-workspaces-container-demo\nexport AWS_PROFILE=gitlab-workspaces-container-demo\n</code></pre>\n<p>Install <a href=\"https://eksctl.io/installation/\">eksctl</a>, a CLI to interact with AWS EKS. Let‚Äôs now create a Kubernetes 1.31 cluster on AWS EKS with 1 node of Ubuntu 22.04 of <code>c5.2xlarge</code> instance type. The nodes can autoscale from 0-20 nodes and each node will have a label <code>sysbox-install: yes</code> . This will be explained later in the article.</p>\n<pre><code>export CLUSTER_NAME=\"gitlab-workspaces-container-demo-eks-sysbox\"\n\neksctl create cluster \\\n  --name \"${CLUSTER_NAME}\" \\\n  --version 1.31 \\\n  --node-ami-family=Ubuntu2204 \\\n  --nodes=1 \\\n  --nodes-min=0 \\\n  --nodes-max=20 \\\n  --instance-types=c5.2xlarge \\\n  --node-labels \"sysbox-install=yes\" \\\n  --asg-access \\\n  --external-dns-access \\\n  --full-ecr-access\n</code></pre>\n<p>Create an <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/associate-service-account-role.html\">IAM OIDC</a> provider for your cluster.</p>\n<pre><code>eksctl utils associate-iam-oidc-provider --cluster \"${CLUSTER_NAME}\" --approve\n</code></pre>\n<p>Create IAM role for <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html\">EBS add-on</a> for EKS.</p>\n<pre><code>eksctl create iamserviceaccount \\\n  --name ebs-csi-controller-sa \\\n  --namespace kube-system \\\n  --cluster \"${CLUSTER_NAME}\" \\\n  --role-name \"AmazonEKS_EBS_CSI_DriverRole_${CLUSTER_NAME}\" \\\n  --role-only \\\n  --attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \\\n  --approve\n</code></pre>\n<p>Create Amazon EBS CSI driver add-on for Amazon EKS cluster.</p>\n<pre><code>eksctl utils describe-addon-versions --kubernetes-version 1.31 | grep aws-ebs-csi-driver\n\nexport AWS_ACCOUNT_ID=\"UPDATE_ME\"\n\neksctl create addon \\\n  --cluster \"${CLUSTER_NAME}\" \\\n  --name aws-ebs-csi-driver \\\n  --version latest \\\n  --service-account-role-arn \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/AmazonEKS_EBS_CSI_DriverRole_${CLUSTER_NAME}\" \\\n  --force\n</code></pre>\n<p>Install <a href=\"https://kubernetes.io/docs/reference/kubectl/\">kubectl</a>, a command line tool for communicating with a Kubernetes cluster's control plane, using the Kubernetes API.</p>\n<p>Let‚Äôs get the <a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\">kubeconfig</a> of the created cluster.</p>\n<pre><code>aws eks update-kubeconfig --name \"${CLUSTER_NAME}\"\n</code></pre>\n<h2>Configure Sysbox</h2>\n<p><a href=\"https://github.com/nestybox/sysbox\">Sysbox</a> is a container runtime that improves container isolation and enables containers to run the same workloads as virtual machines.</p>\n<p><a href=\"https://github.com/nestybox/sysbox#installation\">Install</a> Sysbox on the Kubernetes cluster using the <code>sysbox-deploy-k8s daemonset</code>.</p>\n<pre><code>curl https://raw.githubusercontent.com/nestybox/sysbox/refs/tags/v0.6.6/sysbox-k8s-manifests/sysbox-install.yaml -o sysbox-install.yaml\n</code></pre>\n<p>Because of how Sysbox releases itself, it first created a git tag, which runs a pipeline to build assets after which the YAML files for the <code>sysbox-deploy-k8s daemonset</code> are updated. Thus, we need to update the DaemonSet's <code>spec.template.soec.containers[0].image</code> to <a href=\"https://github.com/nestybox/sysbox/blob/46ba726e8e894aa22e20465a32d22dfa2863ec12/sysbox-k8s-manifests/sysbox-install.yaml#L66\">registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.6.6-0</a> .</p>\n<pre><code>new_image_value=\"registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.6.6-0\"\ntemp_file=$(mktemp)\nsed -E \"s|^([[:space:]]*image:)[[:space:]]*.*|\\1 $new_image_value|\" \"sysbox-install.yaml\" &gt; \"$temp_file\"\nmv \"$temp_file\" \"sysbox-install.yaml\"\n</code></pre>\n<p>Apply the YAML file to Kubernetes and ensure all the pods of the DaemonSet are running.</p>\n<pre><code>kubectl apply -f sysbox-install.yaml\nkubectl get pod -A\nkubectl -n kube-system get daemonset\n</code></pre>\n<p>Verify the installation by creating a pod which uses Sysbox container runtime.</p>\n<pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sysbox-verification-pod\n  namespace: default\n  annotations:\n    io.kubernetes.cri-o.userns-mode: \"auto:size=65536\"\nspec:\n  runtimeClassName: sysbox-runc\n  containers:\n  - image: \"hello-world\"\n    imagePullPolicy: Always\n    name: main\n  restartPolicy: Always\nEOF\n\nkubectl -n default get pod sysbox-verification-pod\nkubectl exec -it sysbox-verification-pod -- echo \"Pod is running successfully on a Kubernetes cluster configured with Sysbox.\"\nkubectl -n default delete pod sysbox-verification-pod\n</code></pre>\n<h2>Configure GitLab agent for Kubernetes and GitLab Workspaces Proxy</h2>\n<p>Follow our <a href=\"https://docs.gitlab.com/ee/user/workspace/set_up_gitlab_agent_and_proxies.html\">documentation tutorial</a> to set up GitLab agent and GitLab Workspaces Proxy.</p>\n<h2>Configure sudo access for a workspace with Sysbox</h2>\n<p>Follow our <a href=\"https://docs.gitlab.com/ee/user/workspace/configuration.html#with-sysbox\">documentation</a> to configure sudo access for a workspace with Sysbox.</p>\n<h2>Configure Ingress Controller</h2>\n<p>Setup <a href=\"https://github.com/kubernetes/ingress-nginx\">Ingress NGINX Controller for Kubernetes</a></p>\n<pre><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx --force-update\nhelm repo update\n\nhelm upgrade --install \\\n  ingress-nginx ingress-nginx/ingress-nginx \\\n  --namespace ingress-nginx \\\n  --create-namespace \\\n  --version 4.11.1 \\\n  --timeout=600s --wait --wait-for-jobs\n\nkubectl -n ingress-nginx get pod\n</code></pre>\n<h2>Build containers inside a workspace</h2>\n<p>We‚Äôll use <a href=\"https://gitlab.com/gitlab-org/workspaces/examples/example-go-http-app\">example-go-http-app</a> as the project to create a workspace from. Open the workspace, start a terminal, and install <a href=\"https://docs.docker.com/engine/install/\">Docker</a>.</p>\n<pre><code># Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release &amp;&amp; echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\n\u000bsudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n# Start the Docker Daemon\nsudo dockerd\n</code></pre>\n<p>Build the container image.</p>\n<pre><code>sudo docker build -t workspaces-golang-server .\n</code></pre>\n<h2>Run containers inside a workspace</h2>\n<p>Let‚Äôs run the container built above and expose port 3000 from the container onto the host (workspace).</p>\n<pre><code>sudo docker run -p 3000:3000 workspaces-golang-server\n</code></pre>\n<p>The port <code>3000</code> is exposed in the <a href=\"https://gitlab.com/gitlab-org/workspaces/examples/example-go-http-app/-/blob/dd3dbb38cdce1143f7ed023980f34630cea991a5/.devfile.yaml#L15\">.devfile.yaml</a> used to create the workspace. Access the server running inside the container from the browser. Here is a video clip.</p>\n<p>&lt;!-- blank line --&gt;\n&lt;figure class=\"video_container\"&gt;\n&lt;iframe src=\"https://www.youtube.com/embed/JQErF0U6oFk?si=6oiK48q5ghZq312g\" frameborder=\"0\" allowfullscreen=\"true\"&gt; &lt;/iframe&gt;\n&lt;/figure&gt;\n&lt;!-- blank line --&gt;</p>\n<h2>Get started today</h2>\n<p>From GitLab 17.4, you can build and run containers securely in GitLab Workspaces. See our <a href=\"https://docs.gitlab.com/ee/user/workspace/configuration.html#build-and-run-containers-in-a-workspace\">documentation</a> for more information. Replace your local development environments to GitLab Workspaces for a secure, ephemeral, reproducible development environment.</p>\n<h2>Read more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2024/11/20/enable-secure-sudo-access-for-gitlab-remote-development-workspaces/\">Enable secure sudo access for GitLab Remote Development workspaces</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2023/06/26/quick-start-guide-for-gitlab-workspaces/\">Quickstart guide for GitLab Remote Development workspaces</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2025/02/27/create-a-workspace-quickly-with-the-gitlab-default-devfile/\">Create a workspace quickly with the GitLab default devfile</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2023/07/31/gitlab-gdk-remote-development/\">Contributor how-to: Remote Development workspaces and GitLab Developer Kit</a></li>\n</ul>",
      "timestamp": 1741512167.350845,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "GitLab Duo Self-Hosted: Enterprise AI built for data privacy",
      "link": "https://about.gitlab.com/blog/2025/02/27/gitlab-duo-self-hosted-enterprise-ai-built-for-data-privacy",
      "published": "2025-02-27T00:00:00.000Z",
      "summary": "<p>We are excited to announce the general availability of GitLab Duo Self-Hosted for Code Suggestions and Chat. An optional capability for self-managed customers with a GitLab Duo Enterprise subscription, GitLab Duo Self-Hosted supports deployment flexibility across multiple platforms, including on-premises infrastructure or in private clouds and secure cloud environments through AWS Bedrock and Azure OpenAI. GitLab Duo Self-Hosted empowers teams to innovate with AI while helping them maintain control over sensitive data and intellectual property.</p>\n<p>Security concerns have been a major barrier to AI adoption in regulated industries. In our <a href=\"http://about.gitlab.com/developer-survey/2024/ai\">Global DevSecOps Survey</a>, more than half of the respondents said that introducing AI into the software development lifecycle is risky. With <a href=\"https://about.gitlab.com/gitlab-duo/\">GitLab Duo</a>, we gave organizations a way to ship more secure software faster with AI throughout the entire software development lifecycle.</p>\n<p>GitLab Duo Self-Hosted expands the availability of GitLab Duo AI features to organizations with stringent data privacy requirements, offering flexibility in both AI large language model (LLM) selection and deployment options. The earliest adopters of GitLab Duo Self-Hosted include organizations in the public sector and regulated industries  ‚Äì e.g., financial services, automotive, and healthcare. These organizations seek to gain the competitive advantage of AI by integrating AI-powered development tools into their environments, while also giving security teams the control they need.</p>\n<p>As one U.S. government agency says: ‚ÄúAfter selecting GitLab as the cornerstone of our agency-wide DevSecOps platform, we chose GitLab Duo Self-Hosted to further advance our software factory capabilities. GitLab Duo‚Äôs ability to operate in air-gapped environments and provide granular control over our data was crucial to delivering secure AI-powered features. This unified approach streamlines our workflow and strengthens security, allowing us to leverage AI for increased productivity while meeting strict compliance requirements.‚Äù</p>\n<p><img alt=\"GitLab Duo Self-Hosted models\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3QJscp0SwNREWti3qTGb5/65b74ee1f0ae19e049bbb4dc64a13cf3/image4.png\" /></p>\n<h2>Architect secure AI deployments</h2>\n<p>GitLab Duo Self-Hosted enables GitLab Duo features that leverage a curated selection of leading AI LLMs, including those from Anthropic, Mistral, and OpenAI. Here are the LLMs supported by GitLab today:</p>\n<ul>\n<li>On-premises - Mistral models with the vLLM serving platform</li>\n<li>AWS - Mistral and Anthropic Claude 3.5 Sonnet via AWS Bedrock</li>\n<li>Microsoft Azure - OpenAI GPT models via Azure AI</li>\n</ul>\n<p>We are evaluating more models to support in the near future. <a href=\"https://docs.gitlab.com/ee/administration/self_hosted_models/supported_models_and_hardware_requirements.html#approved-llms\">Learn more about the LLMs we support.</a></p>\n<p>GitLab Duo Self-Hosted deployment options include on-premises installations powered by the open-source vLLM framework, as well as private-cloud deployments via services like AWS Bedrock and Microsoft Azure AI. This flexibility helps organizations to architect AI solutions that align with their unique security, compliance, and performance requirements.</p>\n<h2>Simplify AI/ML implementation</h2>\n<p>GitLab Duo's AI abstraction layer standardizes and simplifies the integration of the chosen LLM to a feature, mitigating the burden of implementing AI/ML technologies. This enables companies to streamline their AI adoption efforts and enhance the developer experience, free from the complexities of integrating and maintaining multiple tools.</p>\n<p><img alt=\"GitLab Duo Self-Hosted AI-powered features\" src=\"https://images.ctfassets.net/r9o86ar0p03f/4k4FWWuW9SJL8gq86u0P9r/5b7bd0176f7abcaf21d1db48f73b7cb2/image1.png\" /></p>\n<h2>Maintain control of sensitive data</h2>\n<p>By isolating your GitLab instance, AI gateway, and LLMs in your own environment or country of choice, GitLab Duo Self-Hosted makes it possible that sensitive data and intellectual property remain within your designated perimeter. Granular control over data locality helps enable adherence to strict data residency regulations, while adopting AI capabilities in secure settings. Whether you use GitLab Duo Self-Hosted in a completely air-gapped environment with vLLM or leverage a supported private cloud, you can control all aspects of the deployment to include the geographic location of components. By eliminating the reliance on external APIs and providing full visibility into all request and response logs, GitLab Duo Self-Hosted helps even the most regulated organizations confidently adopt AI capabilities and meet the most stringent compliance obligations.</p>\n<p><strong>Start an interactive tour of GitLab Self-Hosted by clicking on the image below:</strong></p>\n<p><a href=\"https://gitlab.navattic.com/gitlab-duo-self-hosted\"><img alt=\"GitLab Duo Self-Hosted tour screenshot\" src=\"https://images.ctfassets.net/r9o86ar0p03f/2VpxB3n1RmKvOYYuWWc41G/71de49c5aba30e07e6d93b00aa086eef/Screenshot_2025-02-20_at_7.00.34_AM.png\" /></a></p>\n<h2>Get started with GitLab Duo Self-Hosted today</h2>\n<p>If you're ready to advance your AI journey while addressing security and data privacy, <a href=\"https://about.gitlab.com/sales/\">reach out to us</a> to help set up GitLab Duo Self-Hosted in your environment today.</p>",
      "timestamp": 1741512167.3508487,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "Create a workspace quickly with the GitLab default devfile",
      "link": "https://about.gitlab.com/blog/2025/02/27/create-a-workspace-quickly-with-the-gitlab-default-devfile",
      "published": "2025-02-27T00:00:00.000Z",
      "summary": "<p>Software development environments can be complex to set up and maintain. Developers often spend a significant amount of time configuring their local environments with the right dependencies, tools, and settings. GitLab aims to solve this by providing a default devfile that enables you to create workspaces and to start developing quickly.</p>\n<h2>GitLab Workspaces</h2>\n<p>GitLab Workspaces provide isolated development environments for making changes to your GitLab projects without the complexity of setting up local dependencies. Workspaces ensure reproducible development setups, allowing developers to share their environment configurations effortlessly.</p>\n<p>By default, GitLab Workspaces are configured to use the GitLab VS Code fork and include the GitLab Workflow extension. To learn more, visit <a href=\"https://docs.gitlab.com/ee/user/workspace/\">the GitLab Workspaces documentation</a>.</p>\n<h2>Understand devfiles</h2>\n<p>A <a href=\"https://devfile.io/docs/2.2.0/devfile-ecosystem\"><strong>devfile</strong></a> is a YAML-based declarative configuration file that defines a project's development environment. It specifies the necessary tools, languages, runtimes, and other components required for development.</p>\n<p>Previously, <a href=\"https://about.gitlab.com/blog/2023/06/26/quick-start-guide-for-gitlab-workspaces/\">setting up a workspace</a> required a custom devfile at the root of the repository. For example, a <code>.devfile.yaml</code> file. A typical devfile looked like this:</p>\n<p><img alt=\"typical default devfile\" src=\"https://images.ctfassets.net/r9o86ar0p03f/3m6D3KyMTaojCt34gDfBaw/0736f517d9288524f835debcc4f1e118/Screenshot_2025-02-26_at_8.15.58_AM.png\" /></p>\n<h2>GitLab default devfile</h2>\n<p>Starting in GitLab 17.9, a GitLab default devfile is available for all projects when creating a workspace. This eliminates the need to manually create a devfile before starting a workspace.\nHere is the content of the default devfile:</p>\n<p><img alt=\"GitLab default devfile content\" src=\"https://images.ctfassets.net/r9o86ar0p03f/6DZe8DY3tMVDhcosgJ867d/699857a668d416b018d52414ab18929e/Screenshot_2025-02-26_at_8.16.20_AM.png\" /></p>\n<p>When creating a workspace with the GitLab UI, the option <strong>Use GitLab default devfile</strong> is always available ‚Äì regardless of whether custom devfiles exist in the repository. Simply select this option to start exploring GitLab Workspaces with one less setup step.</p>\n<p><img alt=\"Use GitLab default devfile screenshot\" src=\"https://images.ctfassets.net/r9o86ar0p03f/1XLkxewYbKAGoy1EjoTTGP/b15ab16547932cd4fd7791d7dc2bade1/image1.png\" /></p>\n<h2>Create your own custom devfiles</h2>\n<p>While the GitLab default devfile provides a quick way to start a workspace, you may want to customize your development environment to better fit your project's needs. By creating a custom devfile, you can tailor your development environment with the exact tools, dependencies, and configurations needed for your workflow.</p>\n<p>Consider creating a custom devfile if you need to:</p>\n<ul>\n<li>Add project-specific dependencies beyond the base development image.</li>\n<li>Adjust CPU and memory resource limits.</li>\n<li>Configure multiple containers for additional services like databases.</li>\n<li>Define custom, project-specific, environment variables.</li>\n<li>Set up specific port mappings.</li>\n<li>Integrate specialized development tools like debuggers or language servers.</li>\n</ul>\n<p>For more details, see the <a href=\"https://docs.gitlab.com/ee/user/workspace/#devfile\">Workspaces devfile documentation</a>.</p>\n<h2>Read more</h2>\n<ul>\n<li><a href=\"https://about.gitlab.com/blog/2025/03/03/build-and-run-containers-in-remote-development-workspaces/\">Build and run containers in Remote Development workspaces</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/07/24/use-gitlab-ai-features-out-of-the-box-in-a-gitlab-workspace/\">Use GitLab AI features out-of-the-box in a GitLab Workspace</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2023/06/26/quick-start-guide-for-gitlab-workspaces/\">Quickstart guide for GitLab Remote Development workspaces</a></li>\n<li><a href=\"https://about.gitlab.com/blog/2024/11/20/enable-secure-sudo-access-for-gitlab-remote-development-workspaces/\">Enable secure sudo access for GitLab Remote Development workspaces</a></li>\n</ul>",
      "timestamp": 1741512167.3508525,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "The ultimate guide to token management at GitLab",
      "link": "https://about.gitlab.com/blog/2025/02/25/the-ultimate-guide-to-token-management-at-gitlab",
      "published": "2025-02-25T00:00:00.000Z",
      "summary": "<p>Imagine this: You are an engineer at a growing tech company, and it‚Äôs 2 a.m. when you get an urgent call. A critical deployment pipeline has failed, and your team is scrambling to figure out why. After hours of digging, you realize someone revoked a personal access token belonging to an engineer who left the company a week ago. This token was tied to several key automation processes, and now your entire system is in chaos. How do you make sure it does not happen again?</p>\n<p>Follow this guide, which takes GitLab customers through the end-to-end process of identifying, managing, and securing their tokens. It is meant to be a handy supplement to the extensive <a href=\"https://docs.gitlab.com/ee/security/tokens\">token overview documentation</a> for GitLab administrators, developers, and security teams who need to ensure proper token management within their projects.</p>\n<p>Here's what is covered in this guide:</p>\n<ul>\n<li><a href=\"https://about.gitlab.com/atom.xml#how-to-select-the-right-token-for-the-job\">How to select the right token for the job</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#token-types\">Token types</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#discovering-your-tokens\">Discovering your tokens</a>\n<ul>\n<li><a href=\"https://about.gitlab.com/atom.xml#credentials-inventory\">Credentials inventory</a></li>\n</ul>\n</li>\n<li><a href=\"https://about.gitlab.com/atom.xml#managing-tokens-in-the-gitlab-ui-and-api\">Managing tokens in the GitLab UI and API</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#token-rotation-and-expiration-management\">Token rotation and expiration management</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#token-management-best-practices\">Token management best practices</a>\n<ul>\n<li><a href=\"https://about.gitlab.com/atom.xml#service-accounts\">Service accounts</a></li>\n</ul>\n</li>\n</ul>\n<h2>How to select the right token for the job</h2>\n<p>Choosing the right token ensures optimal security and functionality based on your use case.\nTokens can be used for authenticating API requests, automating CI/CD pipelines, integrating third-party tools, managing deployments and repositories, and more.</p>\n<p><img alt=\"Token management guide - flow chart for tokens\" src=\"https://images.ctfassets.net/r9o86ar0p03f/1lzZfISF8jgNL20OV0tvoi/9fb3f29c3ce1c987eb1a4a8301631647/image3.png\" /></p>\n<p>For the sake of simplicity, the chart illustrates a straightforward use case tied to single user ownership. For more information, check out our documentation of user roles and permissions at each <a href=\"https://docs.gitlab.com/ee/user/permissions.html\">namespace</a> (user/group) in your instance or top-level group. Example use cases could be as follows:</p>\n<ul>\n<li><strong>Personal access tokens</strong> (<a href=\"https://docs.gitlab.com/user/profile/personal_access_tokens/#personal-access-token-scopes\">PAT</a>) can be used by developers when a user's personal access and permissions are required. In this case, the credentials follow the status and permissions of the user, including the removal of access if the account loses access to a specific project or group (or is blocked entirely).</li>\n<li><strong>Project/group access tokens</strong> (<a href=\"https://docs.gitlab.com/user/project/settings/project_access_tokens/#scopes-for-a-project-access-token\">PrAT</a>/<a href=\"https://docs.gitlab.com/user/group/settings/group_access_tokens/#scopes-for-a-group-access-token\">GrAT</a>) are recommended when access should be scoped to resources within a specific project/group, allowing anyone with a PrAT/GrAT to access those resources through mechanisms managed by assigned scopes.</li>\n</ul>\n<h2>Token types</h2>\n<p>Below is a list of GitLab tokens with their default prefixes and use cases. For more information, please visit the <a href=\"https://docs.gitlab.com/ee/security/tokens/#available-scopes\">GitLab Token overview page</a>.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">Tokens</th>\n<th style=\"text-align: center;\">Prefix</th>\n<th style=\"text-align: center;\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">Personal access token</td>\n<td style=\"text-align: center;\">glpat</td>\n<td style=\"text-align: center;\">Access user-specific data</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">OAuth 2.0 token</td>\n<td style=\"text-align: center;\">gloas</td>\n<td style=\"text-align: center;\">Integrate with third-party applications using OAuth2.0 authentication protocol</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Impersonation token</td>\n<td style=\"text-align: center;\">glpat</td>\n<td style=\"text-align: center;\">Act on behalf of another user for administrative purposes</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Project access token</td>\n<td style=\"text-align: center;\">glpat</td>\n<td style=\"text-align: center;\">Access data from a specific project</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Group access token</td>\n<td style=\"text-align: center;\">glpat</td>\n<td style=\"text-align: center;\">Access data from a specific group</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Deploy token</td>\n<td style=\"text-align: center;\">gldt</td>\n<td style=\"text-align: center;\">Clone, push, and pull container registry images of a project without a user and a password</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Deploy keys</td>\n<td style=\"text-align: center;\">N/A</td>\n<td style=\"text-align: center;\">Allow read-only or read-write access to your repositories</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Runner authentication token</td>\n<td style=\"text-align: center;\">glrt</td>\n<td style=\"text-align: center;\">Authenticate GitLab Runners</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">CI/CD job token</td>\n<td style=\"text-align: center;\">glcbt</td>\n<td style=\"text-align: center;\">Automate CI/CD processes</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Trigger token</td>\n<td style=\"text-align: center;\">glptt</td>\n<td style=\"text-align: center;\">Trigger pipelines manually or programmatically</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Feed token</td>\n<td style=\"text-align: center;\">glft</td>\n<td style=\"text-align: center;\">Authenticate access to package/RSS feeds</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Incoming mail token</td>\n<td style=\"text-align: center;\">glimt</td>\n<td style=\"text-align: center;\">Process incoming emails</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">GitLab agent for Kubernetes token</td>\n<td style=\"text-align: center;\">glagent</td>\n<td style=\"text-align: center;\">Manage Kubernetes clusters via the GitLab agent</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">SCIM tokens</td>\n<td style=\"text-align: center;\">glsoat</td>\n<td style=\"text-align: center;\">Enable SCIM integrations for user provisioning</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Feature flags client token</td>\n<td style=\"text-align: center;\">glffct</td>\n<td style=\"text-align: center;\">Enable feature flags programmatically</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Webhook token</td>\n<td style=\"text-align: center;\">N/A</td>\n<td style=\"text-align: center;\">User set secret token to secure webhook payloads and ensure that the requests are from GitLab</td>\n</tr>\n</tbody>\n</table>\n<h2>Discovering your tokens</h2>\n<h3>Credentials inventory</h3>\n<p>On GitLab Ultimate, administrators (GitLab Self-Managed) and top-level group owners of an enterprise organization (GitLab.com as of Version 17.5) can monitor the credentials in their namespace.</p>\n<p>This inventory tracks token details such as:</p>\n<ul>\n<li>Token type\n<ul>\n<li>Available tokens on <a href=\"https://docs.gitlab.com/ee/user/group/credentials_inventory.html\">GitLab.com</a></li>\n<li>Available tokens on <a href=\"https://docs.gitlab.com/ee/administration/credentials_inventory.html\">GitLab Self-Managed</a></li>\n</ul>\n</li>\n<li>Associated user accounts</li>\n<li>Token scopes, and creation and expiration dates</li>\n<li>Token last used IP addresses (as of GitLab 17.10)</li>\n<li>Token filtration based on the above user-defined parameters</li>\n<li>Ability to revoke and rotate those tokens</li>\n</ul>\n<p>A well-maintained credentials inventory helps identify over-permissioned tokens, and gives insight into credentials that may need to be rotated, ensuring a secure and efficient workflow.</p>\n<p>&lt;!-- blank line --&gt;\n&lt;figure class=\"video_container\"&gt;\n&lt;iframe src=\"https://www.youtube.com/embed/A9ONfnwswd0?si=4VIEUgJaD4daj81b&amp;start=105\" frameborder=\"0\" allowfullscreen=\"true\"&gt; &lt;/iframe&gt;\n&lt;/figure&gt;\n&lt;!-- blank line --&gt;</p>\n<h4>Credentials inventory API</h4>\n<p>As a complement to the UI, there is <a href=\"https://gitlab.com/groups/gitlab-org/-/epics/16343\">ongoing development</a> to release a credentials inventory API through the new /group/:id/manage <a href=\"https://docs.gitlab.com/ee/api/members.html#list-all-members-of-a-group-or-project\">endpoint</a>. The credentials accessible under this endpoint are limited to enterprise <a href=\"https://docs.gitlab.com/ee/user/enterprise_user/\">users</a>, and can be accessed by the top-level group owner of an enterprise organization. An example of the future API call would be:</p>\n<pre><code class=\"language-console\">curl --header \"PRIVATE-TOKEN: &lt;pat&gt;\" \"https://verified_domain.com/api/v4/groups/&lt;group_id&gt;/manage/personal_access_tokens\"           \n</code></pre>\n<h3>GitLab API</h3>\n<p>The GitLab API allows you to programmatically list and manage tokens within your organization. Key authentication-related endpoints support <a href=\"https://docs.gitlab.com/ee/api/rest/authentication.html\">various token types</a>), including personal, group, CI/CD tokens, and more. An example of using a personal access token to list all visible projects across GitLab for the authenticated user is:</p>\n<pre><code class=\"language-console\">curl --header \"PRIVATE-TOKEN: &lt;your_access_token&gt;\" \\\n     \"https://gitlab.example.com/api/v4/projects\"\n\n</code></pre>\n<p>Watch this video to learn how to make API calls to the GitLab API.</p>\n<p>&lt;!-- blank line --&gt;\n&lt;figure class=\"video_container\"&gt;\n&lt;iframe src=\"https://www.youtube.com/embed/0LsMC3ZiXkA?si=vj871YH610jwQdFc\" frameborder=\"0\" allowfullscreen=\"true\"&gt; &lt;/iframe&gt;\n&lt;/figure&gt;\n&lt;!-- blank line --&gt;</p>\n<h3>Finding where tokens are used</h3>\n<p>Customers can find where tokens are used in different ways:</p>\n<ul>\n<li>under <strong>User Profile &gt; <a href=\"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html#view-the-time-at-and-ips-where-a-token-was-last-used\">Access Tokens</a></strong></li>\n<li>in credentials inventory</li>\n<li>in audit events</li>\n<li>via the API</li>\n</ul>\n<p>Information on token usage is updated every 10 minutes for <strong>last_used</strong> and every minute for <strong>last_used_ip</strong>.</p>\n<p>The ability to view IP addresses was introduced in GitLab 17.9, and is controlled by the <strong>:pat_ip</strong> feature flag. Follow these <a href=\"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html#view-the-time-at-and-ips-where-a-token-was-last-used\">steps to view the last time a token was used</a>, along with its last five distinct IP addresses.</p>\n<p><img alt=\"Token management guide - personal access tokens settings\" src=\"https://images.ctfassets.net/r9o86ar0p03f/kVZTX9mQuKy9EKWJ9MVZL/0a1e6f925774129712b5738a7a188f66/image1.png\" /></p>\n<h2>Managing tokens in the GitLab UI and API</h2>\n<p>The following table includes videos detailing a few token creations in the UI and demonstrates their usage via the API.</p>\n<table>\n<thead>\n<tr>\n<th>Tokens</th>\n<th>GitLab UI</th>\n<th>GitLab API</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Personal access token</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html#create-a-personal-access-token\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=3\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/personal_access_tokens.html\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=43\">video</a></td>\n</tr>\n<tr>\n<td>Group access token</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/group/settings/group_access_tokens.html#group-access-tokens\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=120\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/group_access_tokens.html\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=157\">video</a></td>\n</tr>\n<tr>\n<td>Project access token</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/project/settings/project_access_tokens.html#project-access-tokens\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=254\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/project_access_tokens.html\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=285\">video</a></td>\n</tr>\n</tbody>\n</table>\n<h2>Token rotation and expiration management</h2>\n<p>Implementing token rotation and strict expiration policies reduces the risk of compromise and ensures compliance with security standards. Regular rotation and enforced expirations prevent stale credentials from becoming security vulnerabilities.</p>\n<p>Previously, expired group and project access tokens were automatically deleted upon expiration, which made auditing and security reviews more challenging due to the lack of a record of inactive tokens. To address this, a <a href=\"https://gitlab.com/gitlab-org/gitlab/-/issues/462217\">recent feature</a> introduced the retention of inactive group and project access token records in the UI for 30 days after they became inactive. This enhancement aims to allow teams to track token usage, expiration, and revocation for better compliance and monitoring.</p>\n<p>To be more proactive in your token rotation and expiration management, do the following:</p>\n<ul>\n<li>Actively rotate your tokens via the UI or API. If you use the latter, be mindful of the <a href=\"https://docs.gitlab.com/ee/api/personal_access_tokens.html#automatic-reuse-detection\">automatic token reuse detection</a> security mechanism.</li>\n<li>Set an instance-wide <a href=\"https://docs.gitlab.com/ee/administration/settings/account_and_limit_settings.html#limit-the-lifetime-of-access-tokens\">maximum lifetime limit</a> for access tokens.</li>\n</ul>\n<h3>Token rotation API</h3>\n<p>Until GitLab 17.7, customers had to programmatically rotate access tokens with the API. Its counterpart is now available on the UI. Check out the video in the table below or follow the <a href=\"https://docs.gitlab.com/ee/user/project/settings/project_access_tokens.html#use-the-ui\">documentation</a> for guidance.</p>\n<h3>Token rotation snippets</h3>\n<p>The following table includes videos detailing the rotation of GitLab tokens.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">Tokens</th>\n<th style=\"text-align: center;\">Prerequisites</th>\n<th>GitLab UI</th>\n<th>GitLab API</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">Personal access token</td>\n<td style=\"text-align: center;\">Scope: api</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html#create-a-personal-access-token\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=76\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/personal_access_tokens.html#rotate-a-personal-access-token\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=92\">video</a></td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Group access token</td>\n<td style=\"text-align: center;\">Scope: api and Role(s): owner</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/group/settings/group_access_tokens.html#create-a-group-access-token-using-ui\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=203\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/group_access_tokens.html\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=214\">video</a></td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">Project access token</td>\n<td style=\"text-align: center;\">Scope: api and Role(s): owner, maintainer</td>\n<td><a href=\"https://docs.gitlab.com/ee/user/project/settings/project_access_tokens.html#create-a-project-access-token\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=335\">video</a></td>\n<td><a href=\"https://docs.gitlab.com/ee/api/project_access_tokens.html\">Documentation</a> and <a href=\"https://youtu.be/v5Nj3Jy4vaI?t=349\">video</a></td>\n</tr>\n</tbody>\n</table>\n<h2>Token management best practices</h2>\n<h3>Principle of least privilege</h3>\n<p>Mitigate risk by restricting assigned permissions to tokens required for their respective tasks. This allows you to proactively predict and troubleshoot points of failure in your systems. You can do this by:</p>\n<ul>\n<li>Selecting the right token for the right job. See the flowchart.</li>\n<li>Assign only the required scopes when creating a token. For example, use read-only scopes for tokens with auditor-like jobs. See <a href=\"https://docs.gitlab.com/ee/user/permissions.html#roles\">roles</a>.</li>\n<li>Avoid granting administrative privileges unless specifically required.</li>\n<li>Enforce instance-wide default token <a href=\"https://docs.gitlab.com/ee/administration/settings/account_and_limit_settings.html#set-a-lifetime-1\">lifetimes</a>.</li>\n<li>Regularly review and audit token permissions to ensure they align with current operational needs.</li>\n<li>Revoke tokens once the task is complete.</li>\n</ul>\n<h3>Service accounts</h3>\n<p><a href=\"https://docs.gitlab.com/ee/user/profile/service_accounts.html\">Service accounts</a> ensure tokens are tied to non-human entities, separating them from individual user accounts and reducing dependency on specific users. Instead of using personal accounts to generate tokens for automation, create service accounts with limited scopes. Benefits include:</p>\n<ul>\n<li>Usage of service account tokens in CI/CD pipelines to avoid disruptions caused by user account changes</li>\n<li>Programmatically automate rotation processes, as personal accounts remain unaffected</li>\n<li>Clearer monitoring and auditing trail of actions taken by service accounts</li>\n<li>Service accounts with <a href=\"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html#create-a-service-account-personal-access-token-with-no-expiry-date\">no expiration</a> date</li>\n<li>Does not consume <a href=\"https://docs.gitlab.com/user/profile/service_accounts/#create-a-service-account\">a license seat</a></li>\n</ul>\n<p>GitLab plans to release a new <a href=\"https://gitlab.com/groups/gitlab-org/-/epics/9965\">Service Accounts UI</a> as a counterpart to its <a href=\"https://docs.gitlab.com/ee/api/user_service_accounts.html#create-a-service-account-user\">API-based creation</a>, designed to simplify the management of service accounts and their associated tokens. Check out the demo below on the programmatic usage of service accounts.</p>\n<p>&lt;!-- blank line --&gt;\n&lt;figure class=\"video_container\"&gt;\n&lt;iframe src=\"https://www.youtube.com/embed/oZvjg0SCsqY?si=cj-0LjfeonLGXv9u\" frameborder=\"0\" allowfullscreen=\"true\"&gt; &lt;/iframe&gt;\n&lt;/figure&gt;\n&lt;!-- blank line --&gt;</p>\n<h3>Vulnerability tools</h3>\n<p>Leverage GitLab‚Äôs built-in security tools to identify and mitigate vulnerabilities associated with token usage. For maximum coverage, it is recommended to use them all in tandem.</p>\n<ul>\n<li><a href=\"https://docs.gitlab.com/ee/user/application_security/secret_detection/\">Secret Detection</a>: Scans your repository for hardcoded secrets like API tokens, passwords, and other sensitive information. View the <a href=\"https://docs.gitlab.com/ee/user/application_security/secret_detection/detected_secrets.html\">list of detected secrets</a>.</li>\n<li><a href=\"https://docs.gitlab.com/ee/user/application_security/sast/\">Static Application Security Testing (SAST)</a>: Analyzes your source code for security vulnerabilities and <a href=\"https://docs.gitlab.com/ee/user/application_security/sast/#features\">provides reports with UI findings in merge requests</a>, among other features.</li>\n<li><a href=\"https://docs.gitlab.com/ee/user/application_security/dependency_scanning/\">Dependency Scanning</a>: Ensures that third-party libraries used in your project do not expose token-related vulnerabilities.</li>\n</ul>\n<h3>Audit logs and monitoring</h3>\n<p>Maintain token health by regularly reviewing audit logs and token usage, instance- and/or group-wide.</p>\n<ul>\n<li><a href=\"https://docs.gitlab.com/ee/user/compliance/audit_events.html\">Audit events</a>: Enable audit event logging in GitLab to track token-related activities such as creation, usage, deletion and unusual API calls (unpermitted parameters in logs, and consistent triggers of the rate limiter).</li>\n<li><a href=\"https://docs.gitlab.com/ee/administration/reporting/ip_addr_restrictions.html#configure-ip-address-restrictions\">IP allowlisting</a>: Helps prevent malicious users from hiding their activities behind multiple IP addresses.</li>\n<li><a href=\"https://docs.gitlab.com/ee/operations/incident_management/alerts.html\">Alerts</a>: Set up alerts for unusual activities (trigger paging for on-call rotations or be used to create incidents).</li>\n<li><a href=\"https://docs.gitlab.com/ee/administration/credentials_inventory.html\">Credentials inventory</a>: Complete control of all available access tokens with the ability to revoke as needed.</li>\n<li><a href=\"https://docs.gitlab.com/ee/user/profile/notifications.html\">Notifications</a>: Proactively handle any token (group, project, and personal) expiration notification emails you receive. Based on customer demand, this feature was recently extended to include 30-day and 60-day notifications from the seven-day default.</li>\n<li><a href=\"https://docs.gitlab.com/ee/user/project/integrations/webhooks.html#create-a-webhook\">Webhooks</a>: Access token webhooks can be configured on groups and projects to send seven-day token expiry events. This feature was also recently extended to include 30-day and 60-day notifications behind the <strong>:extended_expiry_webhook_execution_setting</strong> feature flag (disabled by default).</li>\n</ul>\n<h2>What's next</h2>\n<p>With GitLab‚Äôs large token catalog, there are ongoing <a href=\"https://gitlab.com/gitlab-org/gitlab/-/issues/502630\">plans</a> for consolidation with a focus on the lifetime, fine-grained scopes, consistent management, and usage. Our current prioritized token-related features include a complete UI for service accounts, additional credential types in the credentials inventory, and improved auditing for tokens and service accounts.</p>\n<blockquote>\n<p>Sign up for a <a href=\"https://about.gitlab.com/free-trial/\">free 60-day trial of GitLab Ultimate</a> to start using token management.</p>\n</blockquote>",
      "timestamp": 1741512167.3508565,
      "translated": false
    },
    {
      "feed_name": "GitLab Kubernetes Blog",
      "source_language": "en",
      "title": "GitLab Duo Workflow: Enterprise visibility and control for agentic AI",
      "link": "https://about.gitlab.com/blog/2025/02/24/gitlab-duo-workflow-enterprise-visibility-and-control-for-agentic-ai",
      "published": "2025-02-24T00:00:00.000Z",
      "summary": "<p>Today, we're excited to announce the opening of the waitlist for the <a href=\"https://about.gitlab.com/gitlab-duo/workflow\">private beta of GitLab Duo Workflow</a>: <strong>agentic AI built on top of the most comprehensive DevSecOps platform.</strong> The next step in our AI roadmap, GitLab Duo Workflow will help development teams navigate everything from project bootstrapping to deployment processes, from debugging issues to cross-team coordination, all within the IDE.</p>\n<p>GitLab Duo Workflow leverages the GitLab platform's structure for collaboration, continuous integration, continuous deployment, security, and compliance to help organizations as they accelerate their development process with AI agents.</p>\n<p>Use GitLab Duo Workflow to help you:</p>\n<ul>\n<li><a href=\"https://about.gitlab.com/atom.xml#from-slow-project-setup-to-a-running-start\">bootstrap a new development project</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#from-legacy-code-to-modern-applications\">modernize code</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#from-context-switching-to-flow-state\">perform contextual tasks</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#from-stale-docs-to-dynamic-knowledge\">create documentation</a></li>\n<li><a href=\"https://about.gitlab.com/atom.xml#from-patchy-to-comprehensive-testing\">enhance test coverage</a></li>\n<li>and more</li>\n</ul>\n<p>This is just the beginning. With GitLab‚Äôs unified data store, the more you use GitLab, the more context GitLab Duo Workflow has about your code, configurations, security findings, and deployment practices. The result: an increasingly powerful development experience that's tailored to your organization.</p>\n<h2>The promise and challenge of AI agents</h2>\n<p>Software has fundamentally changed the world, but only a tiny fraction of the world's population has the skills to build software today. Yet, these developers reach billions of people with smartphones and internet connections. Just imagine a world where <em>more</em> people can build, secure, and deliver production-ready software ‚Äì there will be an explosion of innovation as more people can create software that impacts billions. <strong>Agentic AI will make that happen.</strong></p>\n<p>AI agents understand context, maintain knowledge of entire codebases, and actively collaborate on complex software projects across development, security, and operations. With AI agents, developers can create software at a scale previously unimaginable for individuals or even teams.</p>\n<p>But this shift raises important questions about visibility, control, and how AI will impact developers' work. Organizations need to ensure AI enhances their developers' capabilities while enabling them to maintain oversight of their development process. The key to success isn't just adopting AI ‚Äì it's adopting it in a way that empowers developers while preserving security, compliance, and governance.</p>\n<h2>AI's success depends on your platform, not more add-on tools</h2>\n<p>When you're working with more developers, code, and potential security risks, adding separate tools for each new challenge only creates more complexity. Our most recent <a href=\"https://about.gitlab.com/the-source/platform/devops-teams-want-to-shake-off-diy-toolchains-a-platform-is-the-answer/\">DevSecOps Survey</a> shows just how serious this problem is: DevSecOps teams are juggling up to 14 different tools, with professionals spending up to 80% of their time on non-coding tasks. For AI to be truly effective, it also needs high-quality, unified data. That's hard to achieve with disparate tools.</p>\n<p><strong>The GitLab DevSecOps platform combined with GitLab AI agents</strong> brings everything together in a single data model that encapsulates source code, merge requests, epics, users, access rights, and more. The agents we're building use context about users and projects to standardize how teams work and automate the non-coding tasks that absorb developer time, such as scanning for security issues and enforcing compliance rules. When AI is built directly into the platform, these capabilities become even more powerful, turning AI agents into development partners while keeping you in control of how AI enhances the process.</p>\n<p><strong>This isn't a far-off future ‚Äî it's what we're building right now with GitLab Duo Workflow.</strong></p>\n<p>&lt;div style=\"padding:56.25% 0 0 0;position:relative;\"&gt;&lt;iframe src=\"https://player.vimeo.com/video/1059060959?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"GitLab Duo Workflow, the future of secure agentic AI software development\"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script src=\"https://player.vimeo.com/api/player.js\"&gt;&lt;/script&gt;`</p>\n<h2>GitLab Duo Workflow: AI agents on the most comprehensive DevSecOps platform</h2>\n<p>Leveraging GitLab's end-to-end DevSecOps platform, GitLab Duo Workflow helps developers work at their highest potential. While AI coding assistants help with individual pieces of code, GitLab Duo Workflow will understand your entire development lifecycle ‚Äì automating routine tasks so developers can focus on strategic innovation and creative problem-solving. As we develop GitLab Duo Workflow, here‚Äôs what it will be able to help teams achieve:</p>\n<h3>From slow project setup to a running start</h3>\n<p>Developers spend precious time configuring new projects, managing dependencies, and setting up basic infrastructure instead of building new features. With GitLab Duo Workflow, you can <strong>automate project bootstrapping directly in the IDE</strong>, providing the right configurations from the start so you can focus on innovation sooner.</p>\n<h3>From legacy code to modern applications</h3>\n<p>Modernizing legacy code is more than just updating syntax ‚Äî it requires understanding dependencies, tests, CI/CD pipelines, and documentation. GitLab Duo Workflow helps <strong>modernize your codebase by handling code refactoring</strong> ‚Äì from code to tests.</p>\n<h3>From context switching to flow state</h3>\n<p>Today, developers constantly switch between tools, docs, and codebases to solve problems. GitLab Duo Workflow will help <strong>resolve tasks with the full context of your codebase-related issues and merge requests</strong>, letting developers stay in their flow.</p>\n<h3>From stale docs to dynamic knowledge</h3>\n<p>Documentation becomes stale quickly, making codebases harder to understand and maintain. GitLab Duo Workflow <strong>supports developers in generating and updating documentation</strong>, including README files, code flow diagrams, and architecture documentation.</p>\n<h3>From patchy to comprehensive testing</h3>\n<p>As codebases grow, maintaining comprehensive test coverage becomes increasingly challenging. GitLab Duo Workflow <strong>can generate tests for entire sections of your codebase</strong> while integrating with your existing test infrastructure, ensuring more reliable software with less effort.</p>\n<h2>Sign up for the private beta waitlist</h2>\n<p><a href=\"https://about.gitlab.com/gitlab-duo/workflow\">Sign up for the GitLab Duo Workflow private beta waitlist</a> to see the next step in our vision for secure agentic AI ‚Äì from project setup to deployment. Built on GitLab's DevSecOps platform, these agents understand your entire software lifecycle while maintaining the enterprise-grade security and control organizations require.</p>\n<p><em>Disclaimer: This page contains information about upcoming products, features, and functionality. This information is for informational purposes only and should not be relied upon for purchasing or planning. All items are subject to change or delay, and the development, release, and timing remain at GitLab Inc.'s sole discretion.</em></p>",
      "timestamp": 1741512167.35086,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Powered by DigitalOcean Hatch: How Ex-human uses GPU Droplets to Build Empathetic AI that Serves Customers",
      "link": "https://www.digitalocean.com/blog/ex-human-digitalocean-ai-hatch-program",
      "published": "2025-03-07T17:27:49.482Z",
      "summary": "<p>Hatch is DigitalOcean‚Äôs global program for startups, which provides startups with credits and discounts on computing resources so they can build and scale without worrying about costs. In 2024, Hatch significantly revamped the program to better support those building businesses in the artificial intelligence sector, providing AI/ML startups with discounts for <a href=\"https://www.digitalocean.com/products/gpu-droplets\">GPU Droplets</a> and free access to DigitalOcean‚Äôs premium support in addition to credits.</p>\n<p><a href=\"https://exh.ai/\" rel=\"ugc nofollow noopener\" target=\"_blank\">Ex-human</a>, a startup building empathetic generative AI solutions backed by A16Z GAMES‚Äô SPEEDRUN accelerator, chose the Hatch program to help serve their customers with AI models‚Äîread on to hear about their experience with Hatch so far.</p>\n<h2 id=\"from-film-to-the-future\"><a href=\"https://www.digitalocean.com/blog.atom#from-film-to-the-future\">From film to the future</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#from-film-to-the-future\"></a></h2>\n<p>Inspired by the characters Sam from <em>Her (2013)</em> and Joi from <em>Blade Runner 2049 (2017)</em>, Artem Rodichev, founder and CEO of Ex-human, sought to build a future where humans interact with digital humans and characters on a daily basis, taking the form of friends, mentors, lovers, and more. After a stint at Replika, Rodichev saw that humans were building deeper connections with their AI companions and wanted to create a solution that was both viable for consumers and businesses.</p>\n<p>Ex-human brings their AI characters to life through text, images, video, and audio with unlimited scalability and customizability that opens up possibilities for numerous use cases. Partnering with companies such as Grindr, who are using Ex-human‚Äôs technology to bring an AI wingman to life, this technology has the opportunity to help humans form stronger bonds in both physical and digital worlds.</p>\n<h2 id=\"innovation-shouldn-t-come-at-a-high-cost\"><a href=\"https://www.digitalocean.com/blog.atom#innovation-shouldn-t-come-at-a-high-cost\">Innovation shouldn‚Äôt come at a high cost</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#innovation-shouldn-t-come-at-a-high-cost\"></a></h2>\n<p>Building AI technology requires large amounts of computing power, which can come at a high price, especially for a new business. Ex-human chose the Hatch program because it offers exclusive pricing for access to on-demand NVIDIA H100 GPU Droplets at <strong>$1.90/GPU/hour</strong>*. Despite the favorable cost, Ex-human finds that there are no tradeoffs with power and reliability, giving them a solution that works for their budget and delivers for their needs. Ex-human uses GPU Droplets to serve their LLMs so customers can take advantage of their technology‚Äôs power.</p>\n<p>‚ÄúDigitalOcean‚Äôs GPU Droplets are great. 99% of the time, it [is] used for serving our LLMs. I don‚Äôt think we have any trouble with unavailability, network issues, or stuff like that with DigitalOcean. We found DigitalOcean to be more intuitive and simpler than working with AWS or Google Cloud. It‚Äôs simple, not expensive, and reliable.‚Äù ‚Äì Artem Rodichev, Founder and CEO @ Ex-human</p>\n<p>GPU Droplets allow for users to build, train, and scale their AI/ML workloads with ease. Through the Hatch program, you can access vast amounts of computational power without having to break the bank.</p>\n<p>Hatch startups also receive:</p>\n<ul>\n<li>\n<p>Up to $100,000 in compute credits</p>\n</li>\n<li>\n<p>Three months free of one NVIDIA H100x8 GPU Droplet</p>\n</li>\n<li>\n<p>Complimentary premium support</p>\n</li>\n<li>\n<p>GenAI usage with Hatch credits</p>\n</li>\n</ul>\n<p>*Note that GPU Droplet usage will not be covered by Hatch compute credits. This pricing is only eligible for startups who are a part of the Hatch program, only applies to on-demand NVIDIA H100 GPU Droplets, and is accurate as of 3/7/2025. Pricing is subject to change.</p>\n<h2 id=\"musings-from-the-founder\"><a href=\"https://www.digitalocean.com/blog.atom#musings-from-the-founder\">Musings from the founder</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#musings-from-the-founder\"></a></h2>\n<p>As a founder, Rodichev uses his deep expertise in AI/ML to guide Ex-human‚Äôs business and vision. While leading product development, he works alongside a talented team handling engineering, marketing, sales, investor relations, and everything in between. It‚Äôs hard work, but it‚Äôs deeply rewarding.</p>\n<p>Rodichev: ‚ÄúMy number one advice‚Äìdon‚Äôt start a startup. [laughs] The number two advice‚Äìdo it if that‚Äôs the only thing you can do. If you really have a chip on your shoulder, if you really want to change the world in a way that you see how the world will develop, if you really want to build this kind of feature and no one else can build it, go start a startup.‚Äù</p>\n<p>The simplicity and reliability of DigitalOcean‚Äôs products affords founders like Rodichev to focus on things outside of managing their product‚Äôs infrastructure so they can build the future at full speed.</p>\n<p><strong>Interested in joining the Hatch program to grow your startup? Visit</strong> <a href=\"http://do.co/hatch\" rel=\"ugc nofollow noopener\" target=\"_blank\"><strong>do.co/hatch</strong></a> <strong>to learn more about the program and apply or contact our team at</strong> <a href=\"mailto:hatch@digitalocean.com\" rel=\"ugc nofollow noopener\" target=\"_blank\"><strong>hatch@digitalocean.com</strong></a> <strong>with any questions.</strong></p>\n<p><em>Hatch, DigitalOcean‚Äôs global program for startups, is committed to helping AI/ML startups by providing infrastructure credits and discounts, free access to premium support, a welcoming community of builders, and so much more so founders can focus on what‚Äôs important‚Äìbuilding technology that changes the world.</em></p>",
      "timestamp": 1741512167.9887328,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Scale smarter with DigitalOcean's latest networking upgrades",
      "link": "https://www.digitalocean.com/blog/nlb-ipv6",
      "published": "2025-03-03T18:08:43.823Z",
      "summary": "<p>Growing businesses need networking solutions that are simple, scalable, and reliable. Whether you‚Äôre managing high-traffic applications, optimizing cloud resources, or strengthening security, our latest networking updates are designed to make your cloud infrastructure more powerful and easier to manage. Today, we‚Äôre excited to announce three key networking enhancements: <strong>Network Load Balancer</strong>, <strong>IPv6 for Load Balancers</strong>, and <strong>Reserved IPv6 for Droplets</strong>. Let‚Äôs dive into how these updates can help you distribute traffic efficiently, ensure stability across deployments, and future-proof your networking stack.</p>\n<h2 id=\"network-load-balancer-smarter-traffic-distribution-for-high-performance-apps\"><a href=\"https://www.digitalocean.com/blog.atom#network-load-balancer-smarter-traffic-distribution-for-high-performance-apps\">Network Load Balancer: Smarter traffic distribution for high-performance apps</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#network-load-balancer-smarter-traffic-distribution-for-high-performance-apps\"></a></h2>\n<figure><img alt=\"Network Load Balancer\" src=\"https://networking.nyc3.digitaloceanspaces.com/NLB-new.gif\" /><figcaption>Network Load Balancer</figcaption></figure>\n<p>When your application experiences a surge in users, every millisecond counts. Our new <strong>Network Load Balancer,</strong> now in public preview, is designed to handle high-traffic volumes with greater efficiency and resilience. Unlike our existing load balancer, which operates at the application layer (Layer 7), the Network Load Balancer works at the transport layer (Layer 4). This means lower latency, higher throughput, unmetered total number of connections, and better handling of real-time workloads like gaming, streaming, and chat applications.</p>\n<p><strong>Key benefits:</strong></p>\n<ul>\n<li><strong>Ultra-low latency:</strong> Directs traffic at the IP/protocol level for faster response times.</li>\n<li><strong>Scalable volume management:</strong> Handles high request volumes with minimal overhead.</li>\n<li><strong>Unmetered connections:</strong> Handles up to  millions of connections and requests per second</li>\n</ul>\n<p>With a simple setup and automatic failover, Network Load Balancer helps ensure your application stays responsive‚Äîeven when traffic spikes unexpectedly</p>\n<h2 id=\"ipv6-support-for-internet-facing-regional-load-balancers-delivering-dependable-performance\"><a href=\"https://www.digitalocean.com/blog.atom#ipv6-support-for-internet-facing-regional-load-balancers-delivering-dependable-performance\">IPv6 support for internet-facing regional Load Balancers: Delivering dependable performance</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#ipv6-support-for-internet-facing-regional-load-balancers-delivering-dependable-performance\"></a></h2>\n<figure><img alt=\"IPv6 for load balancers\" src=\"https://networking.nyc3.digitaloceanspaces.com/lb-v6-new-2.gif\" /><figcaption>IPv6 for load balancers</figcaption></figure>\n<p>You can now support IPv6 client connections by assigning IPv6 addresses to your internet-facing load balancers, and even dual-stack your external-facing regional load balancer that gets both IPv4 and IPv6 addresses. Any addresses you assign will persist throughout the lifetime of the load balancer.</p>\n<p><strong>Why it matters:</strong></p>\n<ul>\n<li><strong>IPv4 depletion:</strong> Less to worry about running out of IPv4 addresses. IPv6 support offers a larger address space than IPv4.</li>\n<li><strong>IPv6 client support:</strong> Dual stack your load balancers and support IPv6 clients without modifying your application stack.</li>\n<li><strong>Better global accessibility:</strong> IPv6 is designed to  support growth for businesses scaling internationally or with large distributed workloads.</li>\n</ul>\n<h2 id=\"reserved-ipv6-for-droplets-build-a-scalable-and-resilient-infrastructure\"><a href=\"https://www.digitalocean.com/blog.atom#reserved-ipv6-for-droplets-build-a-scalable-and-resilient-infrastructure\">Reserved IPv6 for Droplets: Build a scalable and resilient infrastructure</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#reserved-ipv6-for-droplets-build-a-scalable-and-resilient-infrastructure\"></a></h2>\n<figure><img alt=\"Reserved IPv6 for Droplets\" src=\"https://networking.nyc3.digitaloceanspaces.com/Reserved-IP.gif\" /><figcaption>Reserved IPv6 for Droplets</figcaption></figure>\n<p>For developers building scalable cloud environments, managing IP addresses should be effortless. With <strong>Reserved IPv6 for Droplets</strong>, now available for public preview, you can reserve, assign, unassign, and reassign IPv6 addresses across different Droplets or to a specific data center. Whether you‚Äôre migrating workloads, deploying blue-green updates, or ensuring continuity after scaling events, Reserved IPv6 gives you the flexibility to manage your network more efficiently.This feature is perfect for teams that need predictable networking while keeping infrastructure simple and cost-effective.</p>\n<p><strong>How it helps:</strong></p>\n<ul>\n<li><strong>IP persistence:</strong> Retain IP addresses when upgrading or replacing Droplets.</li>\n<li><strong>Improved service continuity:</strong> Avoid disruptions during maintenance or scaling.</li>\n<li><strong>More control over your network:</strong> Assign IPv6 addresses based on workload needs.</li>\n</ul>\n<h2 id=\"get-started-with-better-networking-today\"><a href=\"https://www.digitalocean.com/blog.atom#get-started-with-better-networking-today\">Get started with better networking today</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#get-started-with-better-networking-today\"></a></h2>\n<p>These networking enhancements are now available to help you scale with confidence. Whether you need <strong>better load balancing</strong>, <strong>more stable networking</strong>, or <strong>greater control over your IP addresses</strong>, these updates empower you to build resilient, high-performance applications without added complexity.</p>\n<p>To start using <strong>Network Load Balancer</strong>, <strong>IPv6 for Load Balancers</strong>, or <strong>Reserved IPv6 for Droplets</strong>, check out our <a href=\"https://docs.digitalocean.com/products/networking/\" rel=\"ugc nofollow noopener\" target=\"_blank\">documentation</a> or visit your <a href=\"https://cloud.digitalocean.com/login\" rel=\"ugc nofollow noopener\" target=\"_blank\">DigitalOcean console</a>.</p>\n<p>Have questions or feedback? Join the conversation in our <a href=\"https://do.co/discord\" rel=\"ugc nofollow noopener\" target=\"_blank\">community forums</a> or reach out to our support team. We‚Äôd love to hear from you!</p>",
      "timestamp": 1741512167.9887378,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Sharks of DigitalOcean: Apple Li, Director of Financial Planning and Analysis (FP&amp;A)",
      "link": "https://www.digitalocean.com/blog/shark-tales-apple-li-director",
      "published": "2025-03-03T10:37:45.315Z",
      "summary": "<p>Meet Apple Li, our Director of Financial Planning and Analysis (FP&amp;A) in New York City. Apple and her team are the architects behind aligning our financial vision with company goals, driving sustainable growth. Dive into this spotlight to discover Apple‚Äôs inspiring journey, her passion for DO‚Äôs mission, and the impact she and her team make every day.</p>\n<h2 id=\"what-inspired-you-to-join-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#what-inspired-you-to-join-digitalocean\">What inspired you to join DigitalOcean?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-inspired-you-to-join-digitalocean\"></a></h2>\n<p>I studied finance in college and started my career as an equity research analyst working for an asset management company. I wanted to work for a fast-growing and innovative company where I could make an impact. So, I switched careers and joined Digitalocean in 2019. There‚Äôs a lot of growth potential for this company, driven by digital transformation and companies moving to the cloud.</p>\n<h2 id=\"what-do-you-enjoy-about-working-at-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#what-do-you-enjoy-about-working-at-digitalocean\">What do you enjoy about working at DigitalOcean?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-do-you-enjoy-about-working-at-digitalocean\"></a></h2>\n<p>I like DigitalOcean for its mission to simplify cloud computing and better help developers and businesses. We have a great team that truly cares about our customers and is working on products and technologies that will add value.</p>\n<h2 id=\"what-does-your-day-look-like\"><a href=\"https://www.digitalocean.com/blog.atom#what-does-your-day-look-like\">What does your day look like?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-does-your-day-look-like\"></a></h2>\n<p>I help the Product &amp; Technology org with budget planning and management. I do financial analysis for new product launches and new data centers and help the business understand the return on investment of our products and projects. I help to track financial metrics and create reporting materials for internal and external stakeholders. I have monthly meetings with budget owners to review and update budget forecasts. I also have ad hoc meetings with product and engineering leaders on pricing and margin analysis. Plus,I run monthly CapEx steering committee meetings to drive decisions on new investments.</p>\n<h2 id=\"what-is-the-role-of-your-team\"><a href=\"https://www.digitalocean.com/blog.atom#what-is-the-role-of-your-team\">What is the role of your team?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-is-the-role-of-your-team\"></a></h2>\n<p>Our primary goal is to help translate company initiatives and strategies into our financial plans. We also help the business understand the ROI of our products and projects for efficient resource allocation to drive company revenue and customer growth. My team‚Äôs qualities include accountability and ownership, DO fast, collaboration, and business partnership. We‚Äôre looking for people who are analytical, proactive, trustworthy, detail-oriented, passionate about the cloud space, and have strong financial modeling skills.</p>\n<div class=\"callout info\">\n<p>üé• Have a look at Apple‚Äôs full conversation ‚¨áÔ∏è</p>\n\n    <a href=\"https://www.youtube.com/watch?v=Gj2HNuNuUvg\" target=\"_blank\">View YouTube video</a>\n\n</div>\n<h2 id=\"what-excites-you-about-your-work\"><a href=\"https://www.digitalocean.com/blog.atom#what-excites-you-about-your-work\">What excites you about your work?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-excites-you-about-your-work\"></a></h2>\n<p>My team works on the annual planning process. We get to work cross-functionally with many teams across the organization, and ultimately, we come up with an operational and financial plan for the next year that will help us achieve our financial targets and fulfill our mission.</p>\n<h2 id=\"what-do-value-do-you-resonate-with-the-most\"><a href=\"https://www.digitalocean.com/blog.atom#what-do-value-do-you-resonate-with-the-most\">What DO value do you resonate with the most?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-do-value-do-you-resonate-with-the-most\"></a></h2>\n<p>I resonate the most with DO Learning. The company really encourages everyone to have a growth mindset and provides resources and tools to help people learn and grow. For example, we have a book program where we get reimbursed for buying books every month. We also get access to all these great materials on LinkedIn Learning.</p>\n<h2 id=\"dive-into-the-future-with-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#dive-into-the-future-with-digitalocean\">Dive into the future with DigitalOcean</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#dive-into-the-future-with-digitalocean\"></a></h2>\n<p>At DigitalOcean, our customers and community are at the heart of everything we do. We believe in acting like owners, with a bias for action and a relentless drive to simplify cloud computing. If you‚Äôre passionate about continuous learning, thinking bold, and being part of a supportive, innovative team, <a href=\"https://www.digitalocean.com/careers\">explore our open roles today</a>!</p>",
      "timestamp": 1741512167.9887419,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Introducing Bare Metal Systems Built on NVIDIA HGX H200",
      "link": "https://www.digitalocean.com/blog/now-available-bare-metal-nvidia-hgx-h200-gpus",
      "published": "2025-02-18T16:42:03.478Z",
      "summary": "<p>At DigitalOcean, we‚Äôre always working to make it easier for developers, startups, and AI-driven businesses to scale their operations with the high-powered compute they need. Today, we‚Äôre introducing <a href=\"https://www.digitalocean.com/products/bare-metal-gpu\">Bare Metal systems based on the NVIDIA HGX H200 AI supercomputing platform</a>, designed for high-performance AI workloads. Whether you‚Äôre training large-scale models, fine-tuning AI systems, or running real-time inference, <a href=\"https://www.nvidia.com/en-us/data-center/h200/\" rel=\"ugc nofollow noopener\" target=\"_blank\">NVIDIA H200 GPUs</a> provide the power and flexibility to accelerate AI applications.</p>\n<h2 id=\"why-h200\"><a href=\"https://www.digitalocean.com/blog.atom#why-h200\">Why H200?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#why-h200\"></a></h2>\n<p>Equipped with 8x <a href=\"https://www.nvidia.com/en-us/data-center/h200/\" rel=\"ugc nofollow noopener\" target=\"_blank\">NVIDIA HGX H200</a> systems, these machines deliver cutting-edge performance needed for modern AI workloads. NVIDIA H200 GPUs provide faster memory bandwidth, enhanced Tensor Core performance, and more efficient <a href=\"https://blogs.nvidia.com/blog/ai-inference-platform/\" rel=\"ugc nofollow noopener\" target=\"_blank\">real-time inference</a>, making them the ideal choice for large-scale AI deployments. With 141GB of HBM3e memory and a memory bandwidth of 4.8 TB/s, you can tackle complex AI tasks more efficiently, reduce latency, and push your projects further, faster.</p>\n<p>DigitalOcean‚Äôs Bare Metal systems powered by NVIDIA HGX H200 are built for flexibility, enabling you to use them as standalone machines or multi-node clusters. This means you can create custom AI infrastructures with full control over the hardware and software environments‚Äîperfect for training large language models (LLMs), running generative AI models, or fine-tuning proprietary systems.</p>\n<h2 id=\"key-benefits-of-nvidia-h200-gpus-include\"><a href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-nvidia-h200-gpus-include\">Key benefits of NVIDIA H200 GPUs include:</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#key-benefits-of-nvidia-h200-gpus-include\"></a></h2>\n<ul>\n<li>\n<p><strong>Faster Model Training:</strong> Handle larger batch sizes and improve memory efficiency, speeding up training times.</p>\n</li>\n<li>\n<p><strong>Efficient Fine-Tuning:</strong> Optimize foundation models with lower compute overhead and better latency.</p>\n</li>\n<li>\n<p><strong>Enhanced Real-Time Inference:</strong> Run transformer models with faster inference and better power efficiency.</p>\n</li>\n</ul>\n<h2 id=\"scalable-cost-effective-and-ready-for-deployment\"><a href=\"https://www.digitalocean.com/blog.atom#scalable-cost-effective-and-ready-for-deployment\">Scalable, Cost-Effective, and Ready for Deployment</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#scalable-cost-effective-and-ready-for-deployment\"></a></h2>\n<p>Unlike many <a href=\"https://www.digitalocean.com/resources/articles/hyperscaler-cloud\">hyperscalers</a>, our bare metal systems with NVIDIA accelerated computing come with no hidden fees, no complex billing models, and no additional bandwidth charges. Plus, we offer fast deployment with provisioning typically taking around 1-2 days, so you can start scaling your AI workloads quickly.</p>\n<p><strong>Ready to push your AI projects to the next level? <a href=\"https://www.digitalocean.com/products/bare-metal-gpu#sales-form\">Reserve capacity now or learn more about how our Bare Metal systems powered by NVIDIA HGX H200 can help you build faster, smarter AI applications.</a></strong></p>",
      "timestamp": 1741512167.9887474,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Introducing Bitbucket Integration for App Platform",
      "link": "https://www.digitalocean.com/blog/introducing-bitbucket-integration-for-app-platform",
      "published": "2025-02-12T16:00:00.025Z",
      "summary": "<p><a href=\"https://www.digitalocean.com/blog/introducing-digitalocean-app-platform-reimagining-paas-to-make-it-simpler-for-you-to-build-deploy-and-scale-apps\">DigitalOcean‚Äôs App Platform</a>, our Platform as a Service offering, provides seamless integration with major Git providers, enabling developers to deploy applications directly from their repositories. App Platform can automatically analyze and build code from GitHub, GitLab, and public Git repositories. This integration allows developers to focus on writing code while App Platform handles the infrastructure management and deployment process.</p>\n<p>We are excited to add <a href=\"https://bitbucket.org/\" rel=\"ugc nofollow noopener\" target=\"_blank\">Bitbucket Cloud</a> to the list of our supported Git providers. Bitbucket is a widely recognized and used source code management tool for both large and small-scale projects, and this integration with Bitbucket Cloud now enables users to <a href=\"https://cloud.digitalocean.com/apps/new\" rel=\"ugc nofollow noopener\" target=\"_blank\">create an app</a> and re-deploy it automatically when an update is made to the branch containing the source code.</p>\n<p><img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/bitbucket%20image%20one.png\" /></p>\n<p>Let‚Äôs dive into some technical aspects of Bitbucket integration.</p>\n<h2 id=\"git-provider-permissions\"><a href=\"https://www.digitalocean.com/blog.atom#git-provider-permissions\">Git provider permissions</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#git-provider-permissions\"></a></h2>\n<p>Like GitHub and GitLab, the integration with Bitbucket is implemented using OAuth 2.0 authentication flow. We create a Bitbucket OAuth 2.0 consumer app managed by App Platform and request users to grant permissions to this consumer app. This ensures that we have the correct set of scope and permissions to interact with Bitbucket APIs on behalf of the user. We only ask for minimum required permissions, which include:</p>\n<ul>\n<li>Read access to repositories</li>\n<li>Read access to account information</li>\n<li>Read and write access to webhooks</li>\n</ul>\n<p>OAuth 2.0 access tokens are used for authenticating with the Bitbucket APIs as well as cloning a repository in order to build and deploy an application. We have token refresh mechanisms to maintain continuous access.</p>\n<h2 id=\"api-integration\"><a href=\"https://www.digitalocean.com/blog.atom#api-integration\">API Integration</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#api-integration\"></a></h2>\n<p>App Platform‚Äôs backend integrates with Bitbucket‚Äôs RESTful APIs 2.0. Some of the APIs that we make use of are:</p>\n<ul>\n<li>List user‚Äôs workspaces</li>\n<li>List repositories in a workspace and branches in a repository. Note that we list only the repositories that a user has admin access to, since a user is not permitted to create webhooks without it.</li>\n<li>Fetch latest commits from a branch</li>\n<li>Fetch general user information like name and email</li>\n<li>List webhooks and create webhook in a repository</li>\n</ul>\n<h3 id=\"webhooks\"><a href=\"https://www.digitalocean.com/blog.atom#webhooks\">Webhooks</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#webhooks\"></a></h3>\n<p>Webhooks are callback APIs that are triggered by specific events. App Platform creates a webhook on a source code repository with trigger set to repository push events. Once configured, Bitbucket sends an HTTP Post request to this configured URL, delivering a payload with information about the push event. This information helps us automate the process of deploying source code from Bitbucket to your applications.</p>\n<p><img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/bitbucket%20image%202.png\" /></p>\n<p>You can see the configured <strong>App Platform Integration Webhook</strong> in your repository by navigating to Repository Settings -&gt; Webhooks.</p>\n<h2 id=\"other-considerations\"><a href=\"https://www.digitalocean.com/blog.atom#other-considerations\">Other Considerations</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#other-considerations\"></a></h2>\n<p>To maximize the efficiency and effectiveness of our interactions with the Bitbucket API, we have incorporated standard best practices.</p>\n<h3 id=\"rate-limiting\"><a href=\"https://www.digitalocean.com/blog.atom#rate-limiting\">Rate Limiting</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#rate-limiting\"></a></h3>\n<p>Bitbucket imposes <a href=\"https://support.atlassian.com/bitbucket-cloud/docs/api-request-limits/\" rel=\"ugc nofollow noopener\" target=\"_blank\">rate limits on API requests</a> to ensure fair usage and prevent abuse. We handle these limits by implementing strategies like retries with exponential backoff and jitter when receiving 429 status codes. We also use appropriate page size limits to minimize the number of requests.</p>\n<h3 id=\"security\"><a href=\"https://www.digitalocean.com/blog.atom#security\">Security</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#security\"></a></h3>\n<p>Standard measures like using HTTPS to help ensure secure data transmission and storing encrypted tokens in the database. We only ask for bare minimum permissions to be granted by the user which includes read-only access to repositories. The webhook deliveries are also secured by means of signature verification to help ensure that our service only processes deliveries from Bitbucket Cloud.</p>\n<h3 id=\"multi-provider-limits\"><a href=\"https://www.digitalocean.com/blog.atom#multi-provider-limits\">Multi-Provider Limits</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#multi-provider-limits\"></a></h3>\n<p>A single DigitalOcean team member can now:</p>\n<ul>\n<li>Link multiple service accounts from different Git providers simultaneously.</li>\n<li>Cannot link multiple accounts from the same provider. Must remove existing connection before adding a new one from the same provider.</li>\n</ul>\n<h2 id=\"conclusion\"><a href=\"https://www.digitalocean.com/blog.atom#conclusion\">Conclusion</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#conclusion\"></a></h2>\n<p>With the addition of Bitbucket, App Platform now provides support for most of the popular Git version control systems, thus enabling seamless code deployment from repositories. To learn more, read the <a href=\"https://docs.digitalocean.com/products/app-platform/\" rel=\"ugc nofollow noopener\" target=\"_blank\">docs</a> and <a href=\"https://www.digitalocean.com/community/questions/new?tags=Digitalocean%20App%20Platform\">let us know what you think</a>!</p>",
      "timestamp": 1741512167.9887514,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "PostgreSQL 17 is now Available for DigitalOcean Managed PostgreSQL",
      "link": "https://www.digitalocean.com/blog/postgresql-17",
      "published": "2025-02-11T21:39:17.732Z",
      "summary": "<h1 id=\"postgresql-17-is-now-available-for-digitalocean-managed-postgresql\"><a href=\"https://www.digitalocean.com/blog.atom#postgresql-17-is-now-available-for-digitalocean-managed-postgresql\">PostgreSQL 17 is now Available for DigitalOcean Managed PostgreSQL</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#postgresql-17-is-now-available-for-digitalocean-managed-postgresql\"></a></h1>\n<p>We‚Äôre excited to announce that PostgreSQL 17 is now available on DigitalOcean Managed PostgreSQL. With this latest release, you can take advantage of a wealth of benefits, including better performance, expanded developer tools, enhanced security, observability and management tools, and more. Of course, we‚Äôll continue to handle the maintenance, backups, and scaling for you.</p>\n<h2 id=\"what-s-new-in-postgresql-17\"><a href=\"https://www.digitalocean.com/blog.atom#what-s-new-in-postgresql-17\"><strong>What‚Äôs new in PostgreSQL 17?</strong></a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-s-new-in-postgresql-17\"></a></h2>\n<p>Improved performance‚ÄîPostgreSQL 17 introduces significant enhancements that help to optimize database performance:</p>\n<ul>\n<li>\n<p><strong>Faster query execution</strong> through optimized sequential reads, reducing overall processing times.</p>\n</li>\n<li>\n<p><strong>Reduced memory usage for vacuum operations</strong>, making maintenance tasks more efficient and improving overall database health.</p>\n</li>\n<li>\n<p><strong>Indexing improvements</strong> that make lookups and data retrieval for applications with large datasets quicker.</p>\n</li>\n</ul>\n<p>Expanded Developer Tools‚ÄîDevelopers will benefit from several new features that make database management more intuitive and efficient:</p>\n<ul>\n<li>\n<p><strong>New constructors and identity functions</strong> that simplify the way you define and manage database schema elements.</p>\n</li>\n<li>\n<p><strong>The JSON_TABLE() function</strong>, allowing seamless transformation and querying of JSON data within PostgreSQL.</p>\n</li>\n<li>\n<p><strong>Enhanced SQL/JSON support</strong> t make working with structured and semi-structured data easier.</p>\n</li>\n</ul>\n<p>Enhanced high availability and replication‚ÄîFor businesses that rely on high uptime and data resilience, PostgreSQL 17 brings key improvements:</p>\n<ul>\n<li>\n<p><strong>Failover for logical replication</strong>, ensuring smoother transitions in high availability setups and disaster recovery scenarios.</p>\n</li>\n<li>\n<p><strong>Slot preservation during upgrades</strong> that reduce downtime and improving data consistency when moving to newer versions.</p>\n</li>\n<li>\n<p><strong>Performance optimizations in replication</strong>, providing better synchronization across distributed databases.</p>\n</li>\n</ul>\n<p>Advanced security and monitoring‚ÄîSecurity and database observability get notable upgrades in this release:</p>\n<ul>\n<li>\n<p><strong>Expanded monitoring and analysis tools</strong> that open up deeper insights into system health and performance for database administrators.</p>\n</li>\n<li>\n<p><strong>More granular access controls</strong> for tighter security and compliance with regulatory requirements.</p>\n</li>\n<li>\n<p><strong>Improvements in auditing features</strong>, allowing organizations to more precisely track and log critical database events.</p>\n</li>\n</ul>\n<h2 id=\"why-upgrade-to-postgresql-17-on-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#why-upgrade-to-postgresql-17-on-digitalocean\"><strong>Why upgrade to PostgreSQL 17 on DigitalOcean?</strong></a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#why-upgrade-to-postgresql-17-on-digitalocean\"></a></h2>\n<p>With DigitalOcean Managed PostgreSQL, you get the latest innovations without the headaches of manual maintenance. Our fully managed solution includes:</p>\n<ul>\n<li>\n<p><strong>Automated updates and security patches</strong>, so you always run on a secure and optimized database.</p>\n</li>\n<li>\n<p><strong>Built-in scalability</strong>, allowing you to adjust resources as your application grows.</p>\n</li>\n<li>\n<p><strong>24/7 monitoring and support</strong> to give you peace of mind while you focus on building your product.</p>\n</li>\n<li>\n<p><strong>Seamless integration</strong> with DigitalOcean‚Äôs entire ecosystem, including App Platform, Kubernetes, and Managed Databases.</p>\n</li>\n</ul>\n<h2 id=\"get-started-today\"><a href=\"https://www.digitalocean.com/blog.atom#get-started-today\">Get started today</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#get-started-today\"></a></h2>\n<p>If you need help getting started, check out these load balancer resources:</p>\n<ul>\n<li>\n<p><a href=\"https://www.digitalocean.com/products/managed-databases-postgresql\">Visit the Managed PostgreSQL homepage</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.digitalocean.com/#31-january-2025\" rel=\"ugc nofollow noopener\" target=\"_blank\">Read the documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.digitalocean.com/products/databases/postgresql/how-to/upgrade-version/\" rel=\"ugc nofollow noopener\" target=\"_blank\">Access the How-To Guide</a> (upgrading a cluster)</p>\n</li>\n<li>\n<p><a href=\"https://docs.digitalocean.com/products/databases/postgresql/details/limits/\" rel=\"ugc nofollow noopener\" target=\"_blank\">Updated Product Limits</a></p>\n</li>\n<li>\n<p><a href=\"https://www.postgresql.org/about/news/postgresql-17-released-2936/\" rel=\"ugc nofollow noopener\" target=\"_blank\">Read the Release Notes</a></p>\n</li>\n<li>\n<p><a href=\"https://www.digitalocean.com/company/contact/sales\">Contact our sales team</a></p>\n</li>\n</ul>",
      "timestamp": 1741512167.9887555,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Anthropic and DeepSeek Join the GenAI Platform Model Library",
      "link": "https://www.digitalocean.com/blog/now-available-anthropic-deepseek-models-gen-ai-platform",
      "published": "2025-02-07T17:15:49.188Z",
      "summary": "<p><a href=\"https://www.digitalocean.com/products/gen-ai\">DigitalOcean‚Äôs GenAI Platform</a> continues to expand, making AI-powered development more accessible, flexible, and powerful. Today, we‚Äôre excited to announce the availability  of Anthropic‚Äôs Claude models and DeepSeek R1 into our ecosystem, giving you even more options to build and deploy AI-driven applications.</p>\n<p>With <a href=\"https://cloud.digitalocean.com/gen-ai/model-library?i=e0fda3\" rel=\"ugc nofollow noopener\" target=\"_blank\">Anthropic Claude 3.5 (Sonnet &amp; Haiku), Claude 3 Opus, and DeepSeek R1-distill-llama-70B</a>, you get access to advanced AI options for content generation, real-time interactions, and problem-solving. Beyond serverless inference, meaning that you do not have to manage or provision underlying infrastructure to run AI models, DigitalOcean‚Äôs GenAI Platform offers an end-to-end agentic framework with seamless integration and easy deployment. This helps enable you to build AI-driven experiences without infrastructure headaches, paying only for what you use.</p>\n<h2 id=\"say-hello-to-claude-anthropic-s-state-of-the-art-large-language-models\"><a href=\"https://www.digitalocean.com/blog.atom#say-hello-to-claude-anthropic-s-state-of-the-art-large-language-models\">Say Hello to Claude: Anthropic‚Äôs State-of-the-Art Large Language Models</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#say-hello-to-claude-anthropic-s-state-of-the-art-large-language-models\"></a></h2>\n<p>Anthropic‚Äôs Claude models are designed to cater to a variety of enterprise needs, balancing intelligence, speed, and cost. Here‚Äôs an overview of the available models:</p>\n<p><strong>Claude 3.5 Sonnet</strong> ‚Äì This is the most advanced model in the Claude 3.5 family, offering top-tier performance with improved speed. It‚Äôs ideal for:</p>\n<ul>\n<li>Advanced research and analysis</li>\n<li>Complex problem-solving</li>\n<li>Sophisticated language understanding and generation</li>\n<li>High-level strategic planning</li>\n</ul>\n<p><strong>Claude 3.5 Haiku</strong> ‚Äì This model offers near-instant responsiveness, emulating human interactions. It‚Äôs best for:</p>\n<ul>\n<li>Live support chat</li>\n<li>Translations</li>\n<li>Content moderation</li>\n<li>Extracting information from unstructured data</li>\n</ul>\n<p><strong>Claude 3 Opus</strong> ‚Äì This model is designed for strong performance on highly complex tasks, such as mathematics and coding. It‚Äôs well-suited for:</p>\n<ul>\n<li>Task automation, robust coding, and R&amp;D</li>\n<li>Market analysis, forecasting, and strategic decision-making</li>\n<li>Advanced chart analysis and financial insights</li>\n<li>Brainstorming, hypothesis generation, and drug discovery</li>\n</ul>\n<p>Users can now integrate Claude models into their GenAI Platform agents by providing their Anthropic API key at setup. Token usage is billed directly to the user‚Äôs Anthropic account, while any DigitalOcean resources used (e.g., knowledge bases, functions, guardrails) are billed through their DigitalOcean team account.</p>\n<h2 id=\"introducing-deepseek-r1-distill-llama-70b-open-source-power-without-infrastructure-hassle\"><a href=\"https://www.digitalocean.com/blog.atom#introducing-deepseek-r1-distill-llama-70b-open-source-power-without-infrastructure-hassle\">Introducing DeepSeek R1-distill-llama-70B: Open-Source Power without Infrastructure Hassle</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#introducing-deepseek-r1-distill-llama-70b-open-source-power-without-infrastructure-hassle\"></a></h2>\n<p>The DeepSeek R1 model family represents cutting-edge advancements in open-source AI. Released in January, DeepSeek R1 models have  made a splash in the AI community, in some instances, even outperforming leading models.</p>\n<ul>\n<li><strong>Optimized for reasoning, code, and math tasks</strong> ‚Äì making it ideal for developers, analysts, and engineers.</li>\n<li><strong>Ideal for agent routing</strong> ‚Äì easy to set up and leverage within the GenAI Platform for task-specific AI agents.</li>\n<li><strong>Multi-lingual support</strong> ‚Äì providing context-aware responses across different languages.</li>\n<li><strong>Reasoning transparency</strong> ‚Äì users can see not just the answer, but also how the model arrived at it.</li>\n</ul>\n<p>DeepSeek R1-distill-llama-70B is available on the GenAI Platform, and token usage is billed directly through the user‚Äôs DigitalOcean account, with no API key needed.</p>\n<h2 id=\"why-choose-the-digitalocean-genai-platform\"><a href=\"https://www.digitalocean.com/blog.atom#why-choose-the-digitalocean-genai-platform\">Why Choose the DigitalOcean GenAI Platform?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#why-choose-the-digitalocean-genai-platform\"></a></h2>\n<p>Our new GenAI Platform is built for simplicity, streamlining AI model deployment with an intuitive interface and pre-built tools that help eliminate complexity. Whether you‚Äôre an experienced developer or new to AI, the platform makes it easy to create and scale intelligent applications.</p>\n<ul>\n<li><strong>Frictionless Model Deployment</strong> ‚Äì Get up and running with DeepSeek models in seconds with all the tools you need to build a comprehensive AI agent at your fingertips.</li>\n<li><strong>Flexible Bring-Your-Own-Key Support</strong> ‚Äì Seamlessly integrate Anthropic Claude models with your existing API key and billing structure.</li>\n<li><strong>Serverless Model Inference</strong> ‚Äì Eliminate infrastructure complexity with fully managed AI model hosting, allowing you to seamlessly integrate the agent and model into your applications.</li>\n<li><strong>Scalability &amp; Cost Control</strong> ‚Äì Pay-as-you-go pricing for open-source models, giving users full control over their compute costs.</li>\n</ul>\n<h2 id=\"build-your-new-agents-today\"><a href=\"https://www.digitalocean.com/blog.atom#build-your-new-agents-today\">Build Your New Agents Today</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#build-your-new-agents-today\"></a></h2>\n<p>Deploying AI agents with Anthropic Claude or DeepSeek R1 just got easier than ever. Whether you‚Äôre building customer support chatbots, automating workflows, or developing AI-powered applications, the GenAI Platform provides everything you need. Plus, we handle the infrastructure, helping to provide reliable, scalable, and fully managed hosting so you can focus on building and deploying your AI solutions without the overhead.</p>\n<div class=\"callout draft\">\n<p><strong><a href=\"https://cloud.digitalocean.com/gen-ai/model-library?i=e0fda3\" rel=\"ugc nofollow noopener\" target=\"_blank\">Try the new models now -&gt;</a></strong></p>\n</div>",
      "timestamp": 1741512167.98876,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Currents Report: How Growing Tech Businesses Use AI Today",
      "link": "https://www.digitalocean.com/blog/currents-research-report-how-tech-businesses-use-ai-today",
      "published": "2025-02-06T20:10:16.445Z",
      "summary": "<h2 id=\"introduction\"><a href=\"https://www.digitalocean.com/blog.atom#introduction\">Introduction</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#introduction\"></a></h2>\n<p>Currents is DigitalOcean‚Äôs report on trends impacting developers at growing tech businesses around the world. For our latest edition, we focused on how these growing businesses are adapting to the increased adoption of artificial intelligence. The rise of AI has created opportunities for individual developers and businesses, but integrating new tools and technologies is not without challenges, especially for those who are not large enterprises with teams dedicated to AI. This report, gathered responses from over 1,000 developers around the world, examines how widespread adoption of AI really is, what challenges developers face when it comes to AI adoption, how usage of AI tools differs based on company size and other factors, and what the biggest upcoming trends are.</p>\n<p>The findings reveal a significant growth opportunity, as 21% of organizations have yet to implement AI formally in any form. Despite this, there is clear interest in AI innovation: 66% of respondents are engaged in passion projects exploring AI, and 36% are actively investigating capabilities without having launched formal initiatives. For small and medium enterprises (SMEs) in particular, AI adoption could be a game-changer by allowing developers to take on multiple roles more easily‚Äîbut they must first overcome key barriers, such as high Graphical Processing Unit (GPU) costs and lack of internal knowledge on how to best leverage these tools.</p>\n<h2 id=\"key-findings\"><a href=\"https://www.digitalocean.com/blog.atom#key-findings\">Key findings:</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#key-findings\"></a></h2>\n<h3 id=\"ai-adoption-is-increasing-but-still-has-growth-potential\"><a href=\"https://www.digitalocean.com/blog.atom#ai-adoption-is-increasing-but-still-has-growth-potential\">AI adoption is increasing, but still has growth potential</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#ai-adoption-is-increasing-but-still-has-growth-potential\"></a></h3>\n<p>AI adoption has increased significantly over the past year‚Äîin November 2023, we found that 49% of respondents had used AI for business use, and a year later, 79% say their organization is integrating AI in some form. However, there is still clear room for more growth and maturity in organizations‚Äô AI usage, as 32% say they are just starting to explore AI, and just 11% consider themselves an AI-driven business.</p>\n<h3 id=\"cost-and-knowledge-are-barriers-for-entry-for-smes\"><a href=\"https://www.digitalocean.com/blog.atom#cost-and-knowledge-are-barriers-for-entry-for-smes\">Cost and knowledge are barriers for entry for SMEs</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#cost-and-knowledge-are-barriers-for-entry-for-smes\"></a></h3>\n<p>The high upfront costs of GPUs are a challenge for 34% of businesses, along with the lack of knowledge around how to optimize GPUs. Smaller companies feel this more acutely, and sometimes struggle to justify investments in AI as they find it challenging to demonstrate a clear return on investment from these activities, and have a lack of dedicated in-house AI resources.</p>\n<h3 id=\"trust-safety-and-integration-concerns\"><a href=\"https://www.digitalocean.com/blog.atom#trust-safety-and-integration-concerns\">Trust, safety, and integration concerns</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#trust-safety-and-integration-concerns\"></a></h3>\n<p>Other challenges with adoption for AI include integrating AI into existing workflows and choosing the right AI model. Looking at the most urgent issues in the AI space today, 47% say reliance on unverified LLM data is a top concern, along with ensuring AI data is unbiased.</p>\n<h3 id=\"upcoming-trends-in-ai\"><a href=\"https://www.digitalocean.com/blog.atom#upcoming-trends-in-ai\">Upcoming trends in AI</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#upcoming-trends-in-ai\"></a></h3>\n<p>While areas such as agentic AI are already growing quickly, we looked at what respondents feel is the next frontier of AI, and found that Advanced Multi Modal Systems, Real Time Audio Translation, and Automated Machine Learning are the next most compelling. Organizations currently are primarily using AI for improving internal processes and operations and enhancing their existing services with AI/ML.</p>\n<h2 id=\"read-the-report\"><a href=\"https://www.digitalocean.com/blog.atom#read-the-report\">Read the report</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#read-the-report\"></a></h2>\n<p>These findings make it clear‚Äîaccessible AI solutions are key to unlocking AI for businesses of all sizes, especially those without large teams dedicated to AI transformation. Affordable GPU compute and approachable AI tools will help alleviate the challenges many developers are currently facing when it comes to AI, and enable them to integrate AI solutions more efficiently.</p>\n<p>Visit our <a href=\"https://www.digitalocean.com/currents/february-2025\">Currents webpage for the full report and graphs</a> and <a href=\"https://cloud.digitalocean.com/registrations/new\" rel=\"ugc nofollow noopener\" target=\"_blank\">sign up</a> to explore DigitalOcean‚Äôs Generative AI platform and GPU offerings.</p>",
      "timestamp": 1741512167.988764,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Sharks of DigitalOcean: Vasily Prokopov, Staff Solutions Engineer",
      "link": "https://www.digitalocean.com/blog/shark-tales-vasily-prokopov-staff-solutions-engineer",
      "published": "2025-02-05T06:39:16.160Z",
      "summary": "<p>When Vasily Prokopov first came across DigitalOcean, one thing immediately stood out to him: <strong>DO Love</strong>. ‚ÄúHow often do you find a company that lists love as one of its core values?‚Äù he thought. Fast forward to today, Vasily is thriving as a Staff Solutions Engineer in Amsterdam, Netherlands, where that same value shapes every aspect of his work. ‚ÄúThe people here are genuinely supportive, always ready to lend a hand‚Äîwhether you‚Äôre tackling a tricky task or eager to learn something new,‚Äù he says with a smile.</p>\n<p>Vasily helps customers onboard to DigitalOcean, shares best practices for cloud deployment, and acts as a bridge between customers and our product teams. His energy and enthusiasm for innovation are contagious. Read on to hear more about his journey and how he‚Äôs helping developers around the world embrace the simplicity and scalability of cloud technology.</p>\n<h2 id=\"what-excites-you-about-your-role-at-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#what-excites-you-about-your-role-at-digitalocean\">What excites you about your role at DigitalOcean?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-excites-you-about-your-role-at-digitalocean\"></a></h2>\n<p>My role at DigitalOcean has many aspects. A key focus of my role is developing engineering solutions that help new customers successfully integrate and get the most value from DigitalOcean‚Äôs platform. We provide technical assistance, ensure applications are ready for cloud deployment, and guide customers with best practices. We speak with so many customers that we have gathered a wealth of common wisdom about deploying applications in the cloud, and we are always willing and ready to share this information with any customer interested in joining DigitalOcean.</p>\n<div class=\"callout info\">\n<p><strong>üé• Have a look at Vasily‚Äôs full conversation ‚¨áÔ∏è</strong></p>\n\n    <a href=\"https://www.youtube.com/watch?v=_gHMo47Jj_o\" target=\"_blank\">View YouTube video</a>\n\n</div>\n<h2 id=\"how-would-you-describe-the-pace-of-innovation-at-do\"><a href=\"https://www.digitalocean.com/blog.atom#how-would-you-describe-the-pace-of-innovation-at-do\">How would you describe the pace of innovation at DO?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#how-would-you-describe-the-pace-of-innovation-at-do\"></a></h2>\n<p>When it comes to innovation, the thing I really like about working at DigitalOcean is that we are always at the edge of technology. We have these crazy waves of innovation like blockchain, and now it‚Äôs artificial intelligence and machine learning. All the customers that we talk to bring their use cases to DigitalOcean. At DigitalOcean, you will always work with the latest technology. I find this to be a great way for me to stay on the bleeding edge of technology in the industry, and I think that‚Äôs a huge advantage for anyone who joins DigitalOcean.</p>\n<h2 id=\"how-does-customer-feedback-influence-product-development-at-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#how-does-customer-feedback-influence-product-development-at-digitalocean\">How does customer feedback influence product development at DigitalOcean?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#how-does-customer-feedback-influence-product-development-at-digitalocean\"></a></h2>\n<p>On top of helping customers onboard, we also act as a bridge between customers and the product teams. Our roadmap is customer-driven, so when we meet customers, we always ask about the highlights and lowlights of our products. When they share something, we make sure that we pass this feedback to the engineering teams, and then we can implement the features in the future. So, this path between customers, their feedback, and their emotions is translated and passed on to product engineering.</p>\n<h2 id=\"how-would-you-describe-the-culture-of-customer-centricity-at-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#how-would-you-describe-the-culture-of-customer-centricity-at-digitalocean\">How would you describe the culture of customer-centricity at DigitalOcean?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#how-would-you-describe-the-culture-of-customer-centricity-at-digitalocean\"></a></h2>\n<p>Our day-to-day job is to get on calls with customers and help them solve their issues. I think the most important quality of an engineer on this team is really being able to get into the shoes of a customer to understand them. We take the problem of a customer and treat it as our own problem to try to solve it for them. So this is what being customer-centric means to me ‚Äîto show this empathy and help all the customers that we serve at DigitalOcean.</p>\n<h2 id=\"what-do-value-do-you-resonate-with-the-most\"><a href=\"https://www.digitalocean.com/blog.atom#what-do-value-do-you-resonate-with-the-most\">What DO value do you resonate with the most?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-do-value-do-you-resonate-with-the-most\"></a></h2>\n<p>Out of all the values we have here at DigitalOcean, one that stands out to me the most is <strong>DO Simple</strong>. DigitalOcean has built itself to be a very simple cloud. There are many other clouds all around, but you sometimes have to have a PhD to run your simple workload in their clouds. What we build and what we deliver to customers is all very simple. The builds, the products, and the configurations are all developed in a way to give customers maximum value with minimal complexity.</p>\n<p>For our customers, simplicity means that you don‚Äôt have to invest in a big DevOps team; you don‚Äôt have to invest a lot into learning some new technology. Instead, you can take the solution and start using it because it‚Äôs very simple. If you want to run Kubernetes at some point, good luck; that‚Äôs a steep learning curve. If you use the DigitalOcean App Platform, it offers the same benefit, but it‚Äôs much simpler. That‚Äôs why a lot of customers love our products.</p>\n<h2 id=\"dive-into-the-future-with-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#dive-into-the-future-with-digitalocean\">Dive into the future with DigitalOcean</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#dive-into-the-future-with-digitalocean\"></a></h2>\n<p>At DigitalOcean, our customers and community are at the heart of everything we do. We believe in acting like owners, with a bias for action and a relentless drive to simplify cloud computing. If you‚Äôre passionate about continuous learning, thinking bold, and being part of a supportive, innovative team, <a href=\"https://www.digitalocean.com/careers\">explore our open roles today</a>!</p>",
      "timestamp": 1741512167.9887683,
      "translated": false
    },
    {
      "feed_name": "DigitalOcean Kubernetes Content",
      "source_language": "en",
      "title": "Deploy DeepSeek AI Models Instantly on DigitalOcean GPU Droplets",
      "link": "https://www.digitalocean.com/blog/now-available-deepseek-r1-on-gpu-droplets",
      "published": "2025-01-30T21:46:40.443Z",
      "summary": "<p>We‚Äôre excited to announce that DeepSeek R1, the open-source advanced reasoning model, is now available on DigitalOcean as a <a href=\"https://cloud.digitalocean.com/gpus/new?region=nyc2&amp;size=gpu-h100x8-640gb&amp;fleetUuid=e31b0c76-06d2-49d4-b446-2b81a38007c7&amp;appId=177155486&amp;image=deepseek-r1-671b&amp;type=applications\" rel=\"ugc nofollow noopener\" target=\"_blank\">GPU Droplet 1-Click Model</a>. You can now launch DeepSeek R1 directly on DigitalOcean GPU Droplets from the cloud console, streamlining the deployment process.</p>\n<h3 id=\"what-is-deepseek-r1\"><a href=\"https://www.digitalocean.com/blog.atom#what-is-deepseek-r1\">What is DeepSeek R1?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#what-is-deepseek-r1\"></a></h3>\n<p>DeepSeek R1 is a cutting-edge open-source AI model optimized for high-performance NLP and generative AI tasks, including text generation, summarization, and translation. With innovative reasoning capabilities that extend beyond typical LLMs, it stands as one of the most powerful open-source models released. Deploying DeepSeek R1 on DigitalOcean enables developers to integrate advanced AI into their applications effortlessly, without the complexities of infrastructure setup.</p>\n<h3 id=\"launch-deepseek-in-1-click-on-gpu-droplets\"><a href=\"https://www.digitalocean.com/blog.atom#launch-deepseek-in-1-click-on-gpu-droplets\">Launch DeepSeek in 1-Click on GPU Droplets</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#launch-deepseek-in-1-click-on-gpu-droplets\"></a></h3>\n<p>Getting started with the latest DeepSeek model is now easier than ever. With DigitalOcean GPU Droplets and our 1-Click Models, you can deploy DeepSeek R1 in minutes without worrying about setup complexities. DeepSeek R1 is praised as one of the most computationally efficient open-source LLM, allowing you to save on AI infrastructure deployment costs.</p>\n<h3 id=\"why-choose-digitalocean-1-click-models\"><a href=\"https://www.digitalocean.com/blog.atom#why-choose-digitalocean-1-click-models\">Why Choose DigitalOcean 1-Click Models?</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#why-choose-digitalocean-1-click-models\"></a></h3>\n<ul>\n<li><strong>Instant Deployment:</strong> Get models running with a single click‚Äîno manual installation required.</li>\n<li><strong>Optimized Performance:</strong> DigitalOcean GPU Droplets provide powerful, cost-effective compute resources for AI workloads.</li>\n<li><strong>Seamless Scalability:</strong> Easily scale your AI applications as your needs grow.</li>\n<li><strong>Developer-Friendly:</strong> Simple, intuitive deployment through the DigitalOcean Cloud Console.</li>\n</ul>\n<h3 id=\"how-to-deploy-deepseek-on-digitalocean\"><a href=\"https://www.digitalocean.com/blog.atom#how-to-deploy-deepseek-on-digitalocean\">How to Deploy DeepSeek on DigitalOcean</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#how-to-deploy-deepseek-on-digitalocean\"></a></h3>\n<p>Launching DeepSeek with 1-Click Models is simple:</p>\n<ol>\n<li>\n<p>Navigate to the 1-Click Models section in the DigitalOcean Cloud Console\n<img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/image%201.png\" /></p>\n</li>\n<li>\n<p>Select DeepSeek from the available models.\n<img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/image%202.png\" /></p>\n</li>\n<li>\n<p>Choose your preferred GPU Droplet configuration.\n<img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/image%203.png\" /></p>\n</li>\n<li>\n<p>Click Deploy, and your DeepSeek model will be up and running within minutes!\n<img alt=\"image alt text\" src=\"https://doimages.nyc3.cdn.digitaloceanspaces.com/002Blog/EngineeringBlogImages_Grace/image%204.png\" /></p>\n</li>\n</ol>\n<h3 id=\"get-started-today\"><a href=\"https://www.digitalocean.com/blog.atom#get-started-today\">Get Started Today</a><a class=\"hash-anchor\" href=\"https://www.digitalocean.com/blog.atom#get-started-today\"></a></h3>\n<p>With DigitalOcean‚Äôs 1-Click Models, deploying DeepSeek has never been faster. Whether you‚Äôre building AI-powered chatbots, content generation tools, or other NLP applications, you can now focus on innovation instead of infrastructure. <a href=\"https://cloud.digitalocean.com/gpus/new?region=nyc2&amp;size=gpu-h100x8-640gb&amp;fleetUuid=e31b0c76-06d2-49d4-b446-2b81a38007c7&amp;appId=177155486&amp;image=deepseek-r1-671b&amp;type=applications\" rel=\"ugc nofollow noopener\" target=\"_blank\">Try it today and accelerate your AI development with DigitalOcean GPU Droplets -&gt;</a></p>\n<div class=\"callout info\">\n<p>Want to learn more? Check out our tutorial on <a href=\"https://www.digitalocean.com/community/tutorials/deepseek-r1-gpu-droplets\">running DeepSeek R1 large language models on DigitalOcean GPU Droplets with Ollama</a> or <a href=\"https://www.digitalocean.com/community/tutorials/deepseek-r1-large-language-model-capabilities\">understanding the capabilities of DeepSeek R1 large language models</a>.</p>\n</div>",
      "timestamp": 1741512167.9887722,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Why Infrastructure as Code Needs to be Secure by Default",
      "link": "https://www.cncf.io/blog/2025/03/07/why-infrastructure-as-code-needs-to-be-secure-by-default/",
      "published": "Fri, 07 Mar 2025 15:04:57 +0000",
      "summary": "Infrastructure as Code (IaC) has become the standard for managing cloud infrastructure, but it introduces significant challenges, particularly around security and compliance. Issues such as misconfigurations, secret management, policy enforcement, and auditing can complicate workflows. These...",
      "timestamp": 1741512171.7283921,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Welcome StrimziCon 2025!",
      "link": "https://www.cncf.io/blog/2025/03/07/welcome-strimzicon-2025/",
      "published": "Fri, 07 Mar 2025 13:17:13 +0000",
      "summary": "We are very pleased to announce the return of StrimziCon, scheduled later this year! After the huge success of StrimziCon 2024, the Strimzi community decided to repeat the event for 2025. Like last year, this is...",
      "timestamp": 1741512171.728397,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Too Complex: It‚Äôs Not Kubernetes, It‚Äôs What It Does",
      "link": "https://www.cncf.io/blog/2025/03/06/too-complex-its-not-kubernetes-its-what-it-does/",
      "published": "Thu, 06 Mar 2025 21:30:01 +0000",
      "summary": "The open-source container orchestration system for automating software deployment, scaling, and management has earned a bad rep for being too complicated. In this post, let‚Äôs explore whether that reputation is well deserved. The Steep Learning Curve...",
      "timestamp": 1741512171.7284005,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Kubestronaut in Orbit: Gerardo L√≥pez",
      "link": "https://www.cncf.io/blog/2025/03/06/kubestronaut-in-orbit-gerardo-lopez/",
      "published": "Thu, 06 Mar 2025 21:17:25 +0000",
      "summary": "Get to know Gerardo Gerardo is a passionate Cloud Native Advocate, Kubernetes expert, and Docker Captain with a strong focus on DevOps, software development, and security. Based in Costa Rica, he has earned several certifications, including...",
      "timestamp": 1741512171.728404,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "KubeCon + CloudNativeCon Europe 2025 co-located event deep dive: OpenFeature Summit",
      "link": "https://www.cncf.io/blog/2025/03/06/kubecon-cloudnativecon-europe-2025-co-located-event-deep-dive-openfeature-summit/",
      "published": "Thu, 06 Mar 2025 12:52:56 +0000",
      "summary": "Co-chairs: Michael Beemer, Jonathan Norris, Thomas PoignantApril 1, 2025London At the OpenFeature Summit, we want attendees to leave with a deep understanding of the latest trends and real-world use cases in feature flagging. This event is...",
      "timestamp": 1741512171.7284076,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "AI Cloud: What, Why, and How?",
      "link": "https://www.cncf.io/blog/2025/03/06/ai-cloud-what-why-and-how/",
      "published": "Thu, 06 Mar 2025 12:34:28 +0000",
      "summary": "The rapid growth of AI applications across industries has led to significant changes, particularly with the adoption of deep learning and generative AI, which provide a competitive advantage in industries such as drug discovery in pharmaceutical...",
      "timestamp": 1741512171.728411,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Volcano v1.11 Released! A New Era of Cloud-Native Scheduling for AI and Big Data",
      "link": "https://www.cncf.io/blog/2025/03/05/volcano-v1-11-released-a-new-era-of-cloud-native-scheduling-for-ai-and-big-data/",
      "published": "Wed, 05 Mar 2025 12:34:45 +0000",
      "summary": "As the de facto standard in cloud-native batch computing, Volcano has been widely adopted across various scenarios, including AI, Big Data, and High-Performance Computing (HPC). With over 800 contributors from more than 30 countries and tens...",
      "timestamp": 1741512171.7284145,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Aligning Language Practices for KubeCon + CloudNativeCon Japan and KubeCon + CloudNativeCon China",
      "link": "https://www.cncf.io/blog/2025/03/05/aligning-language-practices-for-kubecon-cloudnativecon-japan-and-kubecon-cloudnativecon-china/",
      "published": "Wed, 05 Mar 2025 12:23:34 +0000",
      "summary": "The global cloud native community thrives on diversity and collaboration, bringing together contributors, users, and enthusiasts worldwide. As we continue to grow and expand, we are committed to creating an inclusive and effective environment for learning...",
      "timestamp": 1741512171.7284179,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "Observability Trends in 2025 ‚Äì What‚Äôs Driving Change?",
      "link": "https://www.cncf.io/blog/2025/03/05/observability-trends-in-2025-whats-driving-change/",
      "published": "Wed, 05 Mar 2025 12:10:08 +0000",
      "summary": "Member post originally published on the Middleware blog by Sam Suthar Observability has evolved beyond traditional monitoring, integrating AI, automation, and security. Initially, monitoring focused on collecting logs and metrics separately, often leading to silos and...",
      "timestamp": 1741512171.7284214,
      "translated": false
    },
    {
      "feed_name": "CNCF Blog",
      "source_language": "en",
      "title": "KubeCon + CloudNativeCon Europe 2025 co-located event deep dive: Cloud Native + Kubernetes AI Day",
      "link": "https://www.cncf.io/blog/2025/03/04/kubecon-cloudnativecon-europe-2025-co-located-event-deep-dive-cloud-native-kubernetes-ai-day/",
      "published": "Tue, 04 Mar 2025 14:05:34 +0000",
      "summary": "Co-chairs: Rajas Kakodkar, Ricardo Rocha, Thiago Gil, Yuan TangApril 1, 2025London Cloud Native &#38; Kubernetes AI Day brings together a diverse range of technical enthusiasts, open source contributors, practitioners, researchers and end users, all united in...",
      "timestamp": 1741512171.7284253,
      "translated": false
    }
  ]
}